<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Apache SkyWalking – Trace</title>
    <link>/tags/trace/</link>
    <description>Recent content in Trace on Apache SkyWalking</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Thu, 12 Jan 2023 00:00:00 +0000</lastBuildDate>
    
	  <atom:link href="/tags/trace/feed.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Blog: eBPF enhanced HTTP observability - L7 metrics and tracing</title>
      <link>/blog/ebpf-enhanced-http-observability-l7-metrics-and-tracing/</link>
      <pubDate>Thu, 12 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/blog/ebpf-enhanced-http-observability-l7-metrics-and-tracing/</guid>
      <description>
        
        
        &lt;p&gt;&lt;img src=&#34;banner.jpg&#34; alt=&#34;banner&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;Apache SkyWalking is an open-source Application Performance Management system that helps users collect and aggregate logs, traces, metrics, and events for display on a UI. In the &lt;a href=&#34;/blog/diagnose-service-mesh-network-performance-with-ebpf/&#34;&gt;previous article&lt;/a&gt;, we introduced how to use Apache SkyWalking Rover to analyze the network performance issue in the service mesh environment. However, in business scenarios, users often rely on mature layer 7 protocols, such as HTTP, for interactions between systems. In this article, we will discuss how to use eBPF techniques to analyze performance bottlenecks of layer 7 protocols and how to enhance the tracing system using network sampling.&lt;/p&gt;
&lt;p&gt;This article will show how to use &lt;a href=&#34;https://github.com/apache/skywalking&#34;&gt;Apache SkyWalking&lt;/a&gt; with &lt;a href=&#34;https://ebpf.io/what-is-ebpf/&#34;&gt;eBPF&lt;/a&gt; to enhance metrics and traces in HTTP observability.&lt;/p&gt;
&lt;h2 id=&#34;http-protocol-analysis&#34;&gt;HTTP Protocol Analysis&lt;/h2&gt;
&lt;p&gt;HTTP is one of the most common Layer 7 protocols and is usually used to provide services to external parties and for inter-system communication. In the following sections, we will show how to identify and analyze HTTP/1.x protocols.&lt;/p&gt;
&lt;h3 id=&#34;protocol-identification&#34;&gt;Protocol Identification&lt;/h3&gt;
&lt;p&gt;In HTTP/1.x, the client and server communicate through a single file descriptor (FD) on each side. Figure 1 shows the process of communication involving the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Connect/accept: The client establishes a connection with the HTTP server, or the server accepts a connection from the client.&lt;/li&gt;
&lt;li&gt;Read/write (multiple times): The client or server reads and writes HTTPS requests and responses. A single request-response pair occurs within the same connection on each side.&lt;/li&gt;
&lt;li&gt;Close: The client and server close the connection.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To obtain HTTP content, it’s necessary to read it from the second step of this process. As defined in the &lt;a href=&#34;http://rfc-editor.org/rfc/rfc2068.html&#34;&gt;RFC&lt;/a&gt;, the content is contained within the data of the Layer 4 protocol and can be obtained by parsing the data. The request and response pair can be correlated because they both occur within the same connection on each side.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f1.png&#34; alt=&#34;Figure 1: HTTP communication timeline.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 1: HTTP communication timeline.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;http-pipeline&#34;&gt;HTTP Pipeline&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/HTTP_pipelining&#34;&gt;HTTP pipelining&lt;/a&gt; is a feature of HTTP/1.1 that enables multiple HTTP requests to be sent over a single TCP connection without waiting for the corresponding responses. This feature is important because it ensures that the order of the responses on the server side matches the order of the requests.&lt;/p&gt;
&lt;p&gt;Figure 2 illustrates how this works. Consider the following scenario: an HTTP client sends multiple requests to a server, and the server responds by sending the HTTP responses in the same order as the requests. This means that the first request sent by the client will receive the first response from the server, the second request will receive the second response, and so on.&lt;/p&gt;
&lt;p&gt;When designing HTTP parsing, we should follow this principle by adding request data to a list and removing the first item when parsing a response. This ensures that the responses are processed in the correct order.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f2.png&#34; alt=&#34;Figure 2: HTTP/1.1  pipeline.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 2: HTTP/1.1  pipeline.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;metrics&#34;&gt;Metrics&lt;/h3&gt;
&lt;p&gt;Based on the identification of the HTTP content and process topology diagram mentioned in the previous article, we can combine these two to generate process-to-process metrics data.&lt;/p&gt;
&lt;p&gt;Figure 3 shows the metrics that currently support the analysis between the two processes. Based on the HTTP request and response data, we can analyze the following data:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Metrics Name&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Type&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Unit&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Request CPM(Call Per Minute)&lt;/td&gt;
&lt;td&gt;Counter&lt;/td&gt;
&lt;td&gt;count&lt;/td&gt;
&lt;td&gt;The HTTP request count&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Response Status CPM(Call Per Minute)&lt;/td&gt;
&lt;td&gt;Counter&lt;/td&gt;
&lt;td&gt;count&lt;/td&gt;
&lt;td&gt;The count of per HTTP response status code&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Request Package Size&lt;/td&gt;
&lt;td&gt;Counter/Histogram&lt;/td&gt;
&lt;td&gt;Byte&lt;/td&gt;
&lt;td&gt;The request package size&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Response Package Size&lt;/td&gt;
&lt;td&gt;Counter/Histogram&lt;/td&gt;
&lt;td&gt;Byte&lt;/td&gt;
&lt;td&gt;The response package size&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Client Duration&lt;/td&gt;
&lt;td&gt;Counter/Histogram&lt;/td&gt;
&lt;td&gt;Millisecond&lt;/td&gt;
&lt;td&gt;The duration of single HTTP response on the client side&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Server Duration&lt;/td&gt;
&lt;td&gt;Counter/Histogram&lt;/td&gt;
&lt;td&gt;Millisecond&lt;/td&gt;
&lt;td&gt;The duration of single HTTP response on the server side&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img src=&#34;f3.png&#34; alt=&#34;Figure 3: Process-to-process metrics.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 3: Process-to-process metrics.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;http-and-trace&#34;&gt;HTTP and Trace&lt;/h2&gt;
&lt;p&gt;During the HTTP process, if we unpack the HTTP requests and responses from raw data, we can use this data to correlate with the existing tracing system.&lt;/p&gt;
&lt;h3 id=&#34;trace-context-identification&#34;&gt;Trace Context Identification&lt;/h3&gt;
&lt;p&gt;In order to track the flow of requests between multiple services, the trace system usually creates a trace context when a request enters a service and passes it along to other services during the request-response process. For example, when an HTTP request is sent to another server, the trace context is included in the request header.&lt;/p&gt;
&lt;p&gt;Figure 4 displays the raw content of an HTTP request intercepted by Wireshark. The trace context information generated by the Zipkin Tracing system can be identified by the “X-B3” prefix in the header. By using eBPF to intercept the trace context in the HTTP header, we can connect the current request with the trace system.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f4.png&#34; alt=&#34;Figure 4: View of HTTP headers in Wireshark.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 4: View of HTTP headers in Wireshark.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;trace-event&#34;&gt;Trace Event&lt;/h3&gt;
&lt;p&gt;We have added the concept of an &lt;em&gt;event&lt;/em&gt; to traces. An event can be attached to a span and consists of start and end times, tags, and summaries, allowing us to attach any desired information to the Trace.&lt;/p&gt;
&lt;p&gt;When performing eBPF network profiling, two events can be generated based on the request-response data. Figure 5 illustrates what happens when a service performs an HTTP request with profiling. The trace system generates &lt;em&gt;trace context&lt;/em&gt; information and sends it in the request. When the service executes in the kernel, we can generate an event for the corresponding trace span by interacting with the request-response data and execution time in the kernel space.&lt;/p&gt;
&lt;p&gt;Previously, we could only observe the execution status in the user space. However, by combining traces and eBPF technologies, we can now also get more information about the current trace in the kernel space, which would impact less performance for the target service if we do similar things in the tracing SDK and agent.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f5.png&#34; alt=&#34;Figure 5: Logical view of profiling an HTTP request and response.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 5: Logical view of profiling an HTTP request and response.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;sampling&#34;&gt;Sampling&lt;/h3&gt;
&lt;p&gt;To ensure efficient data storage and minimize unnecessary data sampling, we use a sampling mechanism for traces in our system. This mechanism triggers sampling only when certain conditions are met. We also provide a list of the top &lt;em&gt;N&lt;/em&gt; traces, which allows users to quickly access the relevant request information for a specific trace.&lt;/p&gt;
&lt;p&gt;To help users easily identify and analyze relevant events, we offer three different sampling rules:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Slow Traces&lt;/strong&gt;: Sampling is triggered when the response time for a request exceeds a specified threshold.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Response Status [400, 500)&lt;/strong&gt;: Sampling is triggered when the response status code is greater than or equal to 400 and less than 500.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Response Status [500, 600)&lt;/strong&gt;: Sampling is triggered when the response status code is greater than or equal to 500 and less than 600.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In addition, we recognize that not all request or response raw data may be necessary for analysis. For example, users may be more interested in requesting data when trying to identify performance issues, while they may be more interested in response data when troubleshooting errors. As such, we also provide configuration options for request or response events to allow users to specify which type of data they would like to sample.&lt;/p&gt;
&lt;h2 id=&#34;profiling-in-a-service-mesh&#34;&gt;Profiling in a Service Mesh&lt;/h2&gt;
&lt;p&gt;The SkyWalking and SkyWalking Rover projects have already implemented the HTTP protocol &lt;em&gt;analyze&lt;/em&gt; and &lt;em&gt;trace&lt;/em&gt; associations. How do they perform when running in a service mesh environment?&lt;/p&gt;
&lt;h3 id=&#34;deployment&#34;&gt;Deployment&lt;/h3&gt;
&lt;p&gt;Figure 6 demonstrates the deployment of SkyWalking and SkyWalking Rover in a service mesh environment. SkyWalking Rover is deployed as a DaemonSet on each machine where a service is located and communicates with the SkyWalking backend cluster. It automatically recognizes the services on the machine and reports metadata information to the SkyWalking backend cluster. When a new network profiling task arises, SkyWalking Rover senses the task and analyzes the designated processes, collecting and aggregating network data before ultimately reporting it back to the SkyWalking backend service.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f6.png&#34; alt=&#34;Figure 6: SkyWalking rover deployment topology in a service mesh.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 6: SkyWalking rover deployment topology in a service mesh.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;tracing-systems&#34;&gt;Tracing Systems&lt;/h3&gt;
&lt;p&gt;Starting from version 9.3.0, the SkyWalking backend fully supports all functions in the Zipkin server. Therefore, the SkyWalking backend can collect traces from both the SkyWalking and Zipkin protocols. Similarly, SkyWalking Rover can identify and analyze trace context in both the SkyWalking and Zipkin trace systems. In the following two sections, network analysis results will be displayed in the SkyWalking and Zipkin UI respectively.&lt;/p&gt;
&lt;h4 id=&#34;skywalking&#34;&gt;SkyWalking&lt;/h4&gt;
&lt;p&gt;When SkyWalking performs network profiling, similar to the TCP metrics in the &lt;a href=&#34;/blog/diagnose-service-mesh-network-performance-with-ebpf/&#34;&gt;previous article&lt;/a&gt;, the SkyWalking UI will first display the topology between processes. When you open the dashboard of the line representing the traffic metrics between processes, you can see the metrics of HTTP traffic from the “HTTP/1.x” tab and the sampled HTTP requests with tracing in the “HTTP Requests” tab.&lt;/p&gt;
&lt;p&gt;As shown in Figure 7, there are three lists in the tab, each corresponding to a condition in the event sampling rules. Each list displays the traces that meet the pre-specified conditions. When you click on an item in the trace list, you can view the complete trace.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f7.png&#34; alt=&#34;Figure 7: Sampled HTTP requests within tracing context.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 7: Sampled HTTP requests within tracing context.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;When you click on an item in the trace list, you can quickly view the specified trace. In Figure 8, we can see that in the current service-related span, there is a tag with a number indicating how many HTTP events are related to that trace span.&lt;/p&gt;
&lt;p&gt;Since we are in a service mesh environment, each service involves interacting with Envoy. Therefore, the current span includes Envoy’s request and response information. Additionally, since the current service has both incoming and outgoing requests, there are events in the corresponding span.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f8.png&#34; alt=&#34;Figure 8: Events in the trace detail.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 8: Events in the trace detail.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;When the span is clicked, the details of the span will be displayed. If there are events in the current span, the relevant event information will be displayed on a time axis. As shown in Figure 9, there are a total of 6 related events in the current Span. Each event represents a data sample of an HTTP request/response. One of the events spans multiple time ranges, indicating a longer system call time. It may be due to a blocked system call, depending on the implementation details of the HTTP request in different languages. This can also help us query the possible causes of errors.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f9.png&#34; alt=&#34;Figure 9: Events in one trace span.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 9: Events in one trace span.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Finally, we can click on a specific event to see its complete information. As shown in Figure 10, it displays the sampling information of a request, including the SkyWalking trace context protocol contained in the request header from the HTTP raw data. The raw request data allows you to quickly re-request the request to solve any issues.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f10.png&#34; alt=&#34;Figure 10: The detail of the event.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 10: The detail of the event.&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&#34;zipkin&#34;&gt;Zipkin&lt;/h4&gt;
&lt;p&gt;Zipkin is one of the most widely used distributed tracing systems in the world. SkyWalking can function as an &lt;a href=&#34;https://zipkin.io/pages/extensions_choices.html&#34;&gt;alternative server&lt;/a&gt; to provide advanced features for Zipkin users. Here, we use this way to bring the feature into the Zipkin ecosystem out-of-box. The new events would also be treated as a kind of Zipkin’s tags and annotations.&lt;/p&gt;
&lt;p&gt;To add events to a Zipkin span, we need to do the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Split the start and end times of each event into two annotations with a canonical name.&lt;/li&gt;
&lt;li&gt;Add the sampled HTTP raw data from the event to the Zipkin span tags, using the same event name for corresponding purposes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Figures 11 and 12 show annotations and tags in the same span. In these figures, we can see that the span includes at least two events with the same event name and sequence suffix (e.g., “Start/Finished HTTP Request/Response Sampling-x” in the figure). Both events have separate timestamps to represent their relative times within the span. In the tags, the data content of the corresponding event is represented by the event name and sequence number, respectively.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f11.png&#34; alt=&#34;Figure 11: Event timestamp in the Zipkin span annotation.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 11: Event timestamp in the Zipkin span annotation.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f12.png&#34; alt=&#34;Figure 12: Event raw data in the Zipkin span tag.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 12: Event raw data in the Zipkin span tag.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;demo&#34;&gt;Demo&lt;/h2&gt;
&lt;p&gt;In this section, we demonstrate how to perform network profiling in a service mesh and complete metrics collection and HTTP raw data sampling. To follow along, you will need a running Kubernetes environment.&lt;/p&gt;
&lt;h3 id=&#34;deploy-skywalking-showcase&#34;&gt;Deploy SkyWalking Showcase&lt;/h3&gt;
&lt;p&gt;SkyWalking Showcase contains a complete set of example services and can be monitored using SkyWalking. For more information, please check the &lt;a href=&#34;https://skywalking.apache.org/docs/skywalking-showcase/next/readme/&#34;&gt;official documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this demo, we only deploy service, the latest released SkyWalking OAP, and UI.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#0086b3&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#008080&#34;&gt;SW_OAP_IMAGE&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;apache/skywalking-oap-server:9.3.0
&lt;span style=&#34;color:#0086b3&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#008080&#34;&gt;SW_UI_IMAGE&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;apache/skywalking-ui:9.3.0
&lt;span style=&#34;color:#0086b3&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#008080&#34;&gt;SW_ROVER_IMAGE&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;apache/skywalking-rover:0.4.0

&lt;span style=&#34;color:#0086b3&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#008080&#34;&gt;FEATURE_FLAGS&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;mesh-with-agent,single-node,elasticsearch,rover
make deploy.kubernetes
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After deployment is complete, please run the following script to open SkyWalking UI: http://localhost:8080/.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl port-forward svc/ui 8080:8080 --namespace default
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;start-network-profiling-task&#34;&gt;Start Network Profiling Task&lt;/h3&gt;
&lt;p&gt;Currently, we can select the specific instances that we wish to monitor by clicking the &lt;strong&gt;Data Plane&lt;/strong&gt; item in the &lt;strong&gt;Service Mesh&lt;/strong&gt; panel and the &lt;strong&gt;Service&lt;/strong&gt; item in the &lt;strong&gt;Kubernetes&lt;/strong&gt; panel.&lt;/p&gt;
&lt;p&gt;In figure 13, we have selected an instance with a list of tasks in the network profiling tab.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f13.png&#34; alt=&#34;Figure 13: Network Profiling tab in the Data Plane.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 13: Network Profiling tab in the Data Plane.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;When we click the Start button, as shown in Figure 14, we need to specify the sampling rules for the profiling task. The sampling rules consist of one or more rules, each of which is distinguished by a different URI regular expression. When the HTTP request URI matches the regular expression, the rule is used. If the URI regular expression is empty, the default rule is used. Using multiple rules can help us make different sampling configurations for different requests.&lt;/p&gt;
&lt;p&gt;Each rule has three parameters to determine if sampling is needed:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Minimal Request Duration (ms)&lt;/strong&gt;: requests with a response time exceeding the specified time will be sampled.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sampling response status code between 400 and 499&lt;/strong&gt;: all status codes in the range [400-499) will be sampled.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sampling response status code between 500 and 599&lt;/strong&gt;: all status codes in the range [500-599) will be sampled.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Once the sampling configuration is complete, we can create the task.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f14.png&#34; alt=&#34;Figure 14: Create network profiling task page.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 14: Create network profiling task page.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;done&#34;&gt;Done!&lt;/h3&gt;
&lt;p&gt;After a few seconds, you will see the process topology appear on the right side of the page.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f15.png&#34; alt=&#34;Figure 15&#34;&gt;&lt;/p&gt;
&lt;p&gt;When you click on the line between processes, you can view the data between the two processes, which is divided into three tabs:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;TCP&lt;/strong&gt;: displays TCP-related metrics.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HTTP/1.x&lt;/strong&gt;: displays metrics in the HTTP 1 protocol.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HTTP Requests&lt;/strong&gt;: displays the analyzed request and saves it to a list according to the sampling rule.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;f16.png&#34; alt=&#34;Figure 16: TCP metrics in a network profiling task.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 16: TCP metrics in a network profiling task.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f17.png&#34; alt=&#34;Figure 17: HTTP/1.x metrics in a network profiling task.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 17: HTTP/1.x metrics in a network profiling task.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f18.png&#34; alt=&#34;Figure 18: HTTP sampled requests in a network profiling task.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 18: HTTP sampled requests in a network profiling task.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this article, we detailed the overview of how to analyze the Layer 7 HTTP/1.x protocol in network analysis, and how to associate it with existing trace systems. This allows us to extend the scope of data we can observe from just user space to also include kernel-space data.&lt;/p&gt;
&lt;p&gt;In the future, we will delve further into the analysis of kernel data, such as collecting information on TCP packet size, transmission frequency, network card, and help on enhancing distributed tracing from another perspective.&lt;/p&gt;
&lt;h2 id=&#34;additional-resources&#34;&gt;Additional Resources&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/apache/skywalking&#34;&gt;SkyWalking Github Repo ›&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/apache/skywalking-rover&#34;&gt;SkyWalking Rover Github Repo ›&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://skywalking.apache.org/docs/skywalking-rover/next/readme/&#34;&gt;SkyWalking Rover Documentation ›&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://skywalking.apache.org/blog/diagnose-service-mesh-network-performance-with-ebpf/&#34;&gt;Diagnose Service Mesh Network Performance with eBPF blog post &amp;gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://skywalking.apache.org/docs/main/next/en/concepts-and-designs/profiling/&#34;&gt;SkyWalking Profiling Documentation &amp;gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://skywalking.apache.org/docs/main/next/en/api/x-process-propagation-headers-v3/&#34;&gt;SkyWalking Trace Context Propagation &amp;gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/openzipkin/b3-propagation&#34;&gt;Zipkin Trace Context Propagation &amp;gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.rfc-editor.org/rfc/rfc2068.html&#34;&gt;RFC - Hypertext Transfer Protocol – HTTP/1.1 &amp;gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Zh: 使用 eBPF 提升 HTTP 可观测性 - L7 指标和追踪</title>
      <link>/zh/ebpf-enhanced-http-observability-l7-metrics-and-tracing/</link>
      <pubDate>Thu, 12 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>/zh/ebpf-enhanced-http-observability-l7-metrics-and-tracing/</guid>
      <description>
        
        
        &lt;p&gt;&lt;img src=&#34;banner.jpg&#34; alt=&#34;banner&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;Apache SkyWalking 是一个开源应用性能管理系统，帮助用户收集和聚合日志、追踪、指标和事件，并在 UI 上显示。在&lt;a href=&#34;/zh/diagnose-service-mesh-network-performance-with-ebpf/&#34;&gt;上一篇文章&lt;/a&gt;中，我们介绍了如何使用 Apache SkyWalking Rover 分析服务网格环境中的网络性能问题。但是，在商业场景中，用户通常依靠成熟的第 7 层协议（如 HTTP）来进行系统之间的交互。在本文中，我们将讨论如何使用 eBPF 技术来分析第 7 层协议的性能瓶颈，以及如何使用网络采样来增强追踪系统。&lt;/p&gt;
&lt;p&gt;本文将演示如何使用 &lt;a href=&#34;https://github.com/apache/skywalking&#34;&gt;Apache SkyWalking&lt;/a&gt; 与 &lt;a href=&#34;https://ebpf.io/what-is-ebpf/&#34;&gt;eBPF&lt;/a&gt; 来增强 HTTP 可观察性中的指标和追踪。&lt;/p&gt;
&lt;h2 id=&#34;http-协议分析&#34;&gt;HTTP 协议分析&lt;/h2&gt;
&lt;p&gt;HTTP 是最常用的 7 层协议之一，通常用于为外部方提供服务和进行系统间通信。在下面的章节中，我们将展示如何识别和分析 HTTP/1.x 协议。&lt;/p&gt;
&lt;h3 id=&#34;协议识别&#34;&gt;协议识别&lt;/h3&gt;
&lt;p&gt;在 HTTP/1.x 中，客户端和服务器通过两端的单个文件描述符（File Descriptor）进行通信。图 1 显示了涉及以下步骤的通信过程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Connect/Accept：客户端与 HTTP 服务器建立连接，或者服务器接受客户端的连接。&lt;/li&gt;
&lt;li&gt;Read/Write（多次）：客户端或服务器读取和写入 HTTPS 请求和响应。单个请求 - 响应对在每边的同一连接内发生。&lt;/li&gt;
&lt;li&gt;Close：客户端和服务器关闭连接。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为了获取 HTTP 内容，必须从此过程的第二步读取它。根据 &lt;a href=&#34;http://rfc-editor.org/rfc/rfc2068.html&#34;&gt;RFC&lt;/a&gt; 定义，内容包含在 4 层协议的数据中，可以通过解析数据来获取。请求和响应对可以相关联，因为它们都在两端的同一连接内发生。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f1.png&#34; alt=&#34;图 1：HTTP 通信时间线。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 1：HTTP 通信时间线。&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;http-管线化&#34;&gt;HTTP 管线化&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/HTTP_pipelining&#34;&gt;HTTP 管线化（Pipelining）&lt;/a&gt;是 HTTP/1.1 的一个特性，允许在等待对应的响应的情况下在单个 TCP 连接上发送多个 HTTP 请求。这个特性很重要，因为它确保了服务器端的响应顺序必须与请求的顺序匹配。&lt;/p&gt;
&lt;p&gt;图 2 说明了这是如何工作的，考虑以下情况：HTTP 客户端向服务器发送多个请求，服务器通过按照请求的顺序发送 HTTP 响应来响应。这意味着客户端发送的第一个请求将收到服务器的第一个响应，第二个请求将收到第二个响应，以此类推。&lt;/p&gt;
&lt;p&gt;在设计 HTTP 解析时，我们应该遵循这个原则，将请求数据添加到列表中，并在解析响应时删除第一个项目。这可以确保响应按正确的顺序处理。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f2.png&#34; alt=&#34;图 2： HTTP/1.1 管道。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 2： HTTP/1.1 管道。&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;指标&#34;&gt;指标&lt;/h3&gt;
&lt;p&gt;根据前文提到的 HTTP 内容和流程拓扑图的识别，我们可以将这两者结合起来生成进程间的指标数据。&lt;/p&gt;
&lt;p&gt;图 3 显示了目前支持两个进程间分析的指标。基于 HTTP 请求和响应数据，可以分析以下数据：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;指标名称&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;单位&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;请求 CPM（Call Per Minute）&lt;/td&gt;
&lt;td&gt;计数器&lt;/td&gt;
&lt;td&gt;计数&lt;/td&gt;
&lt;td&gt;HTTP 请求计数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;响应状态 CPM (Call Per Minute)&lt;/td&gt;
&lt;td&gt;计数器&lt;/td&gt;
&lt;td&gt;计数&lt;/td&gt;
&lt;td&gt;每个 HTTP 响应状态码的计数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;请求包大小&lt;/td&gt;
&lt;td&gt;计数器 / 直方图&lt;/td&gt;
&lt;td&gt;字节&lt;/td&gt;
&lt;td&gt;请求包大小&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;响应包大小&lt;/td&gt;
&lt;td&gt;计数器 / 直方图&lt;/td&gt;
&lt;td&gt;字节&lt;/td&gt;
&lt;td&gt;响应包大小&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;客户端持续时间&lt;/td&gt;
&lt;td&gt;计数器 / 直方图&lt;/td&gt;
&lt;td&gt;毫秒&lt;/td&gt;
&lt;td&gt;客户端单个 HTTP 响应的持续时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;服务器持续时间&lt;/td&gt;
&lt;td&gt;计数器 / 直方图&lt;/td&gt;
&lt;td&gt;毫秒&lt;/td&gt;
&lt;td&gt;服务器端单个 HTTP 响应的持续时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img src=&#34;f3.png&#34; alt=&#34;图 3：进程到进程指标。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 3：进程到进程指标。&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;http-和追踪&#34;&gt;HTTP 和追踪&lt;/h2&gt;
&lt;p&gt;在 HTTP 过程中，如果我们能够从原始数据中解包 HTTP 请求和响应，就可以使用这些数据与现有的追踪系统进行关联。&lt;/p&gt;
&lt;h3 id=&#34;追踪上下文标识&#34;&gt;追踪上下文标识&lt;/h3&gt;
&lt;p&gt;为了追踪多个服务之间的请求流，追踪系统通常在请求进入服务时创建追踪上下文，并在请求 - 响应过程中将其传递给其他服务。例如，当 HTTP 请求发送到另一个服务器时，追踪上下文包含在请求头中。&lt;/p&gt;
&lt;p&gt;图 4 显示了 Wireshark 拦截的 HTTP 请求的原始内容。由 Zipkin Tracing 系统生成的追踪上下文信息可以通过头中的 “X-B3” 前缀进行标识。通过使用 eBPF 拦截 HTTP 头中的追踪上下文，可以将当前请求与追踪系统连接起来。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f4.png&#34; alt=&#34;图 4：Wireshark 中的 HTTP Header 视图。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 4：Wireshark 中的 HTTP Header 视图。&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;trace-事件&#34;&gt;Trace 事件&lt;/h3&gt;
&lt;p&gt;我们已经将事件这个概念加入了追踪中。事件可以附加到跨度上，并包含起始和结束时间、标签和摘要，允许我们将任何所需的信息附加到追踪中。&lt;/p&gt;
&lt;p&gt;在执行 eBPF 网络分析时，可以根据请求 - 响应数据生成两个事件。图 5 说明了在带分析的情况下执行 HTTP 请求时发生的情况。追踪系统生成追踪上下文信息并将其发送到请求中。当服务在内核中执行时，我们可以通过与内核空间中的请求 - 响应数据和执行时间交互，为相应的追踪跨度生成事件。&lt;/p&gt;
&lt;p&gt;以前，我们只能观察用户空间的执行状态。现在，通过结合追踪和 eBPF 技术，我们还可以在内核空间获取更多关于当前追踪的信息，如果我们在追踪 SDK 和代理中执行类似的操作，将对目标服务的性能产生较小的影响。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f5.png&#34; alt=&#34;图 5：分析 HTTP 请求和响应的逻辑视图。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 5：分析 HTTP 请求和响应的逻辑视图。&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;抽样&#34;&gt;抽样&lt;/h3&gt;
&lt;p&gt;该机制仅在满足特定条件时触发抽样。我们还提供了前 N 条追踪的列表，允许用户快速访问特定追踪的相关请求信息。为了帮助用户轻松识别和分析相关事件，我们提供了三种不同的抽样规则：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;慢速追踪&lt;/strong&gt;：当请求的响应时间超过指定阈值时触发抽样。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;响应状态 [400,500)&lt;/strong&gt;：当响应状态代码大于或等于 400 且小于 500 时触发抽样。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;响应状态 [500,600)&lt;/strong&gt;：当响应状态代码大于或等于 500 且小于 600 时触发抽样。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;此外，我们认识到分析时可能并不需要所有请求或响应的原始数据。例如，当试图识别性能问题时，用户可能更感兴趣于请求数据，而在解决错误时，他们可能更感兴趣于响应数据。因此，我们还提供了请求或响应事件的配置选项，允许用户指定要抽样的数据类型。&lt;/p&gt;
&lt;h2 id=&#34;服务网格中的分析&#34;&gt;服务网格中的分析&lt;/h2&gt;
&lt;p&gt;SkyWalking Rover 项目已经实现了 HTTP 协议的分析和追踪关联。当在服务网格环境中运行时它们的表现如何？&lt;/p&gt;
&lt;h3 id=&#34;部署&#34;&gt;部署&lt;/h3&gt;
&lt;p&gt;图 6 演示了 SkyWalking 和 SkyWalking Rover 在服务网格环境中的部署方式。SkyWalking Rover 作为一个 DaemonSet 部署在每台服务所在的机器上，并与 SkyWalking 后端集群通信。它会自动识别机器上的服务并向 SkyWalking 后端集群报告元数据信息。当出现新的网络分析任务时，SkyWalking Rover 会感知该任务并对指定的进程进行分析，在最终将数据报告回 SkyWalking 后端服务之前，收集和聚合网络数据。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f6.png&#34; alt=&#34;图 6：服务网格中的 SkyWalking rover 部署拓扑。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 6：服务网格中的 SkyWalking rover 部署拓扑。&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;追踪系统&#34;&gt;追踪系统&lt;/h3&gt;
&lt;p&gt;从版本 9.3.0 开始，SkyWalking 后端完全支持 Zipkin 服务器中的所有功能。因此，SkyWalking 后端可以收集来自 SkyWalking 和 Zipkin 协议的追踪。同样，SkyWalking Rover 可以在 SkyWalking 和 Zipkin 追踪系统中识别和分析追踪上下文。在接下来的两节中，网络分析结果将分别在 SkyWalking 和 Zipkin UI 中显示。&lt;/p&gt;
&lt;h4 id=&#34;skywalking&#34;&gt;SkyWalking&lt;/h4&gt;
&lt;p&gt;当 SkyWalking 执行网络分析时，与&lt;a href=&#34;/zh/diagnose-service-mesh-network-performance-with-ebpf/&#34;&gt;前文中&lt;/a&gt;的 TCP 指标类似，SkyWalking UI 会首先显示进程间的拓扑图。当打开代表进程间流量指标的线的仪表板时，您可以在 “HTTP/1.x” 选项卡中看到 HTTP 流量的指标，并在 “HTTP Requests” 选项卡中看到带追踪的抽样的 HTTP 请求。&lt;/p&gt;
&lt;p&gt;如图 7 所示，选项卡中有三个列表，每个列表对应事件抽样规则中的一个条件。每个列表显示符合预先规定条件的追踪。当您单击追踪列表中的一个项目时，就可以查看完整的追踪。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f7.png&#34; alt=&#34;图 7：Tracing 上下文中的采样 HTTP 请求。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 7：Tracing 上下文中的采样 HTTP 请求。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;当您单击追踪列表中的一个项目时，就可以快速查看指定的追踪。在图 8 中，我们可以看到在当前的服务相关的跨度中，有一个带有数字的标签，表示与该追踪跨度相关的 HTTP 事件数。&lt;/p&gt;
&lt;p&gt;由于我们在服务网格环境中，每个服务都涉及与 Envoy 交互。因此，当前的跨度包括 Envoy 的请求和响应信息。此外，由于当前的服务有传入和传出的请求，因此相应的跨度中有事件。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f8.png&#34; alt=&#34;图 8：Tracing 详细信息中的事件。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 8：Tracing 详细信息中的事件。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;当单击跨度时，将显示跨度的详细信息。如果当前跨度中有事件，则相关事件信息将在时间轴上显示。如图 9 所示，当前跨度中一共有 6 个相关事件。每个事件代表一个 HTTP 请求 / 响应的数据样本。其中一个事件跨越多个时间范围，表示较长的系统调用时间。这可能是由于系统调用被阻塞，具体取决于不同语言中的 HTTP 请求的实现细节。这也可以帮助我们查询错误的可能原因。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f9.png&#34; alt=&#34;图 9：一个 Tracing 范围内的事件。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 9：一个 Tracing 范围内的事件。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;最后，我们可以单击特定的事件查看它的完整信息。如图 10 所示，它显示了一个请求的抽样信息，包括从 HTTP 原始数据中的请求头中包含的 SkyWalking 追踪上下文协议。原始请求数据允许您快速重新请求以解决任何问题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f10.png&#34; alt=&#34;图 10：事件的详细信息。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 10：事件的详细信息。&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&#34;zipkin&#34;&gt;Zipkin&lt;/h4&gt;
&lt;p&gt;Zipkin 是世界上广泛使用的分布式追踪系统。SkyWalking 可以作为&lt;a href=&#34;https://zipkin.io/pages/extensions_choices.html&#34;&gt;替代服务器&lt;/a&gt;，提供高级功能。在这里，我们使用这种方式将功能无缝集成到 Zipkin 生态系统中。新事件也将被视为 Zipkin 的标签和注释的一种。&lt;/p&gt;
&lt;p&gt;为 Zipkin 跨度添加事件，需要执行以下操作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;将每个事件的开始时间和结束时间分别拆分为两个具有规范名称的注释。&lt;/li&gt;
&lt;li&gt;将抽样的 HTTP 原始数据从事件添加到 Zipkin 跨度标签中，使用相同的事件名称用于相应的目的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;图 11 和图 12 显示了同一跨度中的注释和标签。在这些图中，我们可以看到跨度包含至少两个具有相同事件名称和序列后缀的事件（例如，图中的 “Start/Finished HTTP Request/Response Sampling-x”）。这两个事件均具有单独的时间戳，用于表示其在跨度内的相对时间。在标签中，对应事件的数据内容分别由事件名称和序列号表示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f11.png&#34; alt=&#34;图 11：Zipkin span 注释中的事件时间戳。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 11：Zipkin span 注释中的事件时间戳。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f12.png&#34; alt=&#34;图 12：Zipkin span 标签中的事件原始数据。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 12：Zipkin span 标签中的事件原始数据。&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;演示&#34;&gt;演示&lt;/h2&gt;
&lt;p&gt;在本节中，我们将演示如何在服务网格中执行网络分析，并完成指标收集和 HTTP 原始数据抽样。要进行操作，您需要一个运行中的 Kubernetes 环境。&lt;/p&gt;
&lt;h3 id=&#34;部署-skywalking-showcase&#34;&gt;部署 SkyWalking Showcase&lt;/h3&gt;
&lt;p&gt;SkyWalking Showcase 包含一套完整的示例服务，可以使用 SkyWalking 进行监控。有关详细信息，请参阅&lt;a href=&#34;https://skywalking.apache.org/docs/skywalking-showcase/next/readme/&#34;&gt;官方文档&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在本演示中，我们只部署了服务、最新发布的 SkyWalking OAP 和 UI。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#0086b3&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#008080&#34;&gt;SW_OAP_IMAGE&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;apache/skywalking-oap-server:9.3.0
&lt;span style=&#34;color:#0086b3&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#008080&#34;&gt;SW_UI_IMAGE&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;apache/skywalking-ui:9.3.0
&lt;span style=&#34;color:#0086b3&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#008080&#34;&gt;SW_ROVER_IMAGE&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;apache/skywalking-rover:0.4.0

&lt;span style=&#34;color:#0086b3&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#008080&#34;&gt;FEATURE_FLAGS&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;=&lt;/span&gt;mesh-with-agent,single-node,elasticsearch,rover
make deploy.kubernetes
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;部署完成后，运行下面的脚本启动 SkyWalking UI：&lt;a href=&#34;http://localhost:8080/&#34;&gt;http://localhost:8080/&lt;/a&gt;。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl port-forward svc/ui 8080:8080 --namespace default
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;启动网络分析任务&#34;&gt;启动网络分析任务&lt;/h3&gt;
&lt;p&gt;目前，我们可以通过单击服务网格面板中的 &lt;strong&gt;Data Plane&lt;/strong&gt; 项和 &lt;strong&gt;Kubernetes&lt;/strong&gt; 面板中的 &lt;strong&gt;Service&lt;/strong&gt; 项来选择要监视的特定实例。&lt;/p&gt;
&lt;p&gt;在图 13 中，我们已在网络分析选项卡中选择了一个具有任务列表的实例。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f13.png&#34; alt=&#34;图 13：数据平面中的网络分析选项卡。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 13：数据平面中的网络分析选项卡。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;当我们单击 “开始” 按钮时，如图 14 所示，我们需要为分析任务指定抽样规则。抽样规则由一个或多个规则组成，每个规则都由不同的 URI 正则表达式区分。当 HTTP 请求的 URI 与正则表达式匹配时，将使用该规则。如果 URI 正则表达式为空，则使用默认规则。使用多个规则可以帮助我们为不同的请求配置不同的抽样配置。&lt;/p&gt;
&lt;p&gt;每个规则都有三个参数来确定是否需要抽样：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;最小请求持续时间（毫秒）&lt;/strong&gt;：响应时间超过指定时间的请求将被抽样。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;在 400 和 499 之间的抽样响应状态代码&lt;/strong&gt;：范围 [400-499) 中的所有状态代码将被抽样。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;在 500 和 599 之间的抽样响应状态代码&lt;/strong&gt;：范围 [500-599) 中的所有状态码将被抽样。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;抽样配置完成后，我们就可以创建任务了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f14.png&#34; alt=&#34;图 14：创建网络分析任务页面。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 14：创建网络分析任务页面。&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;完成&#34;&gt;完成&lt;/h3&gt;
&lt;p&gt;几秒钟后，你会看到页面的右侧出现进程拓扑结构。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f15.png&#34; alt=&#34;图 15：网络分析任务中的流程拓扑。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 15：网络分析任务中的流程拓扑。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;当您单击进程之间的线时，您可以查看两个过程之间的数据，它被分为三个选项卡：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;TCP&lt;/strong&gt;：显示与 TCP 相关的指标。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HTTP/1.x&lt;/strong&gt;：显示 HTTP 1 协议中的指标。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HTTP 请求&lt;/strong&gt;：显示已分析的请求，并根据抽样规则保存到列表中。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;f16.png&#34; alt=&#34;图 16：网络分析任务中的 TCP 指标。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 16：网络分析任务中的 TCP 指标。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f17.png&#34; alt=&#34;图 17：网络分析任务中的 HTTP/1.x 指标。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 17：网络分析任务中的 HTTP/1.x 指标。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f18.png&#34; alt=&#34;图 18：网络分析任务中的 HTTP 采样请求。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 18：网络分析任务中的 HTTP 采样请求。&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;在本文中，我们详细介绍了如何在网络分析中分析 7 层 HTTP/1.x 协议，以及如何将其与现有追踪系统相关联。这使我们能够将我们能够观察到的数据从用户空间扩展到内核空间数据。&lt;/p&gt;
&lt;p&gt;在未来，我们将进一步探究内核数据的分析，例如收集 TCP 包大小、传输频率、网卡等信息，并从另一个角度提升分布式追踪。&lt;/p&gt;
&lt;h2 id=&#34;其他资源&#34;&gt;其他资源&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/apache/skywalking&#34;&gt;SkyWalking Github Repo ›&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/apache/skywalking-rover&#34;&gt;SkyWalking Rover Github Repo ›&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://skywalking.apache.org/docs/skywalking-rover/v0.3.0/readme/&#34;&gt;SkyWalking Rover Documentation ›&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://skywalking.apache.org/blog/diagnose-service-mesh-network-performance-with-ebpf/&#34;&gt;Diagnose Service Mesh Network Performance with eBPF blog post &amp;gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://skywalking.apache.org/docs/main/next/en/concepts-and-designs/profiling/&#34;&gt;SkyWalking Profiling Documentation &amp;gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://skywalking.apache.org/docs/main/next/en/api/x-process-propagation-headers-v3/&#34;&gt;SkyWalking Trace Context Propagation &amp;gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/openzipkin/b3-propagation&#34;&gt;Zipkin Trace Context Propagation &amp;gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.rfc-editor.org/rfc/rfc2068.html&#34;&gt;RFC - Hypertext Transfer Protocol – HTTP/1.1 &amp;gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Blog: Boost Root Cause Analysis Quickly With SkyWalking’s New Trace-Metrics Association Feature</title>
      <link>/blog/boost-root-cause-analysis-quickly-with-skywalking-new-trace-metrics-association-feature/</link>
      <pubDate>Mon, 19 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/boost-root-cause-analysis-quickly-with-skywalking-new-trace-metrics-association-feature/</guid>
      <description>
        
        
        &lt;p&gt;&lt;img src=&#34;banner.jpg&#34; alt=&#34;Banner&#34;&gt;&lt;/p&gt;
&lt;p&gt;Observability for modern distributed applications work is critical for understanding how they behave under a variety of conditions and for troubleshooting and resolving issues when they arise. Traces, metrics, and logs are regarded as fundamental parts of the observability stack. Traces are the footprints of distributed system executions, meanwhile, metrics measure system performance with numbers in the timeline. Essentially, they measure the performance from two dimensions. Being able to quickly visualize the connection between traces and corresponding metrics makes it possible to quickly diagnose which process flows are correlated to potentially pathological behavior. This powerful new capability is now &lt;a href=&#34;https://skywalking.apache.org/events/release-apache-skywalking-apm-9.3.0/&#34;&gt;available in SkyWalking 9.3.0&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The SkyWalking project started only with tracing, with a focus on 100% sampling-based metrics and topology analysis since 2018. When users face anomaly trends of time-series metrics, like a peak on the line chart, or histogram shows a larger gap between p95 and p95, the immediate question is, why is this happening? One of SkyWalking&amp;rsquo;s latest features, the &lt;strong&gt;trace-metric association&lt;/strong&gt;, makes it much easier to answer that question and to address the root cause.&lt;/p&gt;
&lt;h2 id=&#34;how-are-metrics-generated&#34;&gt;How Are Metrics Generated?&lt;/h2&gt;
&lt;p&gt;SkyWalking provides three ways to calculate metrics:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Metrics built from trace spans, depending on the span’s layer, kind, and tags.&lt;/li&gt;
&lt;li&gt;Metrics extracted from logs—a kind of keyword and tags-based metrics extraction.&lt;/li&gt;
&lt;li&gt;Metrics reported from mature and mainstream metrics/meter systems, such as OpenTelemetry, Prometheus, and Zabbix.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Tracing tracks the processes of requests between an application&amp;rsquo;s services. Most systems that generate traffic and performance-related metrics also generate tracing data, either from server-side trace-based aggregations or through client SDKs.&lt;/p&gt;
&lt;h2 id=&#34;use-skywalking-to-reduce-the-traditional-cost-of-trace-indexing&#34;&gt;Use SkyWalking to Reduce the Traditional Cost of Trace Indexing&lt;/h2&gt;
&lt;p&gt;Tracing data and visualization are critical troubleshooting tools for both developers and operators alike because of how helpful they are in locating issue boundaries. But, because it has traditionally been difficult to find associations between metrics and traces, teams have added increasingly more tags into the spans, and search through various combinations. This trend of increased instrumentation and searching has required increased infrastructure investment to support this kind of search. SkyWalking&amp;rsquo;s metrics and tracing association capabilities can help reduce the cost of indexing and searching that data.&lt;/p&gt;
&lt;h2 id=&#34;find-the-associated-trace&#34;&gt;Find the Associated Trace&lt;/h2&gt;
&lt;p&gt;When looking for association between metrics and traces, the kind of metrics we&amp;rsquo;re dealing with determines their relationships to traces. Let’s review the standard request &lt;em&gt;rate, error, and duration (RED)&lt;/em&gt; metrics to see how it works.&lt;/p&gt;
&lt;h3 id=&#34;success-rate-metrics&#34;&gt;Success Rate Metrics&lt;/h3&gt;
&lt;p&gt;The success rate is determined by the return code, RPC response code, or exceptions of the process. When the success rate decreases, looking for errors in the traces of this service or pod are the first place to look to find clues.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f1.jpg&#34; alt=&#34;Figure 1: The success rate graph from SkyWalking&amp;rsquo;s 9.3.0 dashboard with the option to view related traces at a particular time.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 1: The success rate graph from SkyWalking&amp;rsquo;s 9.3.0 dashboard with the option to view related traces at a particular time.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Drilling down from the peak of the success rate, SkyWalking lists all traces and their error status that were collected in this particular minute (Figure 2):&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f2.jpg&#34; alt=&#34;Figure 2: SkyWalking shows related traces with an error status.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 2: SkyWalking shows related traces with an error status.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Requests to &lt;em&gt;/test&lt;/em&gt; can be located from the trace, and the span’s tag indicates a 404 response code of the HTTP request.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f3.jpg&#34; alt=&#34;Figure 3: A detail view of a request to http://frontend/test showing that the URI doesn&amp;rsquo;t exist.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 3: A detail view of a request to http://frontend/test showing that the URI doesn&amp;rsquo;t exist.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;By looking at the trace data, it becomes immediately clear that the drop in success rate is caused by requests to a nonexistent URI.&lt;/p&gt;
&lt;h3 id=&#34;average-response-time&#34;&gt;Average Response Time&lt;/h3&gt;
&lt;p&gt;The average response time metric provides a general overview of service performance. When average response time is unstable, this usually means that the system is facing serious performance impacts.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f4.jpg&#34; alt=&#34;Figure 4: SkyWalking&amp;rsquo;s query UI for searching for related traces showing traces for requests that exceed a particular duration threshold.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 4: SkyWalking&amp;rsquo;s query UI for searching for related traces showing traces for requests that exceed a particular duration threshold.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;When you drill down from this metric, this query condition (Figure 4) will reveal the slowest traces of the service in this specific minute. Notice, at least 168ms is added as a condition automatically, to avoid scanning a large number of rows in the Database.&lt;/p&gt;
&lt;h3 id=&#34;apdex&#34;&gt;Apdex&lt;/h3&gt;
&lt;p&gt;Apdex—the Application Performance Index—is a measure of response time based against a set threshold. It measures the ratio of satisfactory response times to unsatisfactory response times (Figure 5). The response time is measured from an asset request to completed delivery back to the requestor.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f5.jpg&#34; alt=&#34;Figure 5: The Apdex formula&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 5: The Apdex formula&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A user defines a response time tolerating threshold &lt;em&gt;T&lt;/em&gt;. All responses handled in &lt;em&gt;T&lt;/em&gt; or less time satisfy the user.&lt;/p&gt;
&lt;p&gt;For example, if &lt;em&gt;T&lt;/em&gt; is 1.2 seconds and a response completes in 0.5 seconds, then the user is satisfied. All responses greater than 1.2 seconds dissatisfy the user. Responses greater than 4.8 seconds frustrate the user.&lt;/p&gt;
&lt;p&gt;When the Apdex score decreases, we need to find related traces from two perspectives: slow traces and error status traces. SkyWalking&amp;rsquo;s new related tracing features offers a quick way to view both (Figure 6) directly from the Apdex graph.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f6.jpg&#34; alt=&#34;Figure 6: Show slow trace and error status traces from the Apdex graph&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 6: Show slow trace and error status traces from the Apdex graph&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;service-response-time&#34;&gt;Service Response Time&lt;/h3&gt;
&lt;p&gt;Percentile MetricThe percentile graph (Figure 7) provides p50, p75, p90, p95, and p99 latency ranks to measure the long-tail issues of service performance.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f7.jpg&#34; alt=&#34;Figure 7: The service response time percentile graph helps to highlight long-tail issues of service performance.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 7: The service response time percentile graph helps to highlight long-tail issues of service performance.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This percentile graph shows a typical long-tail issue. P99 latency is four times slower than the P95. When we use the association, we see the traces with latency between P95 - P99 and P99 - Infinity.&lt;/p&gt;
&lt;p&gt;The traces of requests causing this kind of long-tail phenomena are automatically listing from there.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f8.jpg&#34; alt=&#34;Figure 8: Query parameters to search for traces based on latency.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 8: Query parameters to search for traces based on latency.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;are-more-associations-available&#34;&gt;Are More Associations Available?&lt;/h2&gt;
&lt;p&gt;SkyWalking provides more than just associations between between traces and metrics to help you find possible causal relationships and to avoid looking for the proverbial needle in a haystack.&lt;/p&gt;
&lt;p&gt;Currently, SkyWalking 9.3.0 offers two more associations: &lt;strong&gt;metric-to-metric&lt;/strong&gt; associations and &lt;strong&gt;event-to-metric&lt;/strong&gt; associations.&lt;/p&gt;
&lt;h3 id=&#34;metric-to-metric-associations&#34;&gt;Metric-to-metric Associations&lt;/h3&gt;
&lt;p&gt;There are dozens of metrics on the dashboard—which is great for getting a complete picture of application behavior. During a typical performance issue, the peaks of multiple metrics are affected simultaneously. But, trying to correlate peaks across all of these graphs can be difficult&amp;hellip;&lt;/p&gt;
&lt;p&gt;Now in SkyWalking 9.3.0, when you click the peak of one graph, the pop-out box lets you see associated metrics.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f9.jpg&#34; alt=&#34;Figure 9: SkyWalking&amp;rsquo;s option to view associated metrics.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 9: SkyWalking&amp;rsquo;s option to view associated metrics.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;When you choose that option, all associated metrics graphs will show axis pointers (the dotted vertical lines) in all associated graphs like in Figure 10. This makes it easier to correlate the peaks in different graphs with each other. Often, these correlated peaks with have the same root cause.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f10.jpg&#34; alt=&#34;Figure 10: Axis pointers (vertical dotted lines) show associations between peaks across multiple metrics graphs.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 10: Axis pointers (vertical dotted lines) show associations between peaks across multiple metrics graphs.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;event-to-metric-associations&#34;&gt;Event-to-Metric Associations&lt;/h3&gt;
&lt;p&gt;SkyWalking provides the event concept to associate possible service performance impacted by the infrastructure, such as new deployment even from k8s. Or, the anomaly had been detected by alerting or integrated AIOps engine.&lt;/p&gt;
&lt;p&gt;The event to metrics association is also automatically, it could cover the time range of the event on the metric graphs(blue areas). If the area of event and peaks are matched, most likely this event covered this anomaly.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f11.jpg&#34; alt=&#34;Figure 11: SkyWalking&amp;rsquo;s event to metric association view.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 11: SkyWalking&amp;rsquo;s event to metric association view.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;skywalking-makes-it-easier-and-faster-to-find-root-causes&#34;&gt;SkyWalking Makes it Easier and Faster to Find Root Causes&lt;/h2&gt;
&lt;p&gt;SkyWalking now makes it easy to find associations between metrics, events, and traces, ultimately making it possible to identify root causes and fix problems fast. The associations we&amp;rsquo;ve discussed in this article are available out-of-box in the SkyWalking 9.3.0 release.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f12.jpg&#34; alt=&#34;Figure 12: Just click on the dots to see related traces and metrics associations.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Figure 12: Just click on the dots to see related traces and metrics associations.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Click the dots on any metric graph, and you will see a &lt;em&gt;View Related Traces&lt;/em&gt; item pop-out if this metric has logical mapping traces.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this blog, we took a look at the newly-added association feature between metrics and traces. With this new visualization, it&amp;rsquo;s now much easier to find key traces to identify root cause of issues.Associations in SkyWalking can go even deeper. Associations from metrics to traces is not the end of diagnosing system bottleneck. In the next post, we will introduce an eBPF powered trace enhancement where you’ll be able to see HTTP request and response details associated with tracing spans from network profiling. Stay tuned.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Zh: SkyWalking 推出 trace-metric 关联功能助力快速根源问题排查</title>
      <link>/zh/boost-root-cause-analysis-quickly-with-skywalking-new-trace-metrics-association-feature/</link>
      <pubDate>Mon, 19 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>/zh/boost-root-cause-analysis-quickly-with-skywalking-new-trace-metrics-association-feature/</guid>
      <description>
        
        
        &lt;p&gt;&lt;img src=&#34;banner.jpg&#34; alt=&#34;Banner&#34;&gt;&lt;/p&gt;
&lt;p&gt;现代分布式应用程序工作的可观测性对于了解它们在各种条件下的行为方式以及在出现问题时进行故障排除和解决至关重要。追踪、指标和日志被视为可观测性堆栈的基本部分。Trace 是分布式系统执行的足迹，而 metric 则是用时间轴上的数字衡量系统性能。本质上，它们从两个维度衡量性能。能够快速可视化追踪和相应指标之间的联系，可以快速诊断哪些流程与潜在的异常相关。&lt;a href=&#34;https://skywalking.apache.org/events/release-apache-skywalking-apm-9.3.0/&#34;&gt;SkyWalking 9.3.0&lt;/a&gt; 现在提供了这一强大的新功能。&lt;/p&gt;
&lt;p&gt;SkyWalking 项目从 tracing 开始，从 2018 年开始专注于 100% 基于采样的指标和拓扑分析。当用户面对时间序列指标的异常趋势时，比如折线图上的峰值，或者直方图显示 p95 和 p95 之间的差距较大，直接的问题是，为什么会出现这种情况？SkyWalking 的最新功能之一，trace 与 metric 关联，使得回答这个问题和解决根本原因更加容易。&lt;/p&gt;
&lt;h2 id=&#34;指标是如何生成的&#34;&gt;指标是如何生成的？&lt;/h2&gt;
&lt;p&gt;SkyWalking 提供了三种计算指标的方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;根据追踪跨度构建的指标，具体取决于跨度的层、种类和标签。&lt;/li&gt;
&lt;li&gt;从日志中提取指标—— 一种基于关键词和标签的指标提取。&lt;/li&gt;
&lt;li&gt;从成熟和主流的指标 / 仪表系统报告的指标，例如 OpenTelemetry、Prometheus 和 Zabbix。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Tracing 追踪应用程序服务之间的请求过程。大多数生成流量和性能相关指标的系统也会生成追踪数据，这些数据来自服务器端基于追踪的聚合或通过客户端 SDK。&lt;/p&gt;
&lt;h2 id=&#34;使用-skywalking-降低追踪索引的传统成本&#34;&gt;使用 SkyWalking 降低追踪索引的传统成本&lt;/h2&gt;
&lt;p&gt;Trace 数据和可视化对于开发人员和运维人员来说都是至关重要的故障排除工具，因为它们在定位问题边界方面非常有帮助。但是，由于传统上很难找到指标和痕迹之间的关联，团队已经将越来越多的标签添加到跨度中，并搜索各种组合。这种增加仪器和搜索的趋势需要增加基础设施投资来支持这种搜索。SkyWalking 的指标和追踪关联功能有助于降低索引和搜索该数据的成本。&lt;/p&gt;
&lt;h2 id=&#34;查找关联的-trace&#34;&gt;查找关联的 trace&lt;/h2&gt;
&lt;p&gt;在寻找 metric 和 trace 之间的关联时，我们处理的指标类型决定了它们与 trace 的关系。让我们回顾一下标准请求*率、错误和持续时间（RED）*指标，看看它是如何工作的。&lt;/p&gt;
&lt;h3 id=&#34;成功率指标&#34;&gt;成功率指标&lt;/h3&gt;
&lt;p&gt;成功率由返回码、RPC 响应码或进程异常决定。当成功率下降时，在这个服务或 Pod 的 trace 中寻找错误是第一个寻找线索的地方。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f1.jpg&#34; alt=&#34;图 1：SkyWalking 9.3.0 仪表板的成功率图表，带有在特定时间查看相关追踪的选项。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 1：SkyWalking 9.3.0 仪表板的成功率图表，带有在特定时间查看相关 trace 的选项。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;从成功率的峰值向下探索，SkyWalking 列出了在这一特定分钟内收集的所有 trace 及其错误状态（图 2）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f2.jpg&#34; alt=&#34;图 2：SkyWalking 显示具有错误状态的相关追踪。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 2：SkyWalking 显示具有错误状态的相关追踪。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;可以从 trace 中找到对 &lt;code&gt;/test&lt;/code&gt; 的请求，并且 span 的标记指示 HTTP 请求的 404 响应代码。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f3.jpg&#34; alt=&#34;图 3：显示 URI 不存在的 http://frontend/test 请求的详细视图。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 3：显示 URI 不存在的 http://frontend/test 请求的详细视图。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;通过查看 trace 数据，很明显成功率的下降是由对不存在的 URI 的请求引起的。&lt;/p&gt;
&lt;h3 id=&#34;平均响应时间&#34;&gt;平均响应时间&lt;/h3&gt;
&lt;p&gt;平均响应时间指标提供了服务性能的一般概览。当平均响应时间不稳定时，这通常意味着系统面临严重的性能影响。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f4.jpg&#34; alt=&#34;图 4：SkyWalking 用于搜索相关追踪的查询 UI，显示超过特定持续时间阈值的请求的追踪。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 4：SkyWalking 用于搜索相关 trace 的查询 UI，显示超过特定持续时间阈值的请求的 trace。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;当您从该指标向下探索时，该查询条件（图 4）将揭示该特定分钟内服务的最慢 trace。请注意，至少 168ms 作为条件自动添加，以避免扫描数据库中的大量行。&lt;/p&gt;
&lt;h3 id=&#34;apdex&#34;&gt;Apdex&lt;/h3&gt;
&lt;p&gt;Apdex（应用程序性能指数）是根据设定的阈值衡量响应时间的指标。它测量令人满意的响应时间与不令人满意的响应时间的比率（图 5）。响应时间是从资产请求到完成交付回请求者的时间。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f5.jpg&#34; alt=&#34;图 5：Apdex 公式&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 5：Apdex 公式&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;用户定义响应时间容忍阈值 &lt;em&gt;T&lt;/em&gt;。在 &lt;em&gt;T&lt;/em&gt; 或更短时间内处理的所有响应都使用户满意。&lt;/p&gt;
&lt;p&gt;例如，如果 &lt;em&gt;T&lt;/em&gt; 为 1.2 秒，响应在 0.5 秒内完成，则用户会感到满意。所有大于 1.2 秒的响应都会让用户不满意。超过 4.8 秒的响应会让用户感到沮丧。&lt;/p&gt;
&lt;p&gt;当 Apdex 分数下降时，我们需要从两个角度寻找相关的 trace：慢速和错误状态的 trace。SkyWalking 的新相关追踪功能提供了一种直接从 Apdex 图表查看两者（图 6）的快速方法。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f6.jpg&#34; alt=&#34;图 6：显示 Apdex 图中的慢速追踪和错误状态追踪&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 6：显示 Apdex 图中的慢速 trace 和错误状态 trace&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;服务响应时间&#34;&gt;服务响应时间&lt;/h3&gt;
&lt;p&gt;百分位指标百分位图（图 7）提供 p50、p75、p90、p95 和 p99 延迟排名，以衡量服务性能的长尾问题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f7.jpg&#34; alt=&#34;图 7：服务响应时间百分位图有助于突出服务性能的长尾问题。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 7：服务响应时间百分位图有助于突出服务性能的长尾问题。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;这个百分位数图显示了一个典型的长尾问题。P99 延迟比 P95 慢四倍。当我们使用关联时，我们会看到 P95 - P99 和 P99 - Infinity 之间具有延迟的 trace。&lt;/p&gt;
&lt;p&gt;造成这种长尾现象的请求 trace，就是从那里自动列出来的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f8.jpg&#34; alt=&#34;图 8：用于根据延迟搜索追踪的查询参数。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 8：用于根据延迟搜索 trace 的查询参数。&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;是否有更多关联可用&#34;&gt;是否有更多关联可用？&lt;/h2&gt;
&lt;p&gt;SkyWalking 提供的不仅仅是 trace 和 metric 之间的关联，还可以帮助您找到可能的因果关系，避免大海捞针。&lt;/p&gt;
&lt;p&gt;目前，SkyWalking 9.3.0 提供了两种关联：&lt;strong&gt;metric-to-metric&lt;/strong&gt; 关联和 &lt;strong&gt;event-to-metric&lt;/strong&gt; 关联。&lt;/p&gt;
&lt;h3 id=&#34;metric-to-metric-关联&#34;&gt;Metric-to-metric 关联&lt;/h3&gt;
&lt;p&gt;仪表板上有许多指标 —— 这对于全面了解应用程序行为非常有用。在典型的性能问题中，多个指标的峰值会同时受到影响。但是，尝试关联所有这些图表中的峰值可能很困难……&lt;/p&gt;
&lt;p&gt;现在在 SkyWalking 9.3.0 中，当你点击一个图表的峰值时，弹出框可以让你看到相关的指标。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f9.jpg&#34; alt=&#34;图 9：SkyWalking 用于查看相关指标的选项。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 9：SkyWalking 用于查看相关指标的选项。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;当您选择该选项时，所有关联的指标图表将在所有关联的图表中显示轴指针（垂直虚线），如图 10 所示。这使得将不同图表中的峰值相互关联起来变得更加容易。通常，这些相关的峰值具有相同的根本原因。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f10.jpg&#34; alt=&#34;图 10：轴指针（垂直虚线）显示多个指标图中峰值之间的关联。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 10：轴指针（垂直虚线）显示多个指标图中峰值之间的关联。&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;event-to-metric-关联&#34;&gt;Event-to-metric 关联&lt;/h3&gt;
&lt;p&gt;SkyWalking 提供了事件概念来关联可能受基础设施影响的服务性能，例如来自 Kubernetes 的新部署。或者，已通过警报或集成 AIOps 引擎检测到异常。&lt;/p&gt;
&lt;p&gt;事件到指标的关联也是自动的，它可以覆盖指标图上事件的时间范围（蓝色区域）。如果事件区域和峰值匹配，则很可能该事件覆盖了该异常。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f11.jpg&#34; alt=&#34;图 11：SkyWalking 的事件与指标关联视图。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 11：SkyWalking 的事件与指标关联视图。&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;skywalking-使查找根本原因变得更加容易和快速&#34;&gt;SkyWalking 使查找根本原因变得更加容易和快速&lt;/h2&gt;
&lt;p&gt;SkyWalking 现在可以轻松找到指标、事件和追踪之间的关联，最终可以确定根本原因并快速解决问题。我们在本文中讨论的关联在 SkyWalking 9.3.0 版本中开箱即用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;f12.jpg&#34; alt=&#34;图 12：只需单击圆点即可查看相关追踪和指标关联。&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图 12：只需单击圆点即可查看相关 trace 和 metric 关联。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;单击任何指标图上的点，如果该指标具有逻辑映射，您将看到一个&lt;em&gt;查看相关 trace&lt;/em&gt; 弹出窗口。&lt;/p&gt;
&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;
&lt;p&gt;在这篇博客中，我们了解了 metric 和 trace 之间新增的关联功能。有了这个新的可视化，现在可以更容易地找到关键 trace 来识别问题的根本原因。SkyWalking 中的关联可以更深入。从 metric 到 trace 的关联并不是诊断系统瓶颈的终点。在下一篇文章中，我们将介绍 eBPF 支持的追踪增强功能，您将看到与网络分析中的追踪跨度相关的 HTTP 请求和响应详细信息。敬请关注。&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
