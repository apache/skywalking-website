[{"body":"","excerpt":"","ref":"/tags/infrastructure-monitoring/","title":"Infrastructure Monitoring"},{"body":" Origin: Tetrate.io blog\n Background Apache SkyWalking\u0026ndash; the APM tool for distributed systems\u0026ndash; has historically focused on providing observability around tracing and metrics, but service performance is often affected by the host. The newest release, SkyWalking 8.4.0, introduces a new feature for monitoring virtual machines. Users can easily detect possible problems from the dashboard\u0026ndash; for example, when CPU usage is overloaded, when there’s not enough memory or disk space, or when the network status is unhealthy, etc.\nHow it works SkyWalking leverages Prometheus and OpenTelemetry for collecting metrics data as we did for Istio control panel metrics; Prometheus is mature and widely used, and we expect to see increased adoption of the new CNCF project, OpenTelemetry. The SkyWalking OAP Server receives these metrics data of OpenCensus format from OpenTelemetry. The process is as follows:\n Prometheus Node Exporter collects metrics data from the VMs. OpenTelemetry Collector fetches metrics from Node Exporters via Prometheus Receiver, and pushes metrics to SkyWalking OAP Server via the OpenCensus GRPC Exporter. The SkyWalking OAP Server parses the expression with MAL to filter/calculate/aggregate and store the results. The expression rules are in /config/otel-oc-rules/vm.yaml. We can now see the data on the SkyWalking WebUI dashboard.  What to monitor SkyWalking provides default monitoring metrics including:\n CPU Usage (%) Memory RAM Usage (MB) Memory Swap Usage (MB) CPU Average Used CPU Load Memory RAM (total/available/used MB) Memory Swap (total/free MB) File System Mount point Usage (%) Disk R/W (KB/s) Network Bandwidth Usage (receive/transmit KB/s) Network Status (tcp_curr_estab/tcp_tw/tcp_alloc/sockets_used/udp_inuse) File fd Allocated  The following is how it looks when we monitor Linux:\nHow to use To enable this feature, we need to install Prometheus Node Exporter and OpenTelemetry Collector and activate the VM monitoring rules in SkyWalking OAP Server.\nInstall Prometheus Node Exporter wget https://github.com/prometheus/node_exporter/releases/download/v1.0.1/node_exporter-1.0.1.linux-amd64.tar.gz tar xvfz node_exporter-1.0.1.linux-amd64.tar.gz cd node_exporter-1.0.1.linux-amd64 ./node_exporter In linux Node Exporter exposes metrics on port 9100 by default. When it is running, we can get the metrics from the /metrics endpoint. Use a web browser or command curl to verify.\ncurl http://localhost:9100/metrics We should see all the metrics from the output like:\n# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\u0026#34;0\u0026#34;} 7.7777e-05 go_gc_duration_seconds{quantile=\u0026#34;0.25\u0026#34;} 0.000113756 go_gc_duration_seconds{quantile=\u0026#34;0.5\u0026#34;} 0.000127199 go_gc_duration_seconds{quantile=\u0026#34;0.75\u0026#34;} 0.000147778 go_gc_duration_seconds{quantile=\u0026#34;1\u0026#34;} 0.000371894 go_gc_duration_seconds_sum 0.292994058 go_gc_duration_seconds_count 2029 ... Note: We only need to install Node Exporter, rather than Prometheus server. If you want to get more information about Prometheus Node Exporter see: https://prometheus.io/docs/guides/node-exporter/\nInstall OpenTelemetry Collector We can quickly install a OpenTelemetry Collector instance by using docker-compose with the following steps:\n Create a directory to store the configuration files, like /usr/local/otel. Create docker-compose.yaml and otel-collector-config.yaml in this directory represented below:  docker-compose.yaml\nversion: \u0026#34;2\u0026#34; services: # Collector otel-collector: # Specify the image to start the container from image: otel/opentelemetry-collector:0.19.0 # Set the otel-collector configfile  command: [\u0026#34;--config=/etc/otel-collector-config.yaml\u0026#34;] # Mapping the configfile to host directory volumes: - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml ports: - \u0026#34;13133:13133\u0026#34; # health_check extension - \u0026#34;55678\u0026#34; # OpenCensus receiver otel-collector-config.yaml\nextensions: health_check: # A receiver is how data gets into the OpenTelemetry Collector receivers: # Set Prometheus Receiver to collects metrics from targets # It’s supports the full set of Prometheus configuration prometheus: config: scrape_configs: - job_name: \u0026#39;otel-collector\u0026#39; scrape_interval: 10s static_configs: # Replace the IP to your VMs‘s IP which has installed Node Exporter - targets: [ \u0026#39;vm1:9100\u0026#39; ] - targets: [ \u0026#39;vm2:9100\u0026#39; ] - targets: [ ‘vm3:9100\u0026#39; ] processors: batch: # An exporter is how data gets sent to different systems/back-ends exporters: # Exports metrics via gRPC using OpenCensus format opencensus: endpoint: \u0026#34;docker.for.mac.host.internal:11800\u0026#34; # The OAP Server address insecure: true logging: logLevel: debug service: pipelines: metrics: receivers: [prometheus] processors: [batch] exporters: [logging, opencensus] extensions: [health_check] In this directory use command docker-compose to start up the container:  docker-compose up -d After the container is up and running, you should see metrics already exported in the logs:\n... Metric #165 Descriptor: -\u0026gt; Name: node_network_receive_compressed_total -\u0026gt; Description: Network device statistic receive_compressed. -\u0026gt; Unit: -\u0026gt; DataType: DoubleSum -\u0026gt; IsMonotonic: true -\u0026gt; AggregationTemporality: AGGREGATION_TEMPORALITY_CUMULATIVE DoubleDataPoints #0 Data point labels: -\u0026gt; device: ens4 StartTime: 1612234754364000000 Timestamp: 1612235563448000000 Value: 0.000000 DoubleDataPoints #1 Data point labels: -\u0026gt; device: lo StartTime: 1612234754364000000 Timestamp: 1612235563448000000 Value: 0.000000 ... If you want to get more information about OpenTelemetry Collector see: https://opentelemetry.io/docs/collector/\nSet up SkyWalking OAP Server To activate the oc handler and vm relevant rules, set your environment variables:\nSW_OTEL_RECEIVER=default SW_OTEL_RECEIVER_ENABLED_OC_RULES=vm Note: If there are other rules already activated , you can add vm with use , as a separator.\nSW_OTEL_RECEIVER_ENABLED_OC_RULES=vm,oap Start the SkyWalking OAP Server.\nDone! After all of the above steps are completed, check out the SkyWalking WebUI. Dashboard VM provides the default metrics of all observed virtual machines. Note: Clear the browser local cache if you used it to access deployments of previous SkyWalking versions.\nAdditional Resources  Read more about the SkyWalking 8.4 release highlights. Get more SkyWalking updates on Twitter.  ","excerpt":"Origin: Tetrate.io blog\n Background Apache SkyWalking\u0026ndash; the APM tool for distributed …","ref":"/blog/2021-02-07-infrastructure-monitoring/","title":"SkyWalking 8.4 provides infrastructure monitoring"},{"body":"","excerpt":"","ref":"/tags/","title":"Tags"},{"body":" Origin: Tetrate.io blog\n The Apache SkyWalking team today announced the 8.4 release is generally available. This release fills the gap between all previous versions of SkyWalking and the logging domain area. The release also advances SkyWalking’s capabilities for infrastructure observability, starting with virtual machine monitoring.\nBackground SkyWalking has historically focused on the tracing and metrics fields of observability. As its features for tracing, metrics and service level monitoring have become more and more powerful and stable, the SkyWalking team has started to explore new scenarios covered by observability. Because service performance is reflected in the logs, and is highly impacted by the infrastructure on which it runs, SkyWalking brings these two fields into the 8.4 release. This release blog briefly introduces the two new features as well as some other notable changes.\nLogs Metrics, tracing, and logging are considered the three pillars of observability [1]. SkyWalking had the full features of metrics and tracing prior to 8.4; today, as 8.4 is released, the last piece of the jigsaw is now in place.\nFigure 1: Logs Collected By SkyWalking\nFigure 2: Logs Collected By SkyWalking\nThe Java agent firstly provides SDKs to enhance the widely-used logging frameworks, log4j (1.x and 2.x) [2] and logback [3], and send the logs to the SkyWalking backend (OAP). The latter is able to collect logs from wherever the protocol is implemented. This is not a big deal, but when it comes to the correlation between logs and traces, the traditional solution is to print the trace IDs in the logs, and pick the IDs in the error logs to query the related traces. SkyWalking just simplifies the workflow by correlating the logs and traces natively. Navigating between traces and their related logs is as simple as clicking a button.\nFigure 3: Correlation Between Logs and Traces\nInfrastructure Monitoring SkyWalking is known as an application performance monitoring tool. One of the most important factors that impacts the application’s performance is the infrastructure on which the application runs. In the 8.4 release, we added the monitoring metrics of virtual machines into the dashboard.\nFigure 4: VM Metrics\nFundamental metrics such as CPU Used, Memory Used, Disk Read / Write and Network Usage are available on the dashboard. And as usual, those metrics are also available to be configured as alarm triggers when needed.\nDynamic Configurations at Agent Side Dynamic configuration at the backend side has long existed in SkyWalking for several versions. Now, it finally comes to the agent side! Prior to 8.4, you’d have to restart the target services when you modify some configuration items of the agent \u0026ndash; for instance, sampling rate (agent side), ignorable endpoint paths, etc. Now, say goodbye to rebooting. Modifying configurations is not the only usage of the dynamic configuration mechanism. The latter gives countless possibilities to the agent side in terms of dynamic behaviours, e.g. enabling / disabling plugins, enabling / disabling the whole agent, etc. Just imagine!\nGrouped Service Topology This enhancement is from the UI. SkyWalking backend supports grouping the services by user-defined dimensions. In a real world use case, the services are usually grouped by business group or department. When a developer opens the topology map, out of hundreds of services, he or she may just want to focus on the services in charge. The grouped service topology comes to the rescue: one can now choose to display only services belonging to a specified group.\nFigure 5: Grouped Service Topology\nOther Notable Enhancements  Agent: resolves domain names to look up backend service IP addresses. Backend: meter receiver supports meter analysis language (MAL). Backend: several CVE fixes. Backend: supports Envoy {AccessLog,Metrics}Service API V3 and adopts MAL.  Links  [1] https://peter.bourgon.org/blog/2017/02/21/metrics-tracing-and-logging.html [2] https://logging.apache.org/log4j/2.x/ [3] http://logback.qos.ch  Additional Resources  Read more about the SkyWalking 8.4 release highlights. Get more SkyWalking updates on Twitter.  ","excerpt":"Origin: Tetrate.io blog\n The Apache SkyWalking team today announced the 8.4 release is generally …","ref":"/blog/skywalking8-4-release/","title":"Apache SkyWalking 8.4: Logs, VM Monitoring, and Dynamic Configurations at Agent Side"},{"body":"","excerpt":"","ref":"/tags/logs/","title":"Logs"},{"body":"","excerpt":"","ref":"/tags/release-blog/","title":"Release Blog"},{"body":"SkyWalking 8.4.0 is released. Go to downloads page to find release tars. Changes by Version\nProject  Incompatible with previous releases when use H2/MySQL/TiDB storage options, due to support multiple alarm rules triggered for one entity. Chore: adapt create_source_release.sh to make it runnable on Linux. Add package to .proto files, prevent polluting top-level namespace in some languages; The OAP server supports previous agent releases, whereas the previous OAP server (\u0026lt;=8.3.0) won\u0026rsquo;t recognize newer agents since this version (\u0026gt;= 8.4.0). Add ElasticSearch 7.10 to test matrix and verify it works. Replace Apache RAT with skywalking-eyes to check license headers. Set up test of Envoy ALS / MetricsService under Istio 1.8.2 to verify Envoy V3 protocol Test: fix flaky E2E test of Kafka.  Java Agent  The operation name of quartz-scheduler plugin, has been changed as the quartz-scheduler/${className} format. Fix jdk-http and okhttp-3.x plugin did not overwrite the old trace header. Add interceptors of method(analyze, searchScroll, clearScroll, searchTemplate and deleteByQuery) for elasticsearch-6.x-plugin. Fix the unexpected RunningContext recreation in the Tomcat plugin. Fix the potential NPE when trace_sql_parameters is enabled. Update byte-buddy to 1.10.19. Fix thrift plugin trace link broken when intermediate service does not mount agent Fix thrift plugin collects wrong args when the method without parameter. Fix DataCarrier\u0026rsquo;s org.apache.skywalking.apm.commons.datacarrier.buffer.Buffer implementation isn\u0026rsquo;t activated in IF_POSSIBLE mode. Fix ArrayBlockingQueueBuffer\u0026rsquo;s useless IF_POSSIBLE mode list Support building gRPC TLS channel but CA file is not required. Add witness method mechanism in the agent plugin core. Add Dolphinscheduler plugin definition. Make sampling still works when the trace ignores plug-in activation. Fix mssql-plugin occur ClassCastException when call the method of return generate key. The operation name of dubbo and dubbo-2.7.x-plugin, has been changed as the groupValue/className.methodName format Fix bug that rocketmq-plugin set the wrong tag. Fix duplicated EnhancedInstance interface added. Fix thread leaks caused by the elasticsearch-6.x-plugin plugin. Support reading segmentId and spanId with toolkit. Fix RestTemplate plugin recording url tag with wrong port Support collecting logs and forwarding through gRPC. Support config agent.sample_n_per_3_secs can be changed in the runtime. Support config agent.ignore_suffix can be changed in the runtime. Support DNS periodic resolving mechanism to update backend service. Support config agent.trace.ignore_path can be changed in the runtime. Added support for transmitting logback 1.x and log4j 2.x formatted \u0026amp; un-formatted messages via gPRC  OAP-Backend  Make meter receiver support MAL. Support influxDB connection response format option. Fix some error when use JSON as influxDB response format. Support Kafka MirrorMaker 2.0 to replicate topics between Kafka clusters. Add the rule name field to alarm record storage entity as a part of ID, to support multiple alarm rules triggered for one entity. The scope id has been removed from the ID. Fix MAL concurrent execution issues. Fix group name can\u0026rsquo;t be queried in the GraphQL. Fix potential gRPC connection leak(not closed) for the channels among OAP instances. Filter OAP instances(unassigned in booting stage) of the empty IP in KubernetesCoordinator. Add component ID for Python aiohttp plugin requester and server. Fix H2 in-memory database table missing issues Add component ID for Python pyramid plugin server. Add component ID for NodeJS Axios plugin. Fix searchService method error in storage-influxdb-plugin. Add JavaScript component ID. Fix CVE of UninstrumentedGateways in Dynamic Configuration activation. Improve query performance in storage-influxdb-plugin. Fix the uuid field in GRPCConfigWatcherRegister is not updated. Support Envoy {AccessLog,Metrics}Service API V3. Adopt the MAL in Envoy metrics service analyzer. Fix the priority setting doesn\u0026rsquo;t work of the ALS analyzers. Fix bug that endpoint-name-grouping.yml is not customizable in Dockerized case. Fix bug that istio version metric type on UI template mismatches the otel rule. Improve ReadWriteSafeCache concurrency read-write performance Fix bug that if use JSON as InfluxDB.ResponseFormat then NumberFormatException maybe occur. Fix timeBucket not taking effect in EqualsAndHashCode annotation of some relationship metrics. Fix SharingServerConfig's propertie is not correct in the application.yml, contextPath -\u0026gt; restConnextPath. Istio control plane: remove redundant metrics and polish panel layout. Fix bug endpoint name grouping not work due to setting service name and endpoint name out of order. Fix receiver analysis error count metrics. Log collecting and query implementation. Support Alarm to feishu. Add the implementation of ConfigurationDiscovery on the OAP side. Fix bug in parseInternalErrorCode where some error codes are never reached. OAL supports multiple values when as numeric. Add node information from the Openensus proto to the labels of the samples, to support the identification of the source of the Metric data. Fix bug that the same sample name in one MAL expression caused IllegalArgumentException in Analyzer.analyse. Add the text analyzer for querying log in the es storage. Chore: Remove duplicate codes in Envoy ALS handler. Remove the strict rule of OAL disable statement parameter. Fix a legal metric query adoption bug. Don\u0026rsquo;t support global level metric query. Add VM MAL and ui-template configration, support Prometheus node-exporter VM metrics that pushed from OpenTelemetry-collector. Remove unused log query parameters.  UI  Fix un-removed tags in trace query. Fix unexpected metrics name on single value component. Don\u0026rsquo;t allow negative value as the refresh period. Fix style issue in trace table view. Separation Log and Dashboard selector data to avoid conflicts. Fix trace instance selector bug. Fix Unnecessary sidebar in tooltips for charts. Refactor dashboard query in a common script. Implement refreshing data for topology by updating date. Implement group selector in the topology. Fix all as default parameter for services selector. Add icon for Python aiohttp plugin. Add icon for Python pyramid plugin. Fix topology render all services nodes when groups changed. Fix rk-footer utc input\u0026rsquo;s width. Update rk-icon and rewrite rk-header svg tags with rk-icon. Add icon for http type. Fix rk-footer utc without local storage. Sort group names in the topology. Add logo for Dolphinscheduler. Fix dashboard wrong instance. Add a legend for the topology. Update the condition of unhealthy cube. Fix: use icons to replace buttons for task list in profile. Fix: support = in the tag value in the trace query page. Add envoy proxy component logo. Chore: set up license-eye to check license headers and add missing license headers. Fix prop for instances-survey and endpoints-survey. Fix envoy icon in topology. Implement the service logs on UI. Change the flask icon to light version for a better view of topology dark theme. Implement viewing logs on trace page. Fix update props of date component. Fix query conditions for logs. Fix style of selectors to word wrap. Fix logs time. Fix search ui for logs.  Documentation  Update the documents of backend fetcher and self observability about the latest configurations. Add documents about the group name of service. Update docs about the latest UI. Update the document of backend trace sampling with the latest configuration. Update kafka plugin support version to 2.6.1. Add FAQ about Fix compiling on Mac M1 chip.  All issues and pull requests are here\n","excerpt":"SkyWalking 8.4.0 is released. Go to downloads page to find release tars. Changes by Version\nProject …","ref":"/events/release-apache-skywalking-apm-8-4-0/","title":"Release Apache SkyWalking APM 8.4.0"},{"body":"Background The verifier is an important part of the next generation End-to-End Testing framework (NGE2E), which is responsible for verifying whether the actual output satisfies the expected template.\nDesign Thinking We will implement the verifier with Go template, plus some enhancements. Firstly, users need to write a Go template file with provided functions and actions to describe how the expected data looks like. Then the verifer renders the template with the actual data object. Finally, the verifier compares the rendered output with the actual data. If the rendered output is not the same with the actual output, it means the actual data is inconsist with the expected data. Otherwise, it means the actual data match the expected data. On failure, the verifier will also print out what are different between expected and actual data.\nBranches / Actions The verifier inherits all the actions from the standard Go template, such as if, with, range, etc. In addition, we also provide some custom actions to satisfy our own needs.\nList Elements Match contains checks if the actual list contains elements that match the given template.\nExamples:\nmetrics: {{- contains .metrics }} - name: {{ notEmpty .name }} id: {{ notEmpty .id }} value: {{ gt .value 0 }} {{- end }} It means that the list metrics must contain an element whose name and id are not empty, and value is greater than 0.\nmetrics: {{- contains .metrics }} - name: p95 value: {{ gt .value 0 }} - name: p99 value: {{ gt .value 0 }} {{- end }} This means that the list metrics must contain an element named p95 with a value greater than 0, and an element named p95 with a value greater than 0. Besides the two element, the list metrics may or may not have other random elements.\nFunctions Users can use these provided functions in the template to describe the expected data.\nNot Empty notEmpty checks if the string s is empty.\nExample:\nid: {{ notEmpty .id }} Regexp match regexp checks if string s matches the regular expression pattern.\nExamples:\nlabel: {{ regexp .label \u0026#34;ratings.*\u0026#34; }} Base64 b64enc s returns the Base64 encoded string of s.\nExamples:\nid: {{ b64enc \u0026#34;User\u0026#34; }}.static-suffix # this evalutes the base64 encoded string of \u0026#34;User\u0026#34;, concatenated with a static suffix \u0026#34;.static-suffix\u0026#34; Result:\nid: VXNlcg==.static-suffix Full Example Here is an example of expected data:\n# expected.data.yaml nodes: - id: {{ b64enc \u0026#34;User\u0026#34; }}.0 name: User type: USER isReal: false - id: {{ b64enc \u0026#34;Your_ApplicationName\u0026#34; }}.1 name: Your_ApplicationName type: Tomcat isReal: true - id: {{ $h2ID := (index .nodes 2).id }}{{ notEmpty $h2ID }} # We assert that nodes[2].id is not empty and save it to variable `h2ID` for later use name: localhost:-1 type: H2 isReal: false calls: - id: {{ notEmpty (index .calls 0).id }} source: {{ b64enc \u0026#34;Your_ApplicationName\u0026#34; }}.1 target: {{ $h2ID }} # We use the previously assigned variable `h2Id` to asert that the `target` is equal to the `id` of the nodes[2] detectPoints: - CLIENT - id: {{ b64enc \u0026#34;User\u0026#34; }}.0-{{ b64enc \u0026#34;Your_ApplicationName\u0026#34; }}.1 source: {{ b64enc \u0026#34;User\u0026#34; }}.0 target: {{ b64enc \u0026#34;Your_ApplicationName\u0026#34; }}.1 detectPoints: - SERVER will validate this data:\n# actual.data.yaml nodes: - id: VXNlcg==.0 name: User type: USER isReal: false - id: WW91cl9BcHBsaWNhdGlvbk5hbWU=.1 name: Your_ApplicationName type: Tomcat isReal: true - id: bG9jYWxob3N0Oi0x.0 name: localhost:-1 type: H2 isReal: false calls: - id: WW91cl9BcHBsaWNhdGlvbk5hbWU=.1-bG9jYWxob3N0Oi0x.0 source: WW91cl9BcHBsaWNhdGlvbk5hbWU=.1 detectPoints: - CLIENT target: bG9jYWxob3N0Oi0x.0 - id: VXNlcg==.0-WW91cl9BcHBsaWNhdGlvbk5hbWU=.1 source: VXNlcg==.0 detectPoints: - SERVER target: WW91cl9BcHBsaWNhdGlvbk5hbWU=.1 # expected.data.yaml metrics: {{- contains .metrics }} - name: {{ notEmpty .name }} id: {{ notEmpty .id }} value: {{ gt .value 0 }} {{- end }} will validate this data:\n# actual.data.yaml metrics: - name: business-zone::projectA id: YnVzaW5lc3Mtem9uZTo6cHJvamVjdEE=.1 value: 1 - name: system::load balancer1 id: c3lzdGVtOjpsb2FkIGJhbGFuY2VyMQ==.1 value: 0 - name: system::load balancer2 id: c3lzdGVtOjpsb2FkIGJhbGFuY2VyMg==.1 value: 0 and will report an error when validating this data, because there is no element with a value greater than 0:\n# actual.data.yaml metrics: - name: business-zone::projectA id: YnVzaW5lc3Mtem9uZTo6cHJvamVjdEE=.1 value: 0 - name: system::load balancer1 id: c3lzdGVtOjpsb2FkIGJhbGFuY2VyMQ==.1 value: 0 - name: system::load balancer2 id: c3lzdGVtOjpsb2FkIGJhbGFuY2VyMg==.1 value: 0 The contains does an unordered list verification, in order to do list verifications including orders, you can simply use the basic ruls like this:\n# expected.data.yaml metrics: - name: p99 value: {{ gt (index .metrics 0).value 0 }} - name: p95 value: {{ gt (index .metrics 1).value 0 }} which expects the actual metrics list to be exactly ordered, with first element named p99 and value greater 0, second element named p95 and value greater 0.\n","excerpt":"Background The verifier is an important part of the next generation End-to-End Testing framework …","ref":"/blog/2021-02-01-e2e-verifier-design/","title":"[Design] The Verifier of NGE2E"},{"body":"","excerpt":"","ref":"/tags/testing/","title":"Testing"},{"body":"SkyWalking Cloud on Kubernetes 0.2.0 is released. Go to downloads page to find release tars.\n Introduce custom metrics adapter to SkyWalking OAP cluster for Kubernetes HPA autoscaling. Add RBAC files and service account to support Kubernetes coordination. Add default and validation webhooks to operator controllers. Add UI CRD to deploy skywalking UI server. Add Fetcher CRD to fetch metrics from other telemetry system, for example, Prometheus.  ","excerpt":"SkyWalking Cloud on Kubernetes 0.2.0 is released. Go to downloads page to find release tars. …","ref":"/events/release-apache-skywalking-cloud-on-kubernetes-0-2-0/","title":"Release Apache SkyWalking Cloud on Kubernetes 0.2.0"},{"body":"Apache SkyWalking is an open source APM for distributed system, Apache Software Foundation top-level project.\nAt Jan. 11th, 2021, we noticed the Tencent Cloud Service, Tencent Service Watcher - TSW, for first time. Due to the similar short name, which SkyWalking is also called SW in the community, we connected with the service team of Tencent Cloud, and kindly asked.\nThey used to replay, TSW is purely developed by Tencent team itself, which doesn\u0026rsquo;t have any code dependency on SkyWalking.. We didn\u0026rsquo;t push harder.\nBut one week later, Jan 18th, 2021, our V.P., Sheng got the report again from Haoyang SkyWalking PMC member, through WeChat DM(direct message),. He provided complete evidence to prove TSW actually re-distributed the SkyWalking\u0026rsquo;s Java agent. We keep one copy of their agent\u0026rsquo;s distribution(at Jan. 18th), you could be downloaded here.\nSome typically evidences are here\n  ServiceManager is copied and package-name changed in the TSW\u0026rsquo;s agent.   ContextManager is copied and ackage-name changed in the TSW\u0026rsquo;s agent.   At the same time, we checked their tsw-client-package.zip, it didn\u0026rsquo;t include the SkyWalking\u0026rsquo;s LICENSE and NOTICE. Also, they didn\u0026rsquo;t mention TSW agent is the re-ditribution SkyWalking on their website.\nWith all above information, we had enough reason to believe, from the tech perspective, they were violating the Apache 2.0 License.\nFrom the 18th Jan., 2021, we sent mail [Apache 2.0 License Violation] Tencent Cloud TSW service doesn't follow the Apache 2.0 License to brief the SkyWalking PMC, and took the following actions to connect with Tencent.\n Made direct call to Tencent Open Source Office. Connected with Tencent Cloud TVP program committee, as Sheng Wu(Our VP) is a Tencent Cloud TVP. Talked with the Tencent Cloud team lead.  In all above channels, we provided the evidences of coyp-redistribution hebaviors, requested them to revaluate their statements on the website, and follow the License\u0026rsquo;s requirements.\nResolution At Jan. 19th night, UTC+8, 2021. We received response from the Tencent cloud team. They admited their violation behaviors, and did following changes\n  Tencent Cloud TSW service page states, the agent is the fork version(re-distribution) of Apache SkyWalking agent.   TSW agent distributions include the SkyWalking\u0026rsquo;s License and NOTICE. Below is the screenshot, you could download from their product page. We keep a copy of their Jan. 19th 2021 at here.   We have updated the status to the PMC mail list. This license violation issue has been resolved for now.\nThe SkyWalking community and program management committee will keep our eyes on Tencent TSW. ","excerpt":"Apache SkyWalking is an open source APM for distributed system, Apache Software Foundation top-level …","ref":"/blog/2021-01-23-tencent-cloud-violates-aplv2/","title":"[Resolved][License Issue] Tencent Cloud TSW service violates the Apache 2.0 License when using SkyWalking."},{"body":" 第一节：开篇介绍 第二节：数字游戏（Number Game） 第三节：社区原则（Community “Principles”） 第四节：基金会原则（For public good） 第五节：一些不太好的事情   ","excerpt":" 第一节：开篇介绍 第二节：数字游戏（Number Game） 第三节：社区原则（Community “Principles”） 第四节：基金会原则（For public good） 第五节：一些不太 …","ref":"/zh/2021-01-21-educate-community/","title":"[视频] 开放原子开源基金会2020年度峰会 - Educate community Over Support community"},{"body":"","excerpt":"","ref":"/zh_tags/conference/","title":"Conference"},{"body":"","excerpt":"","ref":"/zh_tags/video/","title":"Video"},{"body":"","excerpt":"","ref":"/zh_tags/","title":"Zh_tags"},{"body":"Elastic announced their license change, Upcoming licensing changes to Elasticsearch and Kibana.\n We are moving our Apache 2.0-licensed source code in Elasticsearch and Kibana to be dual licensed under Server Side Public License (SSPL) and the Elastic License, giving users the choice of which license to apply. This license change ensures our community and customers have free and open access to use, modify, redistribute, and collaborate on the code. It also protects our continued investment in developing products that we distribute for free and in the open by restricting cloud service providers from offering Elasticsearch and Kibana as a service without contributing back. This will apply to all maintained branches of these two products and will take place before our upcoming 7.11 release. Our releases will continue to be under the Elastic License as they have been for the last three years.\n Also, they provide the FAQ page for more information about the impact for the users, developers, and vendors.\nIn the perspective of Apache Software Foundation, SSPL has been confirmed as a Catalog X LICENSE(https://www.apache.org/legal/resolved.html#category-x), which means hard-dependency as a part of the core is not allowed. With that, we can\u0026rsquo;t only focus on it anymore. We need to consider other storage options. Right now, we still have InfluxDB, TiDB, H2 server still in Apache 2.0 licensed. Right now, we still have InfluxDB, TiDB, H2 server as storage options still in Apache 2.0 licensed.\nAs one optional plugin, we need to focus on the client driver license. Right now, we are only using ElasticSearch 7.5.0 and 6.3.2 drivers, which are both Apache 2.0 licensed. So, we are safe. For further upgrade, here is their announcement. They answer these typical cases in the FAQ page.\n  I build a SaaS application using Elasticsearch as the backend, how does this affect me?\n This source code license change should not affect you - you can use our default distribution or develop applications on top of it for free, under the Elastic License. This source-available license does not contain any copyleft provisions and the default functionality is free of charge. For a specific example, you can see our response to a question around this at Magento.\nOur users still could use, redistribute, sale the products/services, based on SkyWalking, even they are using self hosting Elastic Search unmodified server.\n  I\u0026rsquo;m using Elasticsearch via APIs, how does this change affect me?\n This change does not affect how you use client libraries to access Elasticsearch. Our client libraries remain licensed under Apache 2.0, with the exception of our Java High Level Rest Client (Java HLRC). The Java HLRC has dependencies on the core of Elasticsearch, and as a result this client library will be licensed under the Elastic License. Over time, we will eliminate this dependency and move the Java HLRC to be licensed under Apache 2.0. Until that time, for the avoidance of doubt, we do not consider using the Java HLRC as a client library in development of an application or library used to access Elasticsearch to constitute a derivative work under the Elastic License, and this will not have any impact on how you license the source code of your application using this client library or how you distribute it.\nThe client driver license incompatible issue will exist, we can\u0026rsquo;t upgrade the driver(s) until they release the Apache 2.0 licensed driver jars. But users are still safe to upgrade the drivers by themselves.\n Apache SkyWalking will discuss the further actions here. If you have any question, welcome to ask. In the later 2021, we will begin to invest the posibility of creating SkyWalking\u0026rsquo;s observability database implementation.\n","excerpt":"Elastic announced their license change, Upcoming licensing changes to Elasticsearch and Kibana.\n We …","ref":"/blog/2021-01-17-elastic-change-license/","title":"Response to Elastic 2021 License Change"},{"body":"SkyWalking Client JS 0.3.0 is released. Go to downloads page to find release tars.\n Support tracing starting at the browser. Add traceSDKInternal SDK for tracing SDK internal RPC. Add detailMode SDK for tracing http method and url as tags in spans. Fix conditions of http status.  ","excerpt":"SkyWalking Client JS 0.3.0 is released. Go to downloads page to find release tars.\n Support tracing …","ref":"/events/release-apache-skywalking-client-js-0-3-0/","title":"Release Apache SkyWalking Client JS 0.3.0"},{"body":"SkyWalking Eyes 0.1.0 is released. Go to downloads page to find release tars.\n License Header  Add check and fix command. check results can be reported to pull request as comments. fix suggestions can be filed on pull request as edit suggestions.    ","excerpt":"SkyWalking Eyes 0.1.0 is released. Go to downloads page to find release tars.\n License Header  Add …","ref":"/events/release-apache-skywalking-eyes-0-1-0/","title":"Release Apache SkyWalking Eyes 0.1.0"},{"body":"SkyWalking NodeJS 0.1.0 is released. Go to downloads page to find release tars.\n Initialize project core codes. Built-in http/https plugin. Express plugin. Axios plugin.  ","excerpt":"SkyWalking NodeJS 0.1.0 is released. Go to downloads page to find release tars.\n Initialize project …","ref":"/events/release-apache-skywalking-nodejs-0-1-0/","title":"Release Apache SkyWalking for NodeJS 0.1.0"},{"body":"SkyWalking Python 0.5.0 is released. Go to downloads page to find release tars.\n  New plugins\n Pyramid Plugin (#102) AioHttp Plugin (#101) Sanic Plugin (#91)    API and enhancements\n @trace decorator supports async functions Supports async task context Optimized path trace ignore Moved exception check to Span.__exit__ Moved Method \u0026amp; Url tags before requests    Fixes:\n BaseExceptions not recorded as errors Allow pending data to send before exit sw_flask general exceptions handled Make skywalking logging Non-global    Chores and tests\n Make tests really run on specified Python version Deprecate 3.5 as it\u0026rsquo;s EOL    ","excerpt":"SkyWalking Python 0.5.0 is released. Go to downloads page to find release tars.\n  New plugins …","ref":"/events/release-apache-skywalking-python-0-5-0/","title":"Release Apache SkyWalking Python 0.5.0"},{"body":"Apache SkyWalking is an open source APM for distributed system. Provide tracing, service mesh observability, metrics analysis, alarm and visualization.\nJust 11 months ago, on Jan. 20th, 2020, SkyWalking hit the 200 contributors mark. With the growth of the project and the community, SkyWalking now includes over 20 sub(ecosystem) projects covering multiple language agents and service mesh, integration with mature open source projects, like Prometheus, Spring(Sleuth), hundreds of libraries to support all tracing/metrics/logs fields. In the past year, the number of contributors grows super astoundingly , and all its metrics point to its community vibrancy. Many corporate titans are already using SkyWalking in a large-scale production environment, including, Alibaba, Huawei, Baidu, Tencent, etc.\nRecently, our SkyWalking main repository overs 300 contributors.\nOur website has thousands of views from most countries in the world every week.\nAlthough we know that, the metrics like GitHub stars and the numbers of open users and contributors, are not a determinant of vibrancy, they do show the trend, we are very proud to share the increased numbers here, too.\nWe double those numbers and are honored with the development of our community.\nThank you, all of our contributors. Not just these 300 contributors of the main repository, or nearly 400 contributors in all repositories, counted by GitHub. There are countless people contributing codes to SkyWalking\u0026rsquo;s subprojects, ecosystem projects, and private fork versions; writing blogs and guidances, translating documents, books, and presentations; setting up learning sessions for new users; convincing friends to join the community as end-users, contributors, even committers. Companies behinds those contributors support their employees to work with the community to provide feedback and contribute the improvements and features upstream. Conference organizers share the stages with speakers from the SkyWalking community.\nSkyWalking can’t make this happen without your help. You made this community extraordinary.\nAt this crazy distributed computing and cloud native age, we as a community could make DEV, OPS, and SRE teams\u0026rsquo; work easier by locating the issue(s) in the haystack quicker than before, like why we named the project as SkyWalking, we will have a clear site line when you stand on the glass bridge Skywalk at Grand Canyon West.\n 376 Contributors counted by GitHub account are following. Dec. 22st, 2020. Generated by a tool deveoped by Yousa\n 1095071913 50168383 Ahoo-Wang AirTrioa AlexanderWert AlseinX Ax1an BFergerson BZFYS CharlesMaster ChaunceyLin5152 CommissarXia Cvimer Doublemine ElderJames EvanLjp FatihErdem FeynmanZhou Fine0830 FingerLiu Gallardot GerryYuan HackerRookie Heguoya Hen1ng Humbertzhang IanCao IluckySi Indifer J-Cod3r JaredTan95 Jargon96 Jijun JohnNiang Jozdortraz Jtrust Just-maple KangZhiDong LazyLei LiWenGu Liu-XinYuan Miss-you O-ll-O Patrick0308 QHWG67 Qiliang RandyAbernethy RedzRedz Runrioter SataQiu ScienJus SevenPointOld ShaoHans Shikugawa SoberChina SummerOfServenteen TJ666 TerrellChen TheRealHaui TinyAllen TomMD ViberW Videl WALL-E WeihanLi WildWolfBang WillemJiang Wooo0 XhangUeiJong Xlinlin YczYanchengzhe YoungHu YunaiV ZhHong ZhuoSiChen ZS-Oliver a198720 a526672351 acurtain adamni135 adermxzs adriancole aeolusheath agile6v aix3 aiyanbo ajanthan alexkarezin alonelaval amogege amwyyyy arugal ascrutae augustowebd bai-yang beckhampu beckjin beiwangnull bigflybrother bostin brucewu-fly c1ay candyleer carlvine500 carrypann cheenursn cheetah012 chenpengfei chenvista chess-equality chestarss chidaodezhongsheng chopin-d clevertension clk1st cngdkxw codeglzhang codelipenghui coder-yqj coki230 coolbeevip crystaldust cui-liqiang cuiweiwei cyberdak cyejing dagmom dengliming devkanro devon-ye dimaaan dingdongnigetou dio dmsolr dominicqi donbing007 dsc6636926 duotai dvsv2 dzx2018 echooymxq efekaptan eoeac evanxuhe feelwing1314 fgksgf fuhuo geektcp geomonlin ggndnn gitter-badger glongzh gnr163 gonedays grissom-grissom grissomsh guodongq guyukou gxthrj gzshilu hailin0 hanahmily haotian2015 haoyann hardzhang harvies hepyu heyanlong hi-sb honganan hsoftxl huangyoje huliangdream huohuanhuan innerpeacez itsvse jasonz93 jialong121 jinlongwang jjlu521016 jjtyro jmjoy jsbxyyx justeene juzhiyuan jy00464346 kaanid karott kayleyang kevinyyyy kezhenxu94 kikupotter kilingzhang killGC klboke ksewen kuaikuai kun-song kylixs landonzeng langke93 langyan1022 langyizhao lazycathome leemove leizhiyuan libinglong lilien1010 limfriend linkinshi linliaoy liuhaoXD liuhaoyang liuyanggithup liuzhengyang liweiv lkxiaolou llissery louis-zhou lpf32 lsyf lucperkins lujiajing1126 lunamagic1978 lunchboxav lxliuxuankb lytscu lyzhang1999 magic-akari makingtime maolie masterxxo maxiaoguang64 membphis mestarshine mgsheng michaelsembwever mikkeschiren mm23504570 momo0313 moonming mrproliu muyun12 nacx neatlife neeuq nic-chen nikitap492 nileblack nisiyong novayoung oatiz oflebbe olzhy onecloud360 osiriswd peng-yongsheng pengweiqhca potiuk purgeyao qijianbo010 qinhang3 qiuyu-d qqeasonchen qxo raybi-asus refactor2 remicollet rlenferink rootsongjc rovast scolia sdanzo seifeHu shiluo34 sikelangya simonlei sk163 snakorse songzhendong songzhian sonxy spacewander stalary stenio2011 stevehu stone-wlg sungitly surechen swartz-k sxzaihua tanjunchen tankilo taskmgr tbdpmi terranhu terrymanu tevahp thanq thebouv tianyuak tincopper tinyu0 tom-pytel tristaZero tristan-tsl trustin tsuilouis tuohai666 tzsword-2020 tzy1316106836 vcjmhg vision-ken viswaramamoorthy wankai123 wbpcode web-xiaxia webb2019 weiqiang333 wendal wengangJi wenjianzhang whfjam wind2008hxy withlin wqr2016 wu-sheng wuguangkuo wujun8 wuxingye x22x22 xbkaishui xcaspar xiaoxiangmoe xiaoy00 xinfeingxia85 xinzhuxiansheng xudianyang yanbw yanfch yang-xiaodong yangxb2010000 yanickxia yanmaipian yanmingbi yantaowu yaowenqiang yazong ychandu ycoe yimeng yu199195 yuqichou yuyujulin yymoth zaunist zaygrzx zcai2 zeaposs zhang98722 zhanghao001 zhangjianweibj zhangkewei zhangsean zhaoyuguang zhentaoJin zhousiliang163 zhuCheer zifeihan zkscpqm zoidbergwill zoumingzm zouyx zshit zxbu zygfengyuwuzu  ","excerpt":"Apache SkyWalking is an open source APM for distributed system. Provide tracing, service mesh …","ref":"/blog/2021-01-01-300-contributors-mark/","title":"Celebrate SkyWalking single repository hits the 300 contributors mark"},{"body":"","excerpt":"","ref":"/zh_tags/open-source-contribution/","title":"Open Source Contribution"},{"body":"","excerpt":"","ref":"/zh_tags/open-source-promotion-plan/","title":"Open Source Promotion Plan"},{"body":"Ke Zhang (a.k.a. HumbertZhang) mainly focuses on the SkyWalking Python agent, he had participated in the \u0026ldquo;Open Source Promotion Plan - Summer 2020\u0026rdquo; and completed the project smoothly, and won the award \u0026ldquo;Most Potential Students\u0026rdquo; that shows his great willingness to continuously contribute to our community.\nUp to date, he has submitted 8 PRs in the Python agent repository, 7 PRs in the main repo, all in total include ~2000 LOC.\nAt Dec. 13th, 2020, the project management committee (PMC) passed the proposal of promoting him as a new committer. He has accepted the invitation at the same day.\nWelcome to join the committer team, Ke Zhang!\n","excerpt":"Ke Zhang (a.k.a. HumbertZhang) mainly focuses on the SkyWalking Python agent, he had participated in …","ref":"/events/welcome-ke-zhang-as-new-committer/","title":"Welcome Ke Zhang (张可) as new committer"},{"body":"今年暑假期间我参加了开源软件供应链点亮计划—暑期 2020 的活动，在这个活动中，我主要参加了 Apache SkyWalking 的 Python Agent 的开发，最终项目顺利结项并获得了”最具潜力奖“，今天我想分享一下我参与这个活动以及开源社区的感受与收获。\n缘起 其实我在参加暑期 2020 活动之前就听说过 SkyWalking 了。我研究生的主要研究方向是微服务和云原生，组里的学长们之前就在使用 SkyWalking 进行一些研究工作，也是通过他们，我了解到了 OpenTracing, SkyWalking 等与微服务相关的 Tracing 工具以及 APM 等，当时我就在想如果有机会可以深度参加这些开源项目就好了。 巧的是，也正是在差不多的时候，本科的一个学长发给了我暑期 2020 活动的链接，我在其中惊喜的发现了 SkyWalking 项目。\n虽然说想要参与 SkyWalking 的开发，但是真的有了机会我却有一些不自信——这可是 Star 上万的 Apache 顶级项目。万幸的是在暑期 2020 活动中，每一个社区都提供了很多题目以供选择，想参与的同学可以提前对要做的事情有所了解，并可以提前做一些准备。我当时也仔细地浏览了项目列表，最终决定申请为 Python Agent 支持 Flask 或 Django 埋点的功能。当时主要考虑的是，我对 Python 语言比较熟悉，同时也有使用 Flask 等 web 框架进行开发的经验，我认为应该可以完成项目要求。为了能让心里更有底一些，我阅读了 Python Agent 的源码，写下了对项目需要做的工作的理解，并向项目的导师柯振旭发送了自荐邮件，最终被选中去完成这个项目。\n过程 被选中后我很激动，也把这份激动化作了参与开源的动力。我在进一步阅读源码，搭建本地环境后，用了三周左右的时间完成了 Django 项目的埋点插件的开发，毕竟我选择的项目是一个低难度的项目，而我在 Python web 方面也有一些经验。在这之后，我的导师和我进行了沟通，在我表达了想要继续做贡献的意愿之后，他给我建议了一些可以进一步进行贡献的方向，我也就继续参与 Python Agent 的开发。接下来，我陆续完成了 PyMongo 埋点插件, 插件版本检查机制, 支持使用 kafka 协议进行数据上报等功能。在提交了暑期 2020 活动的结项申请书后，我又继续参与了在端到端测试中增加对百分位数的验证等功能。\n在整个过程中，我遇到过很多问题，包括对问题认识不够清晰，功能的设计不够完善等等，但是通过与导师的讨论以及 Code Review，这些问题最终都迎刃而解了。此外他还经常会和我交流项目进一步发展方向，并给我以鼓励和肯定，在这里我想特别感谢我的导师在整个项目过程中给我的各种帮助。\n收获 参加暑期 2020 的活动带给我了很多收获，主要有以下几点：\n第一是让我真正参与到了开源项目中。在之前我只向在项目代码或文档中发现的 typo 发起过一些 Pull Request，但是暑期 2020 活动通过列出项目 ＋ 导师指导的方式，明确了所要做的事情，并提供了相应的指导，降低了参与开源的门槛，使得我们学生可以参与到项目的开发中来。\n第二是对我的专业研究方向也有很多启发，我的研究方向就是微服务与云原生相关，通过参与到 SkyWalking 的开发中使得我可以更好地理解研究问题中的一些概念，也让我更得心应手得使用 SkyWalking 来解决一些实际的问题。\n第三是通过参与 SkyWalking Python Agent 以及其他部分的开发，我的贡献得到了社区的承认，并在最近被邀请作为 Committer 加入了社区，这对我而言是很高的认可，也提升了我的自信心。\n​\t第四点就是我通过这个活动认识了不少新朋友，同时也开拓了我的视野，使得我对于开源项目与开源社区有了很多新的认识。\n建议 最后同样是我对想要参与开源社区，想要参与此类活动的同学们的一些建议：\n 虽然奖金很吸引人，但是还是希望大家能抱着长期为项目进行贡献的心态来参与开源项目，以这样的心态参与开源可以让你更好地理解开源社区的运作方式，也可以让你更有机会参与完成激动人心的功能，你在一个东西上付出的时间精力越多，你能收获的往往也越多。 在申请项目的时候，可以提前阅读一下相关功能的源码，并结合自己的思考去写一份清晰明了的 proposal ，这样可以帮助你在申请人中脱颖而出。 在开始着手去完成一个功能之前，首先理清思路，并和自己的导师或了解这一部分的人进行沟通与确认，从而尽量避免在错误的方向上浪费太多时间。  ","excerpt":"今年暑假期间我参加了开源软件供应链点亮计划—暑期 2020 的活动，在这个活动中，我主要参加了 Apache SkyWalking 的 Python Agent 的开发，最终项目顺利结项并获得了”最具 …","ref":"/zh/2020-12-20-summer2020-activity-sharing2/","title":"暑期 2020 活动学生（张可）心得分享"},{"body":"背景 我是一个热爱编程、热爱技术的人，⼀直以来都向往着能参与到开源项⽬中锻炼⾃⼰，但当我面对庞大而复杂的项目代码时，却感到手足无措，不知该从何开始。⽽此次的“开源软件供应链点亮计划-暑期2020”活动则正好提供了这样⼀个机会：清晰的任务要求、开源社区成员作为导师提供指导以及一笔丰厚的奖金，让我顺利地踏上了开源这条道路。\n回顾 在“暑期2020”活动的这两个多月里，我为 SkyWalking 的命令行工具实现了一个 dashboard，此外在阅读项目源码的过程中，还发现并修复了几个 bug。到活动结束时，我共提交了11个 PR，贡献了两千多行改动，对 SkyWalking CLI 项目的贡献数量排名第二，还获得了“最具潜力奖”。\n我觉得之所以能够如此顺利地完成这个项⽬主要有两个原因。一方面，我选择的 SkyWalking CLI 项⽬当时最新的版本号为0.3.0，还处于起步阶段，代码量相对较少，⽽且项⽬结构非常清晰，文档也较为详细，这对于我理解整个项⽬⾮常有帮助，从⽽能够更快地上⼿。另一方面，我的项目导师非常认真负责，每次我遇到问题，导师都会及时地为我解答，然后我提交的 PR 也能够很快地被 review。⽽且导师不时会给予我肯定的评论与⿎励，这极⼤地提⾼了我的成就感，让我更加积极地投⼊到下⼀阶段的⼯作，形成⼀个正向的循环。\n收获 回顾整个参与过程，觉得自己收获颇多：\n首先，我学习到了很多可能在学校里接触不到的新技术，了解了开源项目是如何进行协作，开源社区是如何运转治理的，以及开源文化、Apache way 等知识，仿佛进入了一个崭新而精彩的世界。\n其次，我的编程能力得到了锻炼。因为开源项目对于代码的质量有较高的要求，因此我会在编程时有意识地遵守相关的规范，培养良好的编码习惯。然后在导师的 code review 中也学习到了一些编程技巧。\n此外，参与开源为我的科研带来了不少灵感。因为我的研究方向是智能软件工程，旨在将人工智能技术应用在软件工程的各个环节中，这需要我在实践中发现实际问题。而开源则提供了这样一个窗口，让我足不出户即可参与到软件项目的设计、开发、测试和发布等环节。\n最后也是本次活动最大的一个收获，我的贡献得到了社区的认可，被提名成为了 SkyWalking 社区的第一位学生 committer。\n建议 最后，对于将来想要参加此类活动的同学，附上我的一些建议：\n第一，选择活跃、知名的社区。社区对你的影响将是极其深远的，好的社区意味着成熟的协作流程、良好的氛围、严谨的代码规范，以及有更大几率遇到优秀的导师，这些对于你今后在开源方面的发展都是非常有帮助的。\n第二，以兴趣为导向来选择项目，同时要敢于走出舒适区。我最初在选择项目时，初步确定了两个，一个是低难度的 Python 项目，另一个是中等难度的 Go 项目。当时我很纠结：因为我对 Python 语言比较熟悉，选择一个低难度的项目是比较稳妥的，但是项目的代码我看的并不是很懂，具体要怎么做我完全没有头绪；而 Go 项目是一个命令行工具，我对这个比较感兴趣，且有一个大致的思路，但是我对 Go 语言并不是很熟悉，实践经验为零。最后凭借清晰具体的 proposal 我成功申请到了 Go 项目并顺利地完成了，还在实践中快速掌握了一门新的编程语言。\n这次的“暑期2020”活动虽已圆满结束，但我的开源之路才刚刚开始。\n","excerpt":"背景 我是一个热爱编程、热爱技术的人，⼀直以来都向往着能参与到开源项⽬中锻炼⾃⼰，但当我面对庞大而复杂的项目代码时，却感到手足无措，不知该从何开始。⽽此次的“开源软件供应链点亮计划-暑期2020”活动 …","ref":"/zh/2020-12-19-summer2020-activity-sharing/","title":"暑期2020活动心得分享"},{"body":"NGE2E is the next generation End-to-End Testing framework that aims to help developers to set up, debug, and verify E2E tests with ease. It\u0026rsquo;s built based on the lessons learnt from tens of hundreds of test cases in the SkyWalking main repo.\nGoal  Keep the feature parity with the existing E2E framework in SkyWalking main repo; Support both docker-compose and KinD to orchestrate the tested services under different environments; Get rid of the heavy Java/Maven stack, which exists in the current E2E; be language independent as much as possible, users only need to configure YAMLs and run commands, without writing codes;  Non-Goal  This framework is not involved with the build process, i.e. it won\u0026rsquo;t do something like mvn package or docker build, the artifacts (.tar, docker images) should be ready in an earlier process before this; This project doesn\u0026rsquo;t take the plugin tests into account, at least for now; This project doesn\u0026rsquo;t mean to add/remove any new/existing test case to/from the main repo; This documentation won\u0026rsquo;t cover too much technical details of how to implement the framework, that should go into an individual documentation;  Design Before diving into the design details, let\u0026rsquo;s take a quick look at how the end user might use NGE2E.\n All the following commands are mock, and are open to debate.\n To run a test case in a directory /path/to/the/case/directory\ne2e run /path/to/the/case/directory # or cd /path/to/the/case/directory \u0026amp;\u0026amp; e2e run This will run the test case in the specified directory, this command is a wrapper that glues all the following commands, which can be executed separately, for example, to debug the case:\nNOTE: because all the options can be loaded from a configuration file, so as long as a configuration file (say e2e.yaml) is given in the directory, every command should be able to run in bare mode (without any option explicitly specified in the command line);\nSet Up e2e setup --env=compose --file=docker-compose.yaml --wait-for=service/health e2e setup --env=kind --file=kind.yaml --manifests=bookinfo.yaml,gateway.yaml --wait-for=pod/ready e2e setup # If configuration file e2e.yaml is present  --env: the environment, may be compose or kind, represents docker-compose and KinD respectively; --file: the docker-compose.yaml or kind.yaml file that declares how to set up the environment; --manifests: for KinD, the resources files/directories to apply (using kubectl apply -f); --command: a command to run after the environment is started, this may be useful when users need to install some extra tools or apply resources from command line, like istioctl install --profile=demo; --wait-for: can be specified multiple times to give a list of conditions to be met; wait until the given conditions are met; the most frequently-used strategy should be --wait-for=service/health, --wait-for=deployments/available, etc. that make the e2e setup command to wait for all conditions to be met; other possible strategies may be something like --wait-for=\u0026quot;log:Started Successfully\u0026quot;, --wait-for=\u0026quot;http:localhost:8080/healthcheck\u0026quot;, etc. if really needed;  Trigger Inputs e2e trigger --interval=3s --times=0 --action=http --url=\u0026#34;localhost:8080/users\u0026#34; e2e trigger --interval=3s --times=0 --action=cmd --cmd=\u0026#34;curl localhost:8080/users\u0026#34; e2e trigger # If configuration file e2e.yaml is present  --interval=3s: trigger the action every 3 seconds; --times=0: how many times to trigger the action, 0=infinite; --action=http: the action of the trigger, i.e. \u0026ldquo;perform an http request as an input\u0026rdquo;; --action=cmd: the action of the trigger, i.e. \u0026ldquo;execute the cmd as an input\u0026rdquo;;  Query Output swctl service ls this is a project-specific step, different project may use different tools to query the actual output, for SkyWalking, it uses swctl to query the actual output.\nVerify e2e verify --actual=actual.data.yaml --expected=expected.data.yaml e2e verify --query=\u0026#34;swctl service ls\u0026#34; --expected=expected.data.yaml e2e verify # If configuration file e2e.yaml is present   --actual: the actual data file, only YAML file format is supported;\n  --expected: the expected data file, only YAML file format is supported;\n  --query: the query to get the actual data, the query result must have the same format as --actual and --expected;\n The --query option will get the output into a temporary file and use the --actual under the hood;\n   Cleanup e2e cleanup --env=compose --file=docker-compose.yaml e2e cleanup --env=kind --file=kind.yaml --resources=bookinfo.yaml,gateway.yaml e2e cleanup # If configuration file e2e.yaml is present This step requires the same options in the setup step so that it can clean up all things necessarily.\nSummarize To summarize, the directory structure of a test case might be\ncase-name ├── agent-service # optional, an arbitrary project that is used in the docker-compose.yaml if needed │ ├── Dockerfile │ ├── pom.xml │ └── src ├── docker-compose.yaml ├── e2e.yaml # see a sample below └── testdata ├── expected.endpoints.service1.yaml ├── expected.endpoints.service2.yaml └── expected.services.yaml or\ncase-name ├── kind.yaml ├── bookinfo │ ├── bookinfo.yaml │ └── bookinfo-gateway.yaml ├── e2e.yaml # see a sample below └── testdata ├── expected.endpoints.service1.yaml ├── expected.endpoints.service2.yaml └── expected.services.yaml a sample of e2e.yaml may be\nsetup: env: kind file: kind.yaml manifests: - path: bookinfo.yaml wait: # you can have multiple conditions to wait - namespace: bookinfo label-selector: app=product for: deployment/available - namespace: reviews label-selector: app=product for: deployment/available - namespace: ratings label-selector: app=product for: deployment/available run: - command: | # it can be a shell script or anything executable istioctl install --profile=demo -y kubectl label namespace default istio-injection=enabled wait: - namespace: istio-system label-selector: app=istiod for: deployment/available # OR # env: compose # file: docker-compose.yaml trigger: action: http interval: 3s times: 0 url: localhost:9090/users verify: - query: swctl service ls expected: expected.services.yaml - query: swctl endpoint ls --service=\u0026#34;YnVzaW5lc3Mtem9uZTo6cHJvamVjdEM=.1\u0026#34; expected: expected.projectC.endpoints.yaml then a single command should do the trick.\ne2e run Modules This project is divided into the following modules.\nController A controller command (e2e run) composes all the steps declared in the e2e.yaml, it should be progressive and clearly display which step is currently running. If it failed in a step, the error message should be as much comprehensive as possible. An example of the output might be\ne2e run ✔ Started Kind Cluster - Cluster Name ✔ Checked Pods Readiness - All pods are ready ? Generating Traffic - http localhost:9090/users (progress spinner) ✔ Verified Output - service ls (progress spinner) Verifying Output - endpoint ls ✘ Failed to Verify Output Data - endpoint ls \u0026lt;the diff content\u0026gt; ✔ Clean Up Compared with running the steps one by one, the controller is also responsible for cleaning up env (by executing cleanup command) no mater what status other commands are, even if they are failed, the controller has the following semantics in terms of setup and cleanup.\n// Java try { setup(); // trigger step // verify step // ... } finally { cleanup(); } // GoLang func run() { setup(); defer cleanup(); // trigger step // verify step // ... } Initializer The initializer is responsible for\n  When env==compose\n Start the docker-compose services; Check the services\u0026rsquo; healthiness; Wait until all services are ready according to the interval, etc.;    When env==kind\n Start the KinD cluster according to the config files; Apply the resources files (--manifests) or/and run the custom init command (--commands); Check the pods\u0026rsquo; readiness; Wait until all pods are ready according to the interval, etc.;    Verifier According to scenarios we have at the moment, the must-have features are:\n  Matchers\n Exact match Not null Not empty Greater than 0 Regexp match At least one of list element match    Functions\n Base64 encode/decode    in order to help to identify simple bugs from the GitHub Actions workflow, there are some \u0026ldquo;nice to have\u0026rdquo; features:\n Printing the diff content when verification failed is a super helpful bonus proved in the Python agent repo;  Logging When a test case failed, all the necessary logs should be collected into a dedicated directory, which could be uploaded to the GitHub Artifacts for downloading and analysis;\nLogs through the entire process of a test case are:\n KinD clusters logs; Containers/pods logs; The logs from the NGE2E itself;  More Planned Debugging Debugging the E2E locally has been a strong requirement and time killer that we haven\u0026rsquo;t solve up to date, though we have enhancements like https://github.com/apache/skywalking/pull/5198 , but in this framework, we will adopt a new method to \u0026ldquo;really\u0026rdquo; support debugging locally.\nThe most common case when debugging is to run the E2E tests, with one or more services forwarded into the host machine, where the services are run in the IDE or in debug mode.\nFor example, you may run the SkyWalking OAP server in an IDE and run e2e run, expecting the other services (e.g. agent services, SkyWalking WebUI, etc.) inside the containers to connect to your local OAP, instead of the one declared in docker-compose.yaml.\nFor Docker Desktop Mac/Windows, we can access the services running on the host machine inside containers via host.docker.internal, for Linux, it\u0026rsquo;s 172.17.0.1.\nOne possible solution is to add an option --debug-services=oap,other-service-name that rewrites all the router rules inside the containers from oap to host.docker.internal/172.17.0.1.\nCodeGen When adding new test case, a code generator would be of great value to eliminate the repeated labor and copy-pasting issues.\ne2e new \u0026lt;case-name\u0026gt; ","excerpt":"NGE2E is the next generation End-to-End Testing framework that aims to help developers to set up, …","ref":"/blog/e2e-design/","title":"[Design] NGE2E - Next Generation End-to-End Testing Framework"},{"body":"这篇文章暂时不讲告警策略, 直接看默认情况下激活的告警目标以及钉钉上的告警效果\nSkyWalking内置了很多默认的告警策略, 然后根据告警策略生成告警目标, 我们可以很容易的在界面上看到\n当我们想去让这些告警目标通知到我们时, 由于SkyWalking目前版本(8.3)已经自带了, 只需要简单配置一下即可\n我们先来钉钉群中创建机器人并勾选加签\n然后再修改告警部分的配置文件, 如果你是默认的配置文件(就像我一样), 你可以直接执行以下命令, 反之你也可以手动修改configs/alarm-settings.yml文件\ntee \u0026lt;your_skywalking_path\u0026gt;/configs/alarm-settings.yml \u0026lt;\u0026lt;-'EOF' dingtalkHooks: textTemplate: |- { \u0026quot;msgtype\u0026quot;: \u0026quot;text\u0026quot;, \u0026quot;text\u0026quot;: { \u0026quot;content\u0026quot;: \u0026quot;Apache SkyWalking Alarm: \\n %s.\u0026quot; } } webhooks: - url: https://oapi.dingtalk.com/robot/send?access_token=\u0026lt;access_token\u0026gt; secret: \u0026lt;加签值\u0026gt; EOF 最终效果如下\n参考文档:\nhttps://github.com/apache/skywalking/blob/master/docs/en/setup/backend/backend-alarm.md\nhttps://ding-doc.dingtalk.com/doc#/serverapi2/qf2nxq/uKPlK\n谢谢观看, 后续我会在SkyWalking告警这块写更多实战文章\n","excerpt":"这篇文章暂时不讲告警策略, 直接看默认情况下激活的告警目标以及钉钉上的告警效果\nSkyWalking内置了很多默认的告警策略, 然后根据告警策略生成告警目标, 我们可以很容易的在界面上看到\n当我们想去 …","ref":"/zh/2020-12-13-skywalking-alarm/","title":"SkyWalking报警发送到钉钉群"},{"body":"","excerpt":"","ref":"/zh_tags/user-manual/","title":"User Manual"},{"body":"Gui Cao began the code contributions since May 3, 2020. In the past 6 months, his 23 pull requests(GitHub, zifeihan[1]) have been accepted, which includes 5k+ lines of codes.\nMeanwhile, he took part in the tech discussion, and show the interests to contribute more to the project.\nAt Dec. 4th, 2020, the project management committee(PMC) passed the proposal of promoting him as a new committer. He has accepted the invitation at the same day.\nWelcome Gui Cao join the committer team.\n[1] https://github.com/apache/skywalking/commits?author=zifeihan\n","excerpt":"Gui Cao began the code contributions since May 3, 2020. In the past 6 months, his 23 pull …","ref":"/events/welcome-gui-cao-as-new-committer/","title":"Welcome Gui Cao as new committer"},{"body":" Author: Zhenxu Ke, Sheng Wu, and Tevah Platt. tetrate.io Original link, Tetrate.io blog Dec. 03th, 2020  Apache SkyWalking: an APM (application performance monitor) system, especially designed for microservices, cloud native, and container-based (Docker, Kubernetes, Mesos) architectures.\nEnvoy Access Log Service: Access Log Service (ALS) is an Envoy extension that emits detailed access logs of all requests going through Envoy.\nBackground Apache SkyWalking has long supported observability in service mesh with Istio Mixer adapter. But since v1.5, Istio began to deprecate Mixer due to its poor performance in large scale clusters. Mixer’s functionalities have been moved into the Envoy proxies, and is supported only through the 1.7 Istio release. On the other hand, Sheng Wu and Lizan Zhou presented a better solution based on the Apache SkyWalking and Envoy ALS on KubeCon China 2019, to reduce the performance impact brought by Mixer, while retaining the same observability in service mesh. This solution was initially implemented by Sheng Wu, Hongtao Gao, Lizan Zhou, and Dhi Aurrahman at Tetrate.io. If you are looking for a more efficient solution to observe your service mesh instead of using a Mixer-based solution, this is exactly what you need. In this tutorial, we will explain a little bit how the new solution works, and apply it to the bookinfo application in practice.\nHow it works From a perspective of observability, Envoy can be typically deployed in 2 modes, sidecar, and router. As a sidecar, Envoy mostly represents a single service to receive and send requests (2 and 3 in the picture below). While as a proxy, Envoy may represent many services (1 in the picture below).\nIn both modes, the logs emitted by ALS include a node identifier. The identifier starts with router~ (or ingress~) in router mode and sidecar~ in sidecar proxy mode.\nApart from the node identifier, there are several noteworthy properties in the access logs that will be used in this solution:\n  downstream_direct_remote_address: This field is the downstream direct remote address on which the request from the user was received. Note: This is always the physical peer, even if the remote address is inferred from for example the x-forwarded-for header, proxy protocol, etc.\n  downstream_remote_address: The remote/origin address on which the request from the user was received.\n  downstream_local_address: The local/destination address on which the request from the user was received.\n  upstream_remote_address: The upstream remote/destination address that handles this exchange.\n  upstream_local_address: The upstream local/origin address that handles this exchange.\n  upstream_cluster: The upstream cluster that upstream_remote_address belongs to.\n  We will discuss more about the properties in the following sections.\nSidecar When serving as a sidecar, Envoy is deployed alongside a service, and delegates all the incoming/outgoing requests to/from the service.\n  Delegating incoming requests: in this case, Envoy acts as a server side sidecar, and sets the upstream_cluster in form of inbound|portNumber|portName|Hostname[or]SidecarScopeID.\nThe SkyWalking analyzer checks whether either downstream_remote_address can be mapped to a Kubernetes service:\na. If there is a service (say Service B) whose implementation is running in this IP(and port), then we have a service-to-service relation, Service B -\u0026gt; Service A, which can be used to build the topology. Together with the start_time and duration fields in the access log, we have the latency metrics now.\nb. If there is no service that can be mapped to downstream_remote_address, then the request may come from a service out of the mesh. Since SkyWalking cannot identify the source service where the requests come from, it simply generates the metrics without source service, according to the topology analysis method. The topology can be built as accurately as possible, and the metrics detected from server side are still correct.\n  Delegating outgoing requests: in this case, Envoy acts as a client-side sidecar, and sets the upstream_cluster in form of outbound|\u0026lt;port\u0026gt;|\u0026lt;subset\u0026gt;|\u0026lt;serviceFQDN\u0026gt;.\nClient side detection is relatively simpler than (1. Delegating incoming requests). If upstream_remote_address is another sidecar or proxy, we simply get the mapped service name and generate the topology and metrics. Otherwise, we have no idea what it is and consider it an UNKNOWN service.\n  Proxy role When Envoy is deployed as a proxy, it is an independent service itself and doesn\u0026rsquo;t represent any other service like a sidecar does. Therefore, we can build client-side metrics as well as server-side metrics.\nExample In this section, we will use the typical bookinfo application to demonstrate how Apache SkyWalking 8.3.0+ (the latest version up to Nov. 30th, 2020) works together with Envoy ALS to observe a service mesh.\nInstalling Kubernetes SkyWalking 8.3.0 supports the Envoy ALS solution under both Kubernetes environment and virtual machines (VM) environment, in this tutorial, we’ll only focus on the Kubernetes scenario, for VM solution, please stay tuned for our next blog, so we need to install Kubernetes before taking further steps.\nIn this tutorial, we will use the Minikube tool to quickly set up a local Kubernetes(v1.17) cluster for testing. In order to run all the needed components, including the bookinfo application, the SkyWalking OAP and WebUI, the cluster may need up to 4GB RAM and 2 CPU cores.\nminikube start --memory=4096 --cpus=2 Next, run kubectl get pods --namespace=kube-system --watch to check whether all the Kubernetes components are ready. If not, wait for the readiness before going on.\nInstalling Istio Istio provides a very convenient way to configure the Envoy proxy and enable the access log service. The built-in configuration profiles free us from lots of manual operations. So, for demonstration purposes, we will use Istio through this tutorial.\nexport ISTIO_VERSION=1.7.1 curl -L https://istio.io/downloadIstio | sh - sudo mv $PWD/istio-$ISTIO_VERSION/bin/istioctl /usr/local/bin/ istioctl install --set profile=demo kubectl label namespace default istio-injection=enabled Run kubectl get pods --namespace=istio-system --watch to check whether all the Istio components are ready. If not, wait for the readiness before going on.\nEnabling ALS The demo profile doesn’t enable ALS by default. We need to reconfigure it to enable ALS via some configuration.\nistioctl manifest install \\  --set meshConfig.enableEnvoyAccessLogService=true \\  --set meshConfig.defaultConfig.envoyAccessLogService.address=skywalking-oap.istio-system:11800 The example command --set meshConfig.enableEnvoyAccessLogService=true enables the Envoy access log service in the mesh. And as we said earlier, ALS is essentially a gRPC service that emits requests logs. The config meshConfig.defaultConfig.envoyAccessLogService.address=skywalking-oap.istio-system:11800 tells this gRPC service where to emit the logs, say skywalking-oap.istio-system:11800, where we will deploy the SkyWalking ALS receiver later.\nNOTE: You can also enable the ALS when installing Istio so that you don’t need to restart Istio after installation:\nistioctl install --set profile=demo \\  --set meshConfig.enableEnvoyAccessLogService=true \\  --set meshConfig.defaultConfig.envoyAccessLogService.address=skywalking-oap.istio-system:11800 kubectl label namespace default istio-injection=enabled Deploying Apache SkyWalking The SkyWalking community provides a Helm Chart to make it easier to deploy SkyWalking and its dependent services in Kubernetes. The Helm Chart can be found at the GitHub repository.\n# Install Helm curl -sSLO https://get.helm.sh/helm-v3.0.0-linux-amd64.tar.gz sudo tar xz -C /usr/local/bin --strip-components=1 linux-amd64/helm -f helm-v3.0.0-linux-amd64.tar.gz # Clone SkyWalking Helm Chart git clone https://github.com/apache/skywalking-kubernetes cd skywalking-kubernetes/chart git reset --hard dd749f25913830c47a97430618cefc4167612e75 # Update dependencies helm dep up skywalking # Deploy SkyWalking helm -n istio-system install skywalking skywalking \\  --set oap.storageType=\u0026#39;h2\u0026#39;\\  --set ui.image.tag=8.3.0 \\  --set oap.image.tag=8.3.0-es7 \\  --set oap.replicas=1 \\  --set oap.env.SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS=k8s-mesh \\  --set oap.env.JAVA_OPTS=\u0026#39;-Dmode=\u0026#39; \\  --set oap.envoy.als.enabled=true \\  --set elasticsearch.enabled=false We deploy SkyWalking to the namespace istio-system, so that SkyWalking OAP service can be accessed by skywalking-oap.istio-system:11800, to which we told ALS to emit their logs, in the previous step.\nWe also enable the ALS analyzer in the SkyWalking OAP: oap.env.SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS=k8s-mesh. The analyzer parses the access logs and maps the IP addresses in the logs to the real service names in the Kubernetes, to build a topology.\nIn order to retrieve the metadata (such as Pod IP and service names) from a Kubernetes cluster for IP mappings, we also set oap.envoy.als.enabled=true, to apply for a ClusterRole that has access to the metadata.\nexport POD_NAME=$(kubectl get pods -A -l \u0026#34;app=skywalking,release=skywalking,component=ui\u0026#34; -o name) echo $POD_NAME kubectl -n istio-system port-forward $POD_NAME 8080:8080 Now navigate your browser to http://localhost:8080 . You should be able to see the SkyWalking dashboard. The dashboard is empty for now, but after we deploy the demo application and generate traffic, it should be filled up later.\nDeploying Bookinfo application Run:\nexport ISTIO_VERSION=1.7.1 kubectl apply -f https://raw.githubusercontent.com/istio/istio/$ISTIO_VERSION/samples/bookinfo/platform/kube/bookinfo.yaml kubectl apply -f https://raw.githubusercontent.com/istio/istio/$ISTIO_VERSION/samples/bookinfo/networking/bookinfo-gateway.yaml kubectl wait --for=condition=Ready pods --all --timeout=1200s minikube tunnel Then navigate your browser to http://localhost/productpage. You should be able to see the typical bookinfo application. Refresh the webpage several times to generate enough access logs.\nDone! And you’re all done! Check out the SkyWalking WebUI again. You should see the topology of the bookinfo application, as well the metrics of each individual service of the bookinfo application.\nTroubleshooting  Check all pods status: kubectl get pods -A. SkyWalking OAP logs: kubectl -n istio-system logs -f $(kubectl get pod -A -l \u0026quot;app=skywalking,release=skywalking,component=oap\u0026quot; -o name). SkyWalking WebUI logs: kubectl -n istio-system logs -f $(kubectl get pod -A -l \u0026quot;app=skywalking,release=skywalking,component=ui\u0026quot; -o name). Make sure the time zone at the bottom-right of the WebUI is set to UTC +0.  Customizing Service Names The SkyWalking community brought more improvements to the ALS solution in the 8.3.0 version. You can decide how to compose the service names when mapping from the IP addresses, with variables service and pod. For instance, configuring K8S_SERVICE_NAME_RULE to the expression ${service.metadata.name}-${pod.metadata.labels.version} gets service names with version label such as reviews-v1, reviews-v2, and reviews-v3, instead of a single service reviews, see the PR.\nWorking ALS with VM Kubernetes is popular, but what about VMs? From what we discussed above, in order to map the IPs to services, SkyWalking needs access to the Kubernetes cluster, fetching service metadata and Pod IPs. But in a VM environment, there is no source from which we can fetch those metadata. In the next post, we will introduce another ALS analyzer based on the Envoy metadata exchange mechanism. With this analyzer, you are able to observe a service mesh in the VM environment. Stay tuned! If you want to have commercial support for the ALS solution or hybrid mesh observability, Tetrate Service Bridge, TSB is another good option out there.\nAdditional Resources  KubeCon 2019 Recorded Video. Get more SkyWalking updates on the official website.  Apache SkyWalking founder Sheng Wu, SkyWalking core maintainer Zhenxu Ke are Tetrate engineers, and Tevah Platt is a content writer for Tetrate. Tetrate helps organizations adopt open source service mesh tools, including Istio, Envoy, and Apache SkyWalking, so they can manage microservices, run service mesh on any infrastructure, and modernize their applications.\n","excerpt":"Author: Zhenxu Ke, Sheng Wu, and Tevah Platt. tetrate.io Original link, Tetrate.io blog Dec. 03th, …","ref":"/blog/2020-12-03-obs-service-mesh-with-sw-and-als/","title":"Observe Service Mesh with SkyWalking and Envoy Access Log Service"},{"body":"","excerpt":"","ref":"/zh_tags/service-mesh/","title":"Service Mesh"},{"body":"","excerpt":"","ref":"/tags/service-mesh/","title":"Service Mesh"},{"body":" 如果你正在寻找在 Mixer 方案以外观察服务网格的更优解，本文正符合你的需要。\n Apache Skywalking︰特别为微服务、云原生和容器化（Docker、Kubernetes、Mesos）架构而设计的 APM（应用性能监控）系统。\nEnvoy 访问日志服务︰访问日志服务（ALS）是 Envoy 的扩展组件，会将所有通过 Envoy 的请求的详细访问日志发送出来。\n背景 Apache SkyWalking 一直通过 Istio Mixer 的适配器，支持服务网格的可观察性。不过自从 v1.5 版本，由于 Mixer 在大型集群中差强人意的表现，Istio 开始弃用 Mixer。Mixer 的功能现已迁至 Envoy 代理，并获 Istio 1.7 版本支持。\n在去年的中国 KubeCon 中，吴晟和周礼赞基于 Apache SkyWalking 和 Envoy ALS，发布了新的方案：不再受制于 Mixer 带来的性能影响，也同时保持服务网格中同等的可观察性。这个方案最初是由吴晟、高洪涛、周礼赞和 Dhi Aurrahman 在 Tetrate.io 实现的。\n如果你正在寻找在 Mixer 方案之外，为你的服务网格进行观察的最优解，本文正是你当前所需的。在这个教程中，我们会解释此方案的运作逻辑，并将它实践到 bookinfo 应用上。\n运作逻辑 从可观察性的角度来说，Envoy 一般有两种部署模式︰Sidecar 和路由模式。 Envoy 代理可以代表多项服务（见下图之 1），或者当它作为 Sidecar 时，一般是代表接收和发送请求的单项服务（下图之 2 和 3）。\n在两种模式中，ALS 发放的日志都会带有一个节点标记符。该标记符在路由模式时，以 router~ （或 ingress~）开头，而在 Sidecar 代理模式时，则以 sidecar~ 开头。\n除了节点标记符之外，这个方案［1］所采用的访问日志也有几个值得一提的字段︰\ndownstream_direct_remote_address︰此字段是下游的直接远程地址，用作接收来自用户的请求。注意︰它永远是对端实体的地址，即使远程地址是从 x-forwarded-for header、代理协议等推断出来的。\ndownstream_remote_address︰远程或原始地址，用作接收来自用户的请求。\ndownstream_local_address︰本地或目标地址，用作接收来自用户的请求。\nupstream_remote_address︰上游的远程或目标地址，用作处理本次交换。\nupstream_local_address︰上游的本地或原始地址，用作处理本次交换。\nupstream_cluster︰upstream_remote_address 所属的上游集群。\n我们会在下面详细讲解各个字段。\nSidecar 当 Envoy 作为 Sidecar 的时候，会搭配服务一起部署，并代理来往服务的传入或传出请求。\n  代理传入请求︰在此情况下，Envoy 会作为服务器端的 Sidecar，以 inbound|portNumber|portName|Hostname[or]SidecarScopeID 格式设定 upstream_cluster。\nSkyWalking 分析器会检查 downstream_remote_address 是否能够找到对应的 Kubernetes 服务。\n如果在此 IP（和端口）中有一个服务（例如服务 B）正在运行，那我们就会建立起服务对服务的关系（即服务 B → 服务 A），帮助建立拓扑。再配合访问日志中的 start_time 和 duration 两个字段，我们就可以获得延迟的指标数据了。\n如果没有任何服务可以和 downstream_remote_address 相对应，那请求就有可能来自网格以外的服务。由于 SkyWalking 无法识别请求的服务来源，在没有源服务的情况下，它简单地根据拓扑分析方法生成数据。拓扑依然可以准确地建立，而从服务器端侦测出来的指标数据也依然是正确的。\n  代理传出请求︰在此情况下，Envoy 会作为客户端的 Sidecar，以 outbound|\u0026lt;port\u0026gt;|\u0026lt;subset\u0026gt;|\u0026lt;serviceFQDN\u0026gt; 格式设定 upstream_cluster。\n客户端的侦测相对来说比代理传入请求容易。如果 upstream_remote_address 是另一个 Sidecar 或代理的话，我们只需要获得它相应的服务名称，便可生成拓扑和指标数据。否则，我们没有办法理解它，只能把它当作 UNKNOWN 服务。\n  代理角色 当 Envoy 被部署为前端代理时，它是独立的服务，并不会像 Sidecar 一样，代表任何其他的服务。所以，我们可以建立客户端以及服务器端的指标数据。\n演示范例 在本章，我们会使用典型的 bookinfo 应用，来演示 Apache SkyWalking 8.3.0+ （截至 2020 年 11 月 30 日的最新版本）如何与 Envoy ALS 合作，联手观察服务网格。\n安装 Kubernetes 在 Kubernetes 和虚拟机器（VM）的环境下，SkyWalking 8.3.0 均支持 Envoy ALS 的方案。在本教程中，我们只会演示在 Kubernetes 的情境，至于 VM 方案，请耐心期待我们下一篇文章。所以在进行下一步之前，我们需要先安装 Kubernetes。\n在本教程中，我们会使用 Minikube 工具来快速设立本地的 Kubernetes（v1.17 版本）集群用作测试。要运行所有必要组件，包括 bookinfo 应用、SkyWalking OAP 和 WebUI，集群需要动用至少 4GB 内存和 2 个 CPU 的核心。\nminikube start --memory=4096 --cpus=2 然后，运行 kubectl get pods --namespace=kube-system --watch，检查所有 Kubernetes 的组件是否已准备好。如果还没，在进行下一步前，请耐心等待准备就绪。\n安装 Istio Istio 为配置 Envoy 代理和实现访问日志服务提供了一个非常方便的方案。内建的配置设定档为我们省去了不少手动的操作。所以，考虑到演示的目的，我们会在本教程全程使用 Istio。\nexport ISTIO_VERSION=1.7.1 curl -L https://istio.io/downloadIstio | sh - sudo mv $PWD/istio-$ISTIO_VERSION/bin/istioctl /usr/local/bin/ istioctl install --set profile=demo kubectl label namespace default istio-injection=enabled 然后，运行 kubectl get pods --namespace=istio-system --watch，检查 Istio 的所有组件是否已准备好。如果还没，在进行下一步前，请耐心等待准备就绪。\n启动访问日志服务 演示的设定档没有预设启动 ALS，我们需要重新配置才能够启动 ALS。\nistioctl manifest install \\  --set meshConfig.enableEnvoyAccessLogService=true \\  --set meshConfig.defaultConfig.envoyAccessLogService.address=skywalking-oap.istio-system:11800 范例指令 --set meshConfig.enableEnvoyAccessLogService=true 会在网格中启动访问日志服务。正如之前提到，ALS 本质上是一个会发放请求日志的 gRPC 服务。配置 meshConfig.defaultConfig.envoyAccessLogService.address=skywalking-oap.istio-system:11800 会告诉这个gRPC 服务往哪里发送日志，这里是往 skywalking-oap.istio-system:11800 发送，稍后我们会部署 SkyWalking ALS 接收器到这个地址。\n注意︰\n你也可以在安装 Istio 时启动 ALS，那就不需要在安装后重新启动 Istio︰\nistioctl install --set profile=demo \\  --set meshConfig.enableEnvoyAccessLogService=true \\  --set meshConfig.defaultConfig.envoyAccessLogService.address=skywalking-oap.istio-system:11800 kubectl label namespace default istio-injection=enabled 部署 Apache SkyWalking SkyWalking 社区提供了 Helm Chart ，让你更轻易地在 Kubernetes 中部署 SkyWalking 以及其依赖服务。 Helm Chart 可以在 GitHub 仓库找到。\n# Install Helm curl -sSLO https://get.helm.sh/helm-v3.0.0-linux-amd64.tar.gz sudo tar xz -C /usr/local/bin --strip-components=1 linux-amd64/helm -f helm-v3.0.0-linux-amd64.tar.gz # Clone SkyWalking Helm Chart git clone https://github.com/apache/skywalking-kubernetes cd skywalking-kubernetes/chart git reset --hard dd749f25913830c47a97430618cefc4167612e75 # Update dependencies helm dep up skywalking # Deploy SkyWalking helm -n istio-system install skywalking skywalking \\  --set oap.storageType=\u0026#39;h2\u0026#39;\\  --set ui.image.tag=8.3.0 \\  --set oap.image.tag=8.3.0-es7 \\  --set oap.replicas=1 \\  --set oap.env.SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS=k8s-mesh \\  --set oap.env.JAVA_OPTS=\u0026#39;-Dmode=\u0026#39; \\  --set oap.envoy.als.enabled=true \\  --set elasticsearch.enabled=false 我们在 istio-system 的命名空间内部署 SkyWalking，使 SkyWalking OAP 服务可以使用地址 skywalking-oap.istio-system:11800 访问，在上一步中，我们曾告诉过 ALS 应往此处发放它们的日志。\n我们也在 SkyWalking OAP 中启动 ALS 分析器︰oap.env.SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS=k8s-mesh。分析器会对访问日志进行分析，并解析日志中的 IP 地址和 Kubernetes 中的真实服务名称，以建立拓扑。\n为了从 Kubernetes 集群处获取元数据（例如 Pod IP 和服务名称），以识别相应的 IP 地址，我们还会设定 oap.envoy.als.enabled=true，用来申请一个对元数据有访问权的 ClusterRole。\nexport POD_NAME=$(kubectl get pods -A -l \u0026#34;app=skywalking,release=skywalking,component=ui\u0026#34; -o name) echo $POD_NAME kubectl -n istio-system port-forward $POD_NAME 8080:8080 现在到你的浏览器上访问 http://localhost:8080。你应该会看到 SkyWalking 的 Dashboard。 Dashboard 现在应该是空的，但稍后部署应用和生成流量后，它就会被填满。\n部署 Bookinfo 应用 运行︰\nexport ISTIO_VERSION=1.7.1 kubectl apply -f https://raw.githubusercontent.com/istio/istio/$ISTIO_VERSION/samples/bookinfo/platform/kube/bookinfo.yaml kubectl apply -f https://raw.githubusercontent.com/istio/istio/$ISTIO_VERSION/samples/bookinfo/networking/bookinfo-gateway.yaml kubectl wait --for=condition=Ready pods --all --timeout=1200s minikube tunnel 现在到你的浏览器上进入 http://localhost/productpage。你应该会看到典型的 bookinfo 应用画面。重新整理该页面几次，以生成足够的访问日志。\n完成了！ 这样做，你就成功完成设置了！再查看 SkyWalking 的 WebUI，你应该会看到 bookinfo 应用的拓扑，以及它每一个单独服务的指标数据。\n疑难解答  检查所有 pod 的状态︰kubectl get pods -A。 SkyWalking OAP 的日志︰kubectl -n istio-system logs -f $(kubectl get pod -A -l \u0026quot;app=skywalking,release=skywalking,component=oap\u0026quot; -o name)。 SkyWalking WebUI 的日志︰kubectl -n istio-system logs -f $(kubectl get pod -A -l \u0026quot;app=skywalking,release=skywalking,component=ui\u0026quot; -o name)。 确保 WebUI 右下方的时区设定在 UTC +0。  自定义服务器名称 SkyWalking 社区在 ALS 方案的 8.3.0 版本中，作出了许多改善。你现在可以在映射 IP 地址时，决定如何用 service 和 pod 变量去自定义服务器的名称。例如，将 K8S_SERVICE_NAME_RULE 设置为 ${service.metadata.name}-${pod.metadata.labels.version}，就可以使服务名称带上版本的标签，类似 reviews-v1、reviews-v2 和 reviews- v3，而不再是单个服务 review［2］。\n在 VM 上使用 ALS Kubernetes 很受欢迎，可是 VM 呢？正如我们之前所说，为了替 IP 找到对应的服务，SkyWalking 需要对 Kubernetes 集群有访问权，以获得服务的元数据和 Pod 的 IP。可是在 VM 环境中，我们并没有来源去收集这些元数据。\n在下一篇文章，我们会介绍另外一个 ALS 分析器，它是建立于 Envoy 的元数据交换机制。有了这个分析器，你就可以在 VM 环境中观察服务网格了。万勿错过！\n如果你希望在 ALS 方案或是混合式网格可观察性上获得商业支持，TSB 会是一个好选项。\n额外资源\n KubeCon 2019 的录影视频。 在官方网站上获得更多有关 SkyWalking 的最新消息吧。  如有任何问题或反馈，发送邮件至 learn@tetrate.io。\nApache SkyWalking 创始人吴晟和 SkyWalking 的核心贡献者柯振旭都是 Tetrate 的工程师。 Tetrate 的内容创造者编辑与贡献于本文章。 Tetrate 帮助企业采用开源服务网格工具，包括 Istio、Envoy 和 Apache SkyWalking，让它们轻松管理微服务，在任何架构上运行服务网格，以至现代化他们的应用。\n［1］https://github.com/envoyproxy/envoy/blob/549164c42cae84b59154ca4c36009e408aa10b52/generated_api_shadow/envoy/data/accesslog/v2/accesslog.proto\n［2］https://github.com/apache/skywalking/pull/5722\n","excerpt":"如果你正在寻找在 Mixer 方案以外观察服务网格的更优解，本文正符合你的需要。\n Apache Skywalking︰特别为微服务、云原生和容器化（Docker、Kubernetes、Mesos）架 …","ref":"/zh/observe-service-mesh-with-skywalking-and-envoy-access-log-service/","title":"使用 SkyWalking 和 Envoy 访问日志服务对服务网格进行观察"},{"body":"SkyWalking 8.3.0 is released. Go to downloads page to find release tars.\nProject  Test: ElasticSearch version 7.0.0 and 7.9.3 as storage are E2E tested. Test: Bump up testcontainers version to work around the Docker bug on MacOS.  Java Agent  Support propagate the sending timestamp in MQ plugins to calculate the transfer latency in the async MQ scenarios. Support auto-tag with the fixed values propagated in the correlation context. Make HttpClient 3.x, 4.x, and HttpAsyncClient 3.x plugins to support collecting HTTP parameters. Make the Feign plugin to support Java 14 Make the okhttp3 plugin to support Java 14 Polish tracing context related codes. Add the plugin for async-http-client 2.x Fix NPE in the nutz plugin. Provide Apache Commons DBCP 2.x plugin. Add the plugin for mssql-jtds 1.x. Add the plugin for mssql-jdbc 6.x -\u0026gt; 9.x. Fix the default ignore mechanism isn\u0026rsquo;t accurate enough bug. Add the plugin for spring-kafka 1.3.x. Add the plugin for Apache CXF 3.x. Fix okhttp-3.x and async-http-client-2.x did not overwrite the old trace header.  OAP-Backend  Add the @SuperDataset annotation for BrowserErrorLog. Add the thread pool to the Kafka fetcher to increase the performance. Add contain and not contain OPS in OAL. Add Envoy ALS analyzer based on metadata exchange. Add listMetrics GraphQL query. Add group name into services of so11y and istio relevant metrics Support keeping collecting the slowly segments in the sampling mechanism. Support choose files to active the meter analyzer. Support nested class definition in the Service, ServiceInstance, Endpoint, ServiceRelation, and ServiceInstanceRelation sources. Support sideCar.internalErrorCode in the Service, ServiceInstance, Endpoint, ServiceRelation, and ServiceInstanceRelation sources. Improve Kubernetes service registry for ALS analysis. Add health checker for cluster management Support the service auto grouping. Support query service list by the group name. Improve the queryable tags generation. Remove the duplicated tags to reduce the storage payload. Fix the threads of the Kafka fetcher exit if some unexpected exceptions happen. Fix the excessive timeout period set by the kubernetes-client. Fix deadlock problem when using elasticsearch-client-7.0.0. Fix storage-jdbc isExists not set dbname. Fix searchService bug in the InfluxDB storage implementation. Fix CVE in the alarm module, when activating the dynamic configuration feature. Fix CVE in the endpoint grouping, when activating the dynamic configuration feature. Fix CVE in the uninstrumented gateways configs, when activating the dynamic configuration feature. Fix CVE in the Apdex threshold configs, when activating the dynamic configuration feature. Make the codes and doc consistent in sharding server and core server. Fix that chunked string is incorrect while the tag contains colon. Fix the incorrect dynamic configuration key bug of endpoint-name-grouping. Remove unused min date timebucket in jdbc deletehistory logical Fix \u0026ldquo;transaction too large error\u0026rdquo; when use TiDB as storage. Fix \u0026ldquo;index not found\u0026rdquo; in trace query when use ES7 storage. Add otel rules to ui template to observe Istio control plane. Remove istio mixer Support close influxdb batch write model. Check SAN in the ALS (m)TLS process.  UI  Fix incorrect label in radial chart in topology. Replace node-sass with dart-sass. Replace serviceFilter with serviceGroup Removed \u0026ldquo;Les Miserables\u0026rdquo; from radial chart in topology. Add the Promise dropdown option  Documentation  Add VNode FAQ doc. Add logic endpoint section in the agent setup doc. Adjust configuration names and system environment names of the sharing server module Tweak Istio metrics collection doc. Add otel receiver.  All issues and pull requests are here\n","excerpt":"SkyWalking 8.3.0 is released. Go to downloads page to find release tars.\nProject  Test: …","ref":"/events/release-apache-skwaylking-apm-8-3-0/","title":"Release Apache SkyWalking APM 8.3.0"},{"body":"Python 作为一门功能强大的编程语言，被广泛的应用于计算机行业之中； 在微服务系统架构盛行的今天，Python 以其丰富的软件生态和灵活的语言特性在服务端编程领域也占有重要的一席之地。 本次分享将阐述 Apache SkyWalking 在微服务架构中要解决的问题，展示如何使用 Apache SkyWalking 来近乎自动化地监控 Python 后端应用服务，并对 Apache SkyWalking 的 Python 语言探针的实现技术进行解读。\n ","excerpt":"Python 作为一门功能强大的编程语言，被广泛的应用于计算机行业之中； 在微服务系统架构盛行的今天，Python 以其丰富的软件生态和灵活的语言特性在服务端编程领域也占有重要的一席之地。 本次分享将 …","ref":"/zh/2020-11-30-pycon/","title":"[视频] PyCon China 2020 - Python 微服务应用性能监控"},{"body":"SkyWalking CLI 0.5.0 is released. Go to downloads page to find release tars.\n  Features\n Use template files in yaml format instead Refactor metrics command to adopt metrics-v2 protocol Use goroutine to speed up dashboard global command Add metrics list command    Bug Fixes\n Add flags of instance, endpoint and normal for metrics command Fix the problem of unable to query database metrics    Chores\n Update release guide doc Add screenshots for use cases in README.md Introduce generated codes into codebase    ","excerpt":"SkyWalking CLI 0.5.0 is released. Go to downloads page to find release tars.\n  Features\n Use …","ref":"/events/release-apache-skywalking-cli-0-5-0/","title":"Release Apache SkyWalking CLI 0.5.0"},{"body":"","excerpt":"","ref":"/tags/design/","title":"Design"},{"body":"","excerpt":"","ref":"/tags/satellite/","title":"Satellite"},{"body":" Author: Jiapeng Liu. Baidu. skywalking-satellite: The Sidecar Project of Apache SkyWalking Nov. 25th, 2020  A lightweight collector/sidecar which can be deployed close to the target monitored system, to collect metrics, traces, and logs. It also provides advanced features, such as local cache, format transformation, and sampling.\nDesign Thinking Satellite is a 2 level system to collect observability data from other core systems. So, the core element of the design is to guarantee data stability during Pod startup all the way to Pod shutdown avoiding alarm loss. All modules are designed as plugins, and if you have other ideas, you can add them yourself.\nSLO  Single gatherer supports \u0026gt; 1000 ops (Based 0.5 Core,50M) At least once delivery.(Optional) Data stability: 99.999%.(Optional)  Because they are influenced by the choice of plugins, some items in SLO are optional.\nRole Satellite would be running as a Sidecar. Although Daemonset mode would take up fewer resources, it will cause more troubles to the forwarding of agents. So we also want to use Sidecar mode by reducing the costs. But Daemonset mode would be also supported in the future plan.\nCore Modules The Satellite has 3 core modules which are Gatherer, Processor, and Sender.\n The Gatherer module is responsible for fetching or receiving data and pushing the data to Queue. The Processor module is responsible for reading data from the queue and processing data by a series of filter chains. The Sender module is responsible for async processing and forwarding the data to the external services in the batch mode. After sending success, Sender would also acknowledge the offset of Queue in Gatherer.  Detailed Structure The overall design is shown in detail in the figure below. We will explain the specific components one by one.\nGatherer Concepts The Gatherer has 4 components to support the data collection, which are Input, Collector, Worker, and Queue. There are 2 roles in the Worker, which are Fetcher and Receiver.\n The Input is an abstraction of the input source, which is usually mapped to a configuration file. The Collector is created by the Source, but many collectors could be created by the same Source. For example, when a log path has been configured as the /var/*.log in an Input, the number of collectors is the same as the file number in this path. The Fetcher and Receiver is the real worker to collect data. The receiver interface is an abstraction, which has multiple implementations, such as gRPC receiver and HTTP receiver.Here are some specific use cases:  Trace Receiver is a gRPC server for receiving trace data created by Skywalking agents. Log Receiver is also a gRPC server for receiving log data which is collected by Skywalking agents. (In the future we want Skywalking Agent to support log sending, and RPC-based log sending is more efficient and needs fewer resources than file reading. For example, the way of file reading will bring IO pressure and performance cost under multi-line splicing.) Log Fetcher is like Filebeat, which fits the common log collection scenario. This fetcher will have more responsibility than any other workers because it needs to record the offset and process the multi-line splicing. This feature will be implemented in the future. Prometheus Fetcher supports a new way to fetch Prometheus data and push the data to the upstream. \u0026hellip;\u0026hellip;   The Queue is a buffer module to decouple collection and transmission. In the 1st release version, we will use persistent storage to ensure data stability. But the implementation is a plug-in design that can support pure memory queues later.   The data flow We use the Trace Receiver as an example to introduce the data flow. Queue MmapQueue We have simplified the design of MmapQueue to reduce the resources cost on the memory and disk.\nConcepts There are 2 core concepts in MmapQueue.\n Segment: Segment is the real data store center, that provides large-space storage and does not reduce read and write performance as much as possible by using mmap. And we will avoid deleting files by reusing them. Meta: The purpose of meta is to find the data that the consumer needs.  Segment One MmapQueue has a directory to store the whole data. The Queue directory is made up with many segments and 1 meta file. The number of the segments would be computed by 2 params, which are the max cost of the Queue and the cost of each segment. For example, If the max cost is 512M and each segment cost is 256K, the directory can hold up to 2000 files. Once capacity is exceeded, an coverage policy is adopted that means the 2000th would override the first file.\nEach segment in Queue will be N times the size of the page cache and will be read and written in an appended sequence rather than randomly. These would improve the performance of Queue. For example, each Segment is a 128k file, as shown in the figure below.\nMeta The Meta is a mmap file that only contains 56Bit. There are 5 concepts in the Meta.\n Version: A version flag. Watermark Offset: Point to the current writing space.  ID: SegmentID Offset: The offset in Segment.   Writed Offset: Point to the latest refreshed data, that would be overridden by the write offset after period refresh.  ID: SegmentID Offset: The offset in Segment.   Reading Offset: Point to the current reading space.  ID: SegmentID Offset: The offset in Segment.   Committed Offset: Point to the latest committed offset , that is equal to the latest acked offset plus one.  ID: SegmentID Offset: The offset in Segment.    The following diagram illustrates the transformation process.\n The publisher receives data and wants to write to Queue.  The publisher would read Writing Offset to find a space and do plus one. After this, the publisher will write the data to the space.   The consumer wants to read the data from Queue.  The consumer would read Reading Offset to find the current read offset and do plus one. After this, the consumer will read the data from the space.   On period flush, the flusher would override Watermark Offset by using Writing Offset. When the ack operation is triggered, Committed Offset would plus the batch size in the ack batch. When facing crash, Writing Offset and Reading Offset would be overridden by Watermark Offset and Committed Offset. That is because the Reading Offset and Writing Offset cannot guarantee at least once delivery.  Mmap Performance Test The test is to verify the efficiency of mmap in low memory cost.\n The rate of data generation: 7.5K/item 1043 item/s (Based on Aifanfan online pod.) The test structure is based on Bigqueue because of similar structure. Test tool: Go Benchmark Test Command: go test -bench BenchmarkEnqueue -run=none -cpu=1 Result On Mac(15-inch, 2018,16 GB 2400 MHz DDR4, 2.2 GHz Intel Core i7 SSD):  BenchmarkEnqueue/ArenaSize-128KB/MessageSize-8KB/MaxMem-384KB 66501 21606 ns/op 68 B/op 1 allocs/op BenchmarkEnqueue/ArenaSize-128KB/MessageSize-8KB/MaxMem-1.25MB 72348 16649 ns/op 67 B/op 1 allocs/op BenchmarkEnqueue/ArenaSize-128KB/MessageSize-16KB/MaxMem-1.25MB 39996 33199 ns/op 103 B/op 1 allocs/op   Result On Linux(INTEL Xeon E5-2450 V2 8C 2.5GHZ2,INVENTEC PC3L-10600 16G8,INVENTEC SATA 4T 7.2K*8):  BenchmarkEnqueue/ArenaSize-128KB/MessageSize-8KB/MaxMem-384KB 126662\t12070 ns/op\t62 B/op\t1 allocs/op BenchmarkEnqueue/ArenaSize-128KB/MessageSize-8KB/MaxMem-1.25MB 127393\t12097 ns/op\t62 B/op\t1 allocs/op BenchmarkEnqueue/ArenaSize-128KB/MessageSize-16KB/MaxMem-1.25MB 63292\t23806 ns/op\t92 B/op\t1 allocs/op   Conclusion: Based on the above tests, mmap is both satisfied at the write speed and at little memory with very low consumption when running as a sidecar.  Processor The Processor has 3 core components, which are Consumer, Filter, and Context.\n The Consumer is created by the downstream Queue. The consumer has its own read offset and committed offset, which is similar to the offset concept of Spark Streaming. Due to the particularity of APM data preprocessing, Context is a unique concept in the Satellite filter chain, which supports storing the intermediate event because the intermediate state event also needs to be sent in sometimes. The Filter is the core data processing part, which is similar to the processor of beats. Due to the context, the upstream/downstream filters would be logically coupling.  Sender  BatchConverter decouples the Processor and Sender by staging the Buffer structure, providing parallelization. But if BatchBuffer is full, the downstream processors would be blocked. Follower is a real send worker that has a client, such as a gRPC client or Kafka client, and a fallback strategy. Fallback strategy is an interface, we can add more strategies to resolve the abnormal conditions, such as Instability in the network, upgrade the oap cluster. When sent success, Committed Offset in Queue would plus the number of this batch.  High Performance The scenario using Satellite is to collect a lot of APM data collection. We guarantee high performance by the following ways.\n Shorten transmission path, that means only join 2 components,which are Queue and Processor, between receiving and forwarding. High Performance Queue. MmapQueue provides a big, fast and persistent queue based on memory mapped file and ring structure. Processor maintains a linear design, that could be functional processed in one go-routine to avoid too much goroutines switching.  Stability Stability is a core point in Satellite. Stability can be considered in many ways, such as stable resources cost, stable running and crash recovery.\nStable resource cost In terms of resource cost, Memory and CPU should be a concern.\nIn the aspect of the CPU, we keep a sequence structure to avoid a large number of retries occurring when facing network congestion. And Satellite avoids keep pulling when the Queue is empty based on the offset design of Queue.\nIn the aspect of the Memory, we have guaranteed only one data caching in Satellite, that is Queue. For the queue structure, we also keep the size fixed based on the ring structure to maintain stable Memory cost. Also, MmapQueue is designed for minimizing memory consumption and providing persistence while keeping speed as fast as possible. Maybe supports some strategy to dynamically control the size of MmapQueue to process more extreme conditions in the future.\nStable running There are many cases of network congestion, such as the network problem on the host node, OAP cluster is under upgrating, and Kafka cluster is unstable. When facing the above cases, Follower would process fallback strategy and block the downstream processes. Once the failure strategy is finished, such that send success or give up this batch, the Follower would process the next batch.\nCrash Recovery The crash recovery only works when the user selects MmapQueue in Gatherer because of persistent file system design. When facing a crash, Reading Offset would be overridden by Committed Offset that ensure the at least once delivery. And Writed Offset would override Writing Offset that ensures the consumer always works properly and avoid encountering uncrossable defective data blocks.\nBuffer pool The Queue is to store fixed structure objects, object buffer pool would be efficient to reuse memory to avoid GC.\n ackChan batch convertor  Some metrics In Satellite, we should also collect its own monitoring metrics. The following metrics are necessary for Satellite.\n cpu memory go routine number gatherer_writing_offset gatherer_watermark_offset processor_reading_count sender_committed_offset sender_abandoned_count sender_retry_count  Input and Output We will reuse this diagram to explain the input and output.\n Input  Because the push-pull mode is both supported, Queue is a core component. Queue is designed to be a ring-shaped fixed capacity, that means the oldest data would be overridden by the latest data. If users find data loss, users should raise the ceiling of memory Queue. MmapQueue generally doesn\u0026rsquo;t face this problem unless the Sender transport is congested.   Ouput  If the BatchBuffer is full, the processor would be blocked. If the Channel is full, the downstream components would be blocked, such as BatchConvertor and Processor. When SenderWorker sends failure, the batch data would do a failure strategy that would block pulling data from the Channel. The strategy is a part of Sender,the operation mode is synchronous. Once the failure strategy is finished, such that send success or give up this batch, the Sendworker would keep pulling data from the Channel.    Questions How to avoid keep pulling when the Queue is empty? If Watermark Offset is less than or equal to Reading Offset, a signal would be sent to the consumer to avoid keep pulling.\nWhy reusing files in Queue? The unified model is a ring in Queue, that limits fixed resources cost in memory or disk.In Mmap Queue, reusing files turns the delete operations into an overwrite operations, effectively reducing the creation and deletion behavior in files.\nWhat are the strategies for file creation and deletion in MmapQueue? As Satellite running, the number of the files in MmapQueue would keep growing until up to the maximum capacity. After this, the old files will be overridden by the new data to avoid file deletion. When the Pod died, all resources were recycled.\n","excerpt":"Author: Jiapeng Liu. Baidu. skywalking-satellite: The Sidecar Project of Apache SkyWalking Nov. …","ref":"/blog/2020-11-25-skywalking-satellite-0.1.0-design/","title":"The first design of Satellite 0.1.0"},{"body":"SkyWalking Python 0.4.0 is released. Go to downloads page to find release tars.\n Feature: Support Kafka reporter protocol (#74) BugFix: Move generated packages into skywalking namespace to avoid conflicts (#72) BugFix: Agent cannot reconnect after server is down (#79) Test: Mitigate unsafe yaml loading (#76)  ","excerpt":"SkyWalking Python 0.4.0 is released. Go to downloads page to find release tars.\n Feature: Support …","ref":"/events/release-apache-skywalking-python-0-4-0/","title":"Release Apache SkyWalking Python 0.4.0"},{"body":"活动介绍 Apache SkyWalking 2020 开发者线下活动，社区创始人，PMC成员和Committer会亲临现场，和大家交流和分享项目中的使用经验。 以及邀请Apache Local Community 北京的成员一起分享Apache文化和Apache之道。\n日程安排 开场演讲 09：30-09：50 SkyWalking\u0026rsquo;s 2019-2020 and beyond\n吴晟，Tetrate.io创始工程师，Apache SkyWalking创始人\n  上午 09：55-10：30 贝壳全链路跟踪实践\n赵禹光，赵禹光，贝壳找房监控技术负责人，Apache SkyWalking PMC成员\n10：35-11：15 SkyWalking在百度爱番番部门实践\n刘嘉鹏，百度，SkyWalking contributor\n11：15-11：55 非计算机背景的同学如何贡献开源\n缘于一位本科在读的社会学系的同学的问题，这让我反思我们开源community的定位和Open的程度，于是，适兕从生产、分发、消费的软件供应的角度，根据涉及到的角色，然后再反观现代大学教育体系的专业，进一步对一个开源项目和community需要的专业背景多样性进行一个阐述和探究。并以ALC Beijing为例进行一个事例性的说明。\n适兕，开源布道师，ALC Beijing member，开源之道主创，开源社教育组成员。\n  下午 13：30-14：10 如何从 Apache SkyWalking 社区学习 Apache Way\n温铭，支流科技联合创始人＆CEO，Apache APISIX 项目 VP， Apache SkyWalking Committer\n14：10-14：50 Apache SkyWalking 在小米公司的应用\n宋振东，小米公司小米信息技术部 skywalking 研发负责人\n14：50-15：30 Istio全生命周期监控\n高洪涛，Tetrate.io创始工程师，Apache SkyWalking PMC成员\n15：30-15：45 茶歇\n15：45-16：25 针对HikariCP数据库连接池的监控\n张鑫 Apache SkyWalking PMC 成员\n16：25-17：00 SkyWalking 与 Nginx 的优化实践\n王院生 深圳支流科技创始人兼 CTO，Apache APISIX 创始人 \u0026amp; PMC成员\n ","excerpt":"活动介绍 Apache SkyWalking 2020 开发者线下活动，社区创始人，PMC成员和Committer会亲临现场，和大家交流和分享项目中的使用经验。 以及邀请Apache Local …","ref":"/zh/2020-11-23-devcon/","title":"[视频] SkyWalking DevCon 2020"},{"body":"The APM system provides the tracing or metrics for distributed systems or microservice architectures. Back to APM themselves, they always need backend storage to store the necessary massive data. What are the features required for backend storage? Simple, fewer dependencies, widely used query language, and the efficiency could be into your consideration. Based on that, traditional SQL databases (like MySQL) or NoSQL databases would be better choices. However, this topic will present another backend storage solution for the APM system viewing from NewSQL. Taking Apache Skywalking for instance, this talking will share how to make use of Apache ShardingSphere, a distributed database middleware ecosystem to extend the APM system\u0026rsquo;s storage capability.\nAs a senior DBA worked at JD.com, the responsibility is to develop the distributed database and middleware, and the automated management platform for database clusters. As a PMC of Apache ShardingSphere, I am willing to contribute to the OS community and explore the area of distributed databases and NewSQL.\n  ","excerpt":"The APM system provides the tracing or metrics for distributed systems or microservice …","ref":"/blog/2020-11-21-apachecon-obs-shardingsphere/","title":"[Video] Another backend storage solution for the APM system"},{"body":"Apache APISIX is a cloud-native microservices API gateway, delivering the ultimate performance, security, open-source and scalable platform for all your APIs and microservices. Apache SkyWalking: an APM(application performance monitor) system, especially designed for microservices, cloud-native and container-based (Docker, Kubernetes, Mesos) architectures. Through the powerful plug-in mechanism of Apache APISIX, Apache Skywalking is quickly supported, so that we can see the complete life cycle of requests from the edge to the internal service. Monitor and manage each request in a visual way, and improve the observability of the service.\n  ","excerpt":"Apache APISIX is a cloud-native microservices API gateway, delivering the ultimate performance, …","ref":"/blog/2020-11-21-apachecon-obs-apisix/","title":"[Video] Improve Apache APISIX observability with Apache SkyWalking"},{"body":"Today\u0026rsquo;s monitoring solutions are geared towards operational tasks, displaying behavior as time-series graphs inside dashboards and other abstractions. These abstractions are immensely useful but are largely designed for software operators, whose responsibilities require them to think in systems, rather than the underlying source code. This is problematic given that an ongoing trend of software development is the blurring boundaries between building and operating software. This trend makes it increasingly necessary for programming environments to not just support development-centric activities, but operation-centric activities as well. Such is the goal of the feedback-driven development approach. By combining IDE and APM technology, software developers can intuitively explore multiple dimensions of their software simultaneously with continuous feedback about their software from inception to production.\nBrandon Fergerson is an open-source software developer who does not regard himself as a specialist in the field of programming, but rather as someone who is a devoted admirer. He discovered the beauty of programming at a young age and views programming as an art and those who do it well to be artists. He has an affinity towards getting meta and combining that with admiration of programming, has found source code analysis to be exceptionally interesting. Lately, his primary focus involves researching and building AI-based pair programming technology.\n  ","excerpt":"Today\u0026rsquo;s monitoring solutions are geared towards operational tasks, displaying behavior as …","ref":"/blog/2020-11-21-apachecon-obs-sourcemarker/","title":"[Video] SourceMarker - Continuous Feedback for Developers"},{"body":"Over the past few years, and coupled with the growing adoption of microservices, distributed tracing has emerged as one of the most commonly used monitoring and troubleshooting methodologies. New tracing tools are increasingly being introduced, driving adoption even further. One of these tools is Apache SkyWalking, a popular open-source tracing, and APM platform. This talk explores the history of the SkyWalking storage module, shows the evolution of distributed tracing storage layers, from the traditional relational database to document-based search engine. I hope that this talk contributes to the understanding of history and also that it helps to clarify the different types of storage that are available to organizations today.\nHongtao Gao is the engineer of tetrate.io and the former Huawei Cloud expert. One of PMC members of Apache SkyWalking and participates in some popular open-source projects such as Apache ShardingSphere and Elastic-Job. He has an in-depth understanding of distributed databases, container scheduling, microservices, ServicMesh, and other technologies.\n  ","excerpt":"Over the past few years, and coupled with the growing adoption of microservices, distributed tracing …","ref":"/blog/2020-11-21-apachecon-obs-storage/","title":"[Video] The history of distributed tracing storage"},{"body":"","excerpt":"","ref":"/tags/conference/","title":"Conference"},{"body":"","excerpt":"","ref":"/tags/video/","title":"Video"},{"body":" 作者: 赵禹光 原文链接: 亲临百人盛况的Apache SkyWalking 2020 DevCon，看见了什么？ 2020 年 10 月 29 日  活动现场 2020年11月14日Apache SkyWalking 2020 DevCon由贝壳找房和tetrate赞助，Apache SkyWalking、云原生、Apache APISIX、Apache Pulsar 和 ALC Beijing 五大社区合作，在贝壳找房一年级会议室盛大举行，本次活动主要面对Apache SkyWalking的使用者、开发者和潜在用户。线上线下共有230多人报名。经统计，实际参加活动人数超过130人，近60%的人愿意抽出自己的休息时间，来交流学习Apache SkyWalking和开源文化。不难看见，在可预见的未来，中国的开源项目很快将进入下一个维度，那必定是更广的社区人员参与，更高技术知识体现，更强的线上稳定性和及时修复能力。\n活动历程： 09：30-09：50 SkyWalking\u0026rsquo;s 2019-2020 and beyond 吴晟老师本次分享：回顾2020年度SkyWalking发布的重要的新特性，出版的《Apache SkyWalking实战》图书，社区的进展，开源爱好者如何参与SkyWalking建设，和已知社区在主导的SkyWalking2021年孵化中的新特性。\n09：55-10：30 贝壳全链路跟踪实践 赵禹光老师（作者）本次分享：回顾了贝壳找房2018年至今，贝壳找房的全链路跟踪项目与SkyWalking的渊源，分享了SkyWalking在实践中遇到的问题，和解决方案。以及SkyWalking近10%的Committer都曾经或正在贝壳人店平台签中研发部，工作过的趣事。\n10：35-11：15 刘嘉鹏老师分享 SkyWalking在百度爱番番部门实践 刘嘉鹏老师本次分享：回顾了百度爱番番部门在使用SkyWalking的发展历程\u0026amp;现状，CRM SAAS产品在近1年使用SkyWalking实践经验，以及如何参与SkyWalking的贡献，并成为的Apache Committer。\n11：15-11：55 适兕老师分享 非计算机背景的同学如何贡献开源 适兕是国内很有名的开源布道师，本次分享从生产、分发、消费的软件供应的角度，根据涉及到的角色，然后再反观现代大学教育体系的专业，进一步对一个开源项目和community需要的专业背景多样性进行一个阐述和探究。并以ALC Beijing为例进行一个事例性的说明，非计算机背景的同学如何贡献开源。\n13：30-14：10 如何从 Apache SkyWalking 社区学习 Apache Way 14：10-14：50 Apache SkyWalking 在小米公司的应用 宋振东老师是小米信息技术部分布式链路追踪系统研发负责人，分别以小米公司，业务开发、架构师、SRE、Leader和QA等多个视角，回顾了SkyWalking在小米公司的应用实践。从APM的产品选型到实际落地，对其他公司准备使用SkyWalking落地，非常有借鉴意义。\n14：50-15：30 Istio全生命周期监控 高洪涛老师本次分享了SkyWalking和可观测云原生等非常前沿的知识布道，其中有，云原生在Logging、Metrics和Tracing的相关知识，Istio，K8S等方面的实践。对一些公司在前沿技术的落地，非常有借鉴意义。\n15：45-16：25 针对HikariCP数据库连接池的监控 张鑫老师本次分享了，以一个SkyWalking无法Tracing的实际线上故障的故事出发，讲述如何定位，和补充SkyWalking插件的不足，并将最后的实践贡献到社区。对大家参与开源很有帮助。\n16：25-17：00 SkyWalking 与 Nginx 的优化实践 王院生老师本次分享SkyWalking社区和APISIX社区合作，在Nginx插件的实践过程，对社区之间的如何开展合作，非常有借鉴意义，院生老师的工作\u0026amp;开源态度，很好的诠释Geek精神，也是我们互联网从业者需要学习恪守的。\nApache SkyWalking 2020 DevCon 讲师PPT Apache SkyWalking 2020 DevCon 讲师 PPT\nSkyWalking 后续发展计划 正如吴晟老师所说：No plan, open to the community，Apache SkyWalking是没有RoadMap。社区的后续发展，依赖于每个人在社区的贡献。与其期待，不如大胆设想，将自己的设计按照Apache Way贡献到SkyWalking，你就是下一个Apache SkyWalking Commiter，加入Member of SkyWalking大家庭，让社区因为你，而更加有活力。\n","excerpt":"作者: 赵禹光 原文链接: 亲临百人盛况的Apache SkyWalking 2020 DevCon，看见了什么？ 2020 年 10 月 29 日  活动现场 2020年11月14日Apache …","ref":"/zh/2020-11-21-what-do-we-see-at-the-apache-skywalking-2020-devcon-event/","title":"亲临百人盛况的Apache SkyWalking 2020 DevCon，看见了什么？"},{"body":"Sheng Wu is a founding engineer at tetrate.io, leads the observability for service mesh and hybrid cloud. A searcher, evangelist, and developer in the observability, distributed tracing, and APM. He is a member of the Apache Software Foundation. Love open source software and culture. Created the Apache SkyWalking project and being its VP and PMC member. Co-founder and PMC member of Apache ShardingSphere. Also as a PMC member of Apache Incubator and APISIX. He is awarded as Microsoft MVP, Alibaba Cloud MVP, Tencent Cloud TVP.\nIn the Apache FY2020 report, China is on the top of the download statistics. More China initiated projects joined the incubator, and some of them graduated as the Apache TLP. Sheng joined the Apache community since 2017, in the past 3 years, he witnessed the growth of the open-source culture and Apache way in China. Many developers have joined the ASF as new contributors, committers, foundation members. Chinese enterprises and companies paid more attention to open source contributions, rather than simply using the project like before. In the keynote, he would share the progress about China embracing the Apache culture, and willing of enhancing the whole Apache community.\n  ","excerpt":"Sheng Wu is a founding engineer at tetrate.io, leads the observability for service mesh and hybrid …","ref":"/blog/2020-11-21-apachecon-keynote/","title":"[Video] Apache grows in China"},{"body":"SkyWalking Client JS 0.2.0 is released. Go to downloads page to find release tars.\n Bug Fixes  Fixed a bug in sslTime calculate. Fixed a bug in server response status judgment.    ","excerpt":"SkyWalking Client JS 0.2.0 is released. Go to downloads page to find release tars.\n Bug Fixes  Fixed …","ref":"/events/release-apache-skywalking-client-js-0.2.0/","title":"Release Apache SkyWalking Client JS 0.2.0"},{"body":"SkyWalking Cloud on Kubernetes 0.1.0 is released. Go to downloads page to find release tars.\n Add OAPServer CRDs and controller.  ","excerpt":"SkyWalking Cloud on Kubernetes 0.1.0 is released. Go to downloads page to find release tars.\n Add …","ref":"/events/release-apache-skywalking-cloud-on-kubernetes-0.1.0/","title":"Release Apache SkyWalking Cloud on Kubernetes 0.1.0"},{"body":"Based on his continuous contributions, Jiapeng Liu (a.k.a evanljp) has been voted as a new committer.\n","excerpt":"Based on his continuous contributions, Jiapeng Liu (a.k.a evanljp) has been voted as a new …","ref":"/events/welcome-jiapeng-liu-as-new-committer/","title":"Welcome Jiapeng Liu as new committer"},{"body":"SkyWalking Kubernetes Helm Chart 4.0.0 is released. Go to downloads page to find release tars.\n Allow overriding configurations files under /skywalking/config. Unify the usages of different SkyWalking versions. Add Values for init container in case of using private regestry. Add services, endpoints resources in ClusterRole.  ","excerpt":"SkyWalking Kubernetes Helm Chart 4.0.0 is released. Go to downloads page to find release tars. …","ref":"/events/release-apache-skywalking-kubernetes-helm-chart-4.0.0/","title":"Release Apache SkyWalking Kubernetes Helm Chart 4.0.0"},{"body":"SkyWalking Client JS 0.1.0 is released. Go to downloads page to find release tars.\n Support Browser Side Monitoring. Require SkyWalking APM 8.2+.  ","excerpt":"SkyWalking Client JS 0.1.0 is released. Go to downloads page to find release tars.\n Support Browser …","ref":"/events/release-apache-skywalking-client-js0.1.0/","title":"Release Apache SkyWalking Client JS 0.1.0"},{"body":"","excerpt":"","ref":"/tags/browser/","title":"Browser"},{"body":" Author: Zhenxu Ke, Sheng Wu, Hongtao Gao, and Tevah Platt. tetrate.io Original link, Tetrate.io blog Oct. 29th, 2020  Apache SkyWalking, the observability platform, and open-source application performance monitor (APM) project, today announced the general availability of its 8.2 release. The release extends Apache SkyWalking’s functionalities and monitoring boundary to the browser side.\nBackground SkyWalking is an observability platform and APM tool that works with or without a service mesh, providing automatic instrumentation for microservices, cloud-native and container-based applications. The top-level Apache project is supported by a global community and is used by Alibaba, Huawei, Tencent, Baidu, ByteDance, and scores of others.\nBrowser side monitoring APM helps SRE and Engineering teams to diagnose system failures, or optimize the systems before they become intolerably slow. But is it enough to always make the users happy?\nIn 8.2.0, SkyWalking extends its monitoring boundary to the browser side, e.g., Chrome, or the network between Chrome and the backend service, or the codes running in the browser. With this, not only can we monitor the backend services and requests sent by the browser as usual, but also the front end rendering speed, error logs, etc., which are the most efficient metrics for capturing the experiences of our end users. (This does not currently extend to IoT devices, but this feature moves SkyWalking a step in that direction).\nWhat\u0026rsquo;s more, SkyWalking browser monitoring also provides data about how the users use products, such as PV(page views), UV(unique visitors), top N PV(page views), etc., which can give a product team clues for optimizing their products.\nQuery traces by tags In SkyWalking\u0026rsquo;s Span data model, there are many important fields that are already indexed and can be queried by the users, but for the sake of performance, querying by Span tags was not supported until now. In SkyWalking 8.2.0, we allow users to query traces by specified tags, which is extremely useful. For example, SRE engineers running tests on the product environment can tag the synthetic traffic and query by this tag later.\nMeter Analysis Language In 8.2.0, the meter system provides a functional analysis language called MAL(Meter Analysis Language) that allows users to analyze and aggregate meter data in the OAP streaming system. The result of an expression can be ingested by either the agent analyzer or OpenTelemetry/Prometheus analyzer.\nComposite Alert Rules Alerting is a good way to discover system failures in time. A common problem is that we configure too many triggers just to avoid missing any possible issue. Nobody likes to be woken up by alert messages at midnight, only to find out that the trigger is too sensitive. These kinds of alerts become noisy and don\u0026rsquo;t help at all.\nIn 8.2.0, users can now configure composite alert rules, where composite rules take multiple metrics dimensions into account. With composite alert rules, we can leverage as many metrics as needed to more accurately determine whether there’s a real problem or just an occasional glitch.\nCommon scenarios like successful rate \u0026lt; 90% but there are only 1~2 requests can now be resolved by a composite rule, such as traffic(calls per minute) \u0026gt; n \u0026amp;\u0026amp; successful rate \u0026lt; m%.\nOther Notable Enhancements  The agent toolkit exposes some APIs for users to send customizable metrics. The agent exclude_plugins allows you to exclude some plugins; mount enables you to load a new set of plugins. More than 10 new plugins have been contributed to the agent. The alert system natively supports sending alert messages to Slack, WeChat, DingTalk.  Additional Resources  Read more about the SkyWalking 8.2 release highlights. Get more SkyWalking updates on Twitter.  ","excerpt":"Author: Zhenxu Ke, Sheng Wu, Hongtao Gao, and Tevah Platt. tetrate.io Original link, Tetrate.io blog …","ref":"/blog/2020-10-29-skywalking8-2-release/","title":"Features in SkyWalking 8.2: Browser Side Monitoring; Query Traces by Tags; Meter Analysis Language"},{"body":"","excerpt":"","ref":"/zh_tags/release-blog/","title":"Release Blog"},{"body":" 作者: 柯振旭, 吴晟, 高洪涛, Tevah Platt. tetrate.io 原文链接: What\u0026rsquo;s new with Apache SkyWalking 8.2? Browser monitoring and more 2020 年 10 月 29 日  Apache SkyWalking，一个可观测性平台，也是一个开源的应用性能监视器（APM）项目，今日宣布 8.2 发行版全面可用。该发行版拓展了核心功能，并将其监控边界拓展到浏览器端。\n背景 SkyWalking 是一个观测平台和 APM 工具。它可以选择性的与 Service Mesh 协同工作，为微服务、云原生和基于容器的应用提供自动的指标。该项目是全球社区支持的 Apache 顶级项目，阿里巴巴、华为、腾讯、百度、字节跳动等许多公司都在使用。\n浏览器端监控 APM 可以帮助 SRE 和工程团队诊断系统故障，也能在系统异常缓慢之前优化它。但它是否足以让用户总是满意呢？\n在 8.2.0 版本中， SkyWalking 将它的监控边界拓展到了浏览器端，比如 Chrome ，或者 Chrome 和后端服务之间的网络。这样，我们不仅可以像以前一样监控浏览器发送给后端服务的与请求，还能看到前端的渲染速度、错误日志等信息——这些信息是获取最终用户体验的最有效指标。（目前此功能尚未拓展到物联网设备中，但这项功能使得 SkyWalking 向着这个方向前进了一步）\n此外，SkyWalking浏览器监视也提供以下数据: PV（page views，页面浏览量）， UV（unique visitors，独立访客数），浏览量前 N 的页面（Top N Page Views）等。这些数据可以为产品队伍优化他们的产品提供线索。\n按标签 (tag) 查询链路数据 在 SkyWalking 的 Span 数据模型中，已经有了许多被索引并可供用户查询的重要字段。但出于性能考虑，使用 Span 标签查询链路数据的功能直到现在才正式提供。在 SkyWalking 8.2.0 中，我们允许用户查询被特定标签标记的链路，这非常有用。SRE 工程师可以在生产环境中运行测试，将其打上仿真流量的标签，并稍后通过该标签查找它。\n指标分析语言 在 8.2.0 中，仪表系统提供了一项名为MAL（Meter Analysis Language，指标分析语言）的强大分析语言。该语言允许用户在 OAP 流系统中分析并聚合（aggregate）指标数据。 表达式的结果可以被 Agent 分析器或 OpenTelemetry/Prometheus 分析器获取。\n复合警报规则 警报是及时发现系统失效的有效方式。一个常见的问题是，为了避免错过任何可能的问题，我们通常会配置过多的触发器（triggers）。没有人喜欢半夜被警报叫醒，结果只是因为触发系统太敏感。这种警报很嘈杂并毫无帮助。\n在 8.2.0 版本中，用户选择可以配置考虑了多个度量维度的复合警报规则。使用复合报警规则，我们可以根据需要添加尽可能多的指标来更精确地判断是否存在真正的问题，或者只是一个偶发的小问题。\n一些常见的情况，如 成功率 \u0026lt; 90% 但只有 1~2 个请求，现在可以通过复合规则解决，如流量(即每分钟调用数) \u0026gt; n \u0026amp;\u0026amp; 成功率 \u0026lt; m%。\n其它值得注意的功能增强  agent-toolkit SDK 公开了某些 API，供用户发送自定义指标。 Agent exclude_plgins 配置允许您排除某些插件（plugins）; mount 配置使您能够加载一套新的插件。 社区贡献了超过 10 个新 Agent 插件。 报警系统原生支持发送消息到 Slack，企业微信，钉钉。  附加资源   阅读更多关于SkyWalkng 8.2 发行版重点.\n  在推特上获取更多关于 SkyWalking 的更新。\n  Apache SkyWalking DevCon 报名信息 Apache SkyWalking DevCon 2020 开始报名了。 2020 年 11 月 14 日，欢迎大家来线下参加活动和交流, 或者报名观看线上直播。\n","excerpt":"作者: 柯振旭, 吴晟, 高洪涛, Tevah Platt. tetrate.io 原文链接: What\u0026rsquo;s new with Apache SkyWalking 8.2? Browser …","ref":"/zh/2020-10-29-skywalking8-2-release/","title":"SkyWalking 8.2.0 中的新特性: 浏览器端监控; 使用标签查询; 指标分析语言"},{"body":"SkyWalking 8.2.0 is released. Go to downloads page to find release tars.\nProject  Support Browser monitoring. Add e2e test for ALS solution of service mesh observability. Support compiling(include testing) in JDK11. Support build a single module.  Java Agent  Support metrics plugin. Support slf4j logs of gRPC and Kafka(when agent uses them) into the agent log files. Add PROPERTIES_REPORT_PERIOD_FACTOR config to avoid the properties of instance cleared. Limit the size of traced SQL to avoid OOM. Support mount command to load a new set of plugins. Add plugin selector mechanism. Enhance the witness classes for MongoDB plugin. Enhance the parameter truncate mechanism of SQL plugins. Enhance the SpringMVC plugin in the reactive APIs. Enhance the SpringMVC plugin to collect HTTP headers as the span tags. Enhance the Kafka plugin, about @KafkaPollAndInvoke Enhance the configuration initialization core. Plugin could have its own plugins. Enhance Feign plugin to collect parameters. Enhance Dubbo plugin to collect parameters. Provide Thrift plugin. Provide XXL-job plugin. Provide MongoDB 4.x plugin. Provide Kafka client 2.1+ plugin. Provide WebFlux-WebClient plugin. Provide ignore-exception plugin. Provide quartz scheduler plugin. Provide ElasticJob 2.x plugin. Provide Spring @Scheduled plugin. Provide Spring-Kafka plugin. Provide HBase client plugin. Provide JSON log format. Move Spring WebFlux plugin to the optional plugin. Fix inconsistent logic bug in PrefixMatch Fix duplicate exit spans in Feign LoadBalancer mechanism. Fix the target service blocked by the Kafka reporter. Fix configurations of Kafka report don\u0026rsquo;t work. Fix rest template concurrent conflict. Fix NPE in the ActiveMQ plugin. Fix conflict between Kafka reporter and sampling plugin. Fix NPE in the log formatter. Fix span layer missing in certain cases, in the Kafka plugin. Fix error format of time in serviceTraffic update. Upgrade bytebuddy to 1.10.14  OAP-Backend  Support Nacos authentication. Support labeled meter in the meter receiver. Separate UI template into multiple files. Provide support for Envoy tracing. Envoy tracer depends on the Envoy community. Support query trace by tags. Support composite alarm rules. Support alarm messages to DingTalk. Support alarm messages to WeChat. Support alarm messages to Slack. Support SSL for Prometheus fetcher and self telemetry. Support labeled histogram in the prometheus format. Support the status of segment based on entry span or first span only. Support the error segment in the sampling mechanism. Support SSL certs of gRPC server. Support labeled metrics in the alarm rule setting. Support to query all labeled data, if no explicit label in the query condition. Add TLS parameters in the mesh analysis. Add health check for InfluxDB storage. Add super dataset concept for the traces/logs. Add separate replicas configuration for super dataset. Add IN operator in the OAL. Add != operator in the OAL. Add like operator in the OAL. Add latest function in the prometheus analysis. Add more configurations in the gRPC server. Optimize the trace query performance. Optimize the CPU usage rate calculation, at least to be 1. Optimize the length of slow SQL column in the MySQL storage. Optimize the topology query, use client side component name when no server side mapping. Add component IDs for Python component. Add component ID range for C++. Fix Slack notification setting NPE. Fix some module missing check of the module manager core. Fix authentication doesn\u0026rsquo;t work in sharing server. Fix metrics batch persistent size bug. Fix trace sampling bug. Fix CLR receiver bug. Fix end time bug in the query process. Fix Exporter INCREMENT mode is not working. Fix an error when executing startup.bat when the log directory exists Add syncBulkActions configuration to set up the batch size of the metrics persistent. Meter Analysis Language.  UI  Add browser dashboard. Add browser log query page. Support query trace by tags. Fix JVM configuration. Fix CLR configuration.  Document  Add the document about SW_NO_UPSTREAM_REAL_ADDRESS. Update ALS setup document. Add Customization Config section for plugin development.  All issues and pull requests are here\n","excerpt":"SkyWalking 8.2.0 is released. Go to downloads page to find release tars.\nProject  Support Browser …","ref":"/events/release-apache-skywalking-apm-8-2-0/","title":"Release Apache SkyWalking APM 8.2.0"},{"body":"高洪涛 美国ServiceMesh服务商tetrate创始工程师。原华为软件开发云技术专家。目前为Apache SkyWalking核心贡献者，参与该开源项目在软件开发云的商业化进程。曾任职当当网系统架构师，开源达人，曾参与Apache ShardingSphere，Elastic-Job等知名开源项目。对分布式数据库，容器调度，微服务，ServicMesh等技术有深入的了解。\n议题简介 定制化Operator模式在面向Kubernetes的云化平台建构中变得越来越流行。Apache SkyWalking社区已经开始尝试使用Operator模式去构建基于Kubernetes平台的PaaS云组件。本次分享给将会给听众带来该项目的初衷，实现与未来演进等相关内容。分享的内容包含：\n 项目动机与设计理念 核心功能展示，包含SkyWalking核心组件的发布，更新与维护。 观测ServiceMesh，包含于Istio的自动集成。 目前的工作进展和对未来的规划。   ","excerpt":"高洪涛 美国ServiceMesh服务商tetrate创始工程师。原华为软件开发云技术专家。目前为Apache SkyWalking核心贡献者，参与该开源项目在软件开发云的商业化进程。曾任职当当网系统 …","ref":"/zh/2020-10-25-coscon20-swck/","title":"[视频] Apache SkyWalking Cloud on Kubernetes"},{"body":"SkyWalking LUA Nginx 0.3.0 is released. Go to downloads page to find release tars.\n Load the base64 module in utils, different ENV use different library. Add prefix skywalking, avoid conflicts with other lua libraries. Chore: only expose the method of setting random seed, it is optional. Coc: use correct code block type. CI: add upstream_status to tag http.status Add http.status  ","excerpt":"SkyWalking LUA Nginx 0.3.0 is released. Go to downloads page to find release tars.\n Load the base64 …","ref":"/events/release-apache-skywalking-lua-nginx-0.3.0/","title":"Release Apache SkyWalking LUA Nginx 0.3.0"},{"body":"SkyWalking CLI 0.4.0 is released. Go to downloads page to find release tars.\n Features  Add dashboard global command with auto-refresh Add dashboard global-metrics command Add traces search Refactor metrics thermodynamic command to adopt the new query protocol   Bug Fixes  Fix wrong golang standard time    ","excerpt":"SkyWalking CLI 0.4.0 is released. Go to downloads page to find release tars.\n Features  Add …","ref":"/events/release-apache-skywalking-cli-0-4-0/","title":"Release Apache SkyWalking CLI 0.4.0"},{"body":"Huaxi Jiang (江华禧) (a.k.a. fgksgf) mainly focuses on the SkyWalking CLI project, he had participated in the \u0026ldquo;Open Source Promotion Plan - Summer 2020\u0026rdquo; and completed the project smoothly, and won the award \u0026ldquo;Most Potential Students\u0026rdquo; that shows his great willingness to continuously contribute to our community.\nUp to date, he has submitted 26 PRs in the CLI repository, 3 PRs in the main repo, all in total include ~4000 LOC.\nAt Sep. 28th, 2020, the project management committee (PMC) passed the proposal of promoting him as a new committer. He has accepted the invitation at the same day.\nWelcome to join the committer team, Huaxi!\n","excerpt":"Huaxi Jiang (江华禧) (a.k.a. fgksgf) mainly focuses on the SkyWalking CLI project, he had participated …","ref":"/events/welcome-huaxi-jiang-as-new-committer/","title":"Welcome Huaxi Jiang (江华禧) as new committer"},{"body":"SkyWalking Python 0.3.0 is released. Go to downloads page to find release tars.\n  New plugins\n Urllib3 Plugin (#69) Elasticsearch Plugin (#64) PyMongo Plugin (#60) Rabbitmq Plugin (#53) Make plugin compatible with Django (#52)    API\n Add process propagation (#67) Add tags to decorators (#65) Add Check version of packages when install plugins (#63) Add thread propagation (#62) Add trace ignore (#59) Support snapshot context (#56) Support correlation context (#55)    Chores and tests\n Test: run multiple versions of supported libraries (#66) Chore: add pull request template for plugin (#61) Chore: add dev doc and reorganize the structure (#58) Test: update test health check (#57) Chore: add make goal to package release tar ball (#54)    ","excerpt":"SkyWalking Python 0.3.0 is released. Go to downloads page to find release tars.\n  New plugins …","ref":"/events/release-apache-skywalking-python-0-3-0/","title":"Release Apache SkyWalking Python 0.3.0"},{"body":"吴晟 吴晟，Apache 基金会会员，Apache SkyWalking 创始人、项目 VP 和 PMC 成员，Apache 孵化器 PMC 成员，Apache ShardingSphere PMC成员，Apache APISIX PMC 成员，Apache ECharts (incubating) 和Apache DolphinScheduler (incubating) 孵化器导师，Zipkin 成员和贡献者。\n分享大纲  分布式追踪兴起的背景 SkyWalking和其他分布式追踪的异同 定位问题的流程和方法 性能剖析的由来、用途和优势  听众收获 听众能够全面的了解分布式追踪的技术背景，和技术原理。以及为什么这些年，分布式追踪和基于分布式追踪的APM系统，Apache SkyWalking，得到了广泛的使用、集成，甚至云厂商的支持。同时，除了针对追踪数据，我们应该关注更多的是，如何利用其产生的监控数据，定位系统的性能问题。以及它有哪些短板，应该如何弥补。\n ","excerpt":"吴晟 吴晟，Apache 基金会会员，Apache SkyWalking 创始人、项目 VP 和 PMC 成员，Apache 孵化器 PMC 成员，Apache ShardingSphere PMC成 …","ref":"/zh/2020-08-13-cloud-native-academy/","title":"[视频] 云原生学院 - 后分布式追踪时代的性能问题定位——方法级性能剖析"},{"body":"SkyWalking Chart 3.1.0 is released. Go to downloads page to find release tars.\n Support SkyWalking 8.1.0 Support enable oap dynamic configuration through k8s configmap  ","excerpt":"SkyWalking Chart 3.1.0 is released. Go to downloads page to find release tars.\n Support SkyWalking …","ref":"/events/release-apache-skywalking-chart-3-1-0-for-skywalking-8-1-0/","title":"Release Apache SkyWalking Chart 3.1.0 for SkyWalking 8.1.0"},{"body":" Author: Sheng Wu Original link, Tetrate.io blog  SkyWalking, a top-level Apache project, is the open source APM and observability analysis platform that is solving the problems of 21st-century systems that are increasingly large, distributed, and heterogenous. It\u0026rsquo;s built for the struggles system admins face today: To identify and locate needles in a haystack of interdependent services, to get apples-to-apples metrics across polyglot apps, and to get a complete and meaningful view of performance.\nSkyWalking is a holistic platform that can observe microservices on or off a mesh, and can provide consistent monitoring with a lightweight payload.\nLet\u0026rsquo;s take a look at how SkyWalking evolved to address the problem of observability at scale, and grew from a pure tracing system to a feature-rich observability platform that is now used to analyze deployments that collect tens of billions of traces per day.\nDesigning for scale When SkyWalking was first initialized back in 2015, its primary use case was monitoring the first-generation distributed core system of China Top Telecom companies, China Unicom and China Mobile. In 2013-2014, the telecom companies planned to replace their old traditional monolithic applications with a distributed system. Supporting a super-large distributed system and scaleablity were the high-priority design goals from Day one. So, what matters at scale?\nPull vs. push Pull and push modes relate to the direction of data flow. If the agent collects data and pushes them to the backend for further analysis, we call it \u0026ldquo;push\u0026rdquo; mode. Debate over pull vs. push has gone on for a long time. The key for an observability system is to minimize the cost of the agent, and to be generally suitable for different kinds of observability data.\nThe agent would send the data out a short period after it is collected. Then, we would have less concern about overloading the local cache. One typical case would be endpoint (URI of HTTP, service of gRPC) metrics. Any service could easily have hundreds, even thousands of endpoints. An APM system must have these metrics analysis capabilities.\nFurthermore, metrics aren\u0026rsquo;t the only thing in the observability landscape; traces and logs are important too. SkyWalking is designed to provide a 100% sampling rate tracing capability in the production environment. Clearly, push mode is the only solution.\nAt the same time, using push mode natively doesn\u0026rsquo;t mean SkyWalking can\u0026rsquo;t do data pulling. In recent 8.x releases, SkyWalking supports fetching data from Prometheus-instrumented services for reducing the Non-Recurring Engineering of the end users. Also, pull mode is popular in the MQ based transport, typically as a Kafka consumer. The SkyWalking agent side uses the push mode, and the OAP server uses the pull mode.\nThe conclusion: push mode is the native way, but pull mode works in some special cases too.\nMetrics analysis isn\u0026rsquo;t just mathematical calculation Metrics rely on mathematical theories and calculations. Percentile is a good measure for identifying the long tail issue, and reasonable average response time and successful rate are good SLO(s). But those are not all. Distributed tracing provides not just traces with detailed information, but high values metrics that can be analyzed.\nThe service topology map is required from Ops and SRE teams for the NOC dashboard and confirmation of system data flow. SkyWalking uses the STAM (Streaming Topology Analysis Method) to analyze topology from the traces, or based on ALS (Envoy Access Log Service) in the service mesh environment. This topology and metrics of nodes (services) and lines (service relationships) can\u0026rsquo;t be pulled from simple metrics SDKs.\nAs with fixing the limitation of endpoint metrics collection, SkyWalking needs to do endpoint dependency analysis from trace data too. Endpoint dependency analysis provides more important and specific information, including upstream and downstream. Those dependency relationships and metrics help the developer team to locate the boundaries of a performance issue, to specific code blocks.\nPre-calculation vs. query stage calculation? Query stage calculation provides flexibility. Pre-calculation, in the analysis stage, provides better and much more stable performance. Recall our design principle: SkyWalking targets a large-scale distributed system. Query stage calculation was very limited in scope, and most metrics calculations need to be pre-defined and pre-calculated. The key of supporting large datasets is reducing the size of datasets in the design level. Pre-calculation allows the original data to be merged into aggregated results downstream, to be used in a query or even for an alert check.\nTTL of metrics is another important business enabler. With the near linear performance offered by queries because of pre-calculation, with a similar query infrastructure, organizations can offer higher TTL, thereby providing extended visibility of performance.\nSpeaking of alerts, query-stage calculation also means the alerting query is required to be based on the query engine. But in this case, when the dataset increasing, the query performance could be inconsistent. The same thing happens in a different metrics query.\nCases today Today, SkyWalking is monitoring super large-scale distributed systems in many large enterprises, including Alibaba, Huawei, Tencent, Baidu, China Telecom, and various banks and insurance companies. The online service companies have more traffic than the traditional companies, like banks and telecom suppliers.\nSkyWalking is the observability platform used for a variety of use cases for distributed systems that are super-large by many measures:\n Lagou.com, an online job recruitment platform  SkyWalking is observing \u0026gt;100 services, 500+ JVM instances SkyWalking collects and analyzes 4+ billion traces per day to analyze performance data, including metrics of 300k+ endpoints and dependencies Monitoring \u0026gt;50k traffic per second in the whole cluster   Yonghui SuperMarket, online service  SkyWalking analyzes at least 10+ billion (3B) traces with metrics per day SkyWalking\u0026rsquo;s second, smaller deployment, analyzes 200+ million traces per day   Baidu, internet and AI company, Kubernetes deployment  SkyWalking collects 1T+ traces a day from 1,400+ pods of 120+ services Continues to scale out as more services are added   Beike Zhaofang(ke.com), a Chinese online property brokerage backed by Tencent Holdings and SoftBank Group  Has used SkyWalking from its very beginning, and has two members in the PMC team. Deployments collect 16+ billion traces per day   Ali Yunxiao, DevOps service on the Alibaba Cloud,  SkyWalking collects and analyzes billions of spans per day SkyWalking keeps AliCloud\u0026rsquo;s 45 services and ~300 instances stable   A department of Alibaba TMall, one of the largest business-to-consumer online retailers, spun off from Taobao  A customized version of SkyWalking monitors billions of traces per day At the same time, they are building a load testing platform based on SkyWalking\u0026rsquo;s agent tech stack, leveraging its tracing and context propagation cabilities    Conclusion SkyWalking\u0026rsquo;s approach to observability follows these principles:\n Understand the logic model: don\u0026rsquo;t treat observability as a mathematical tool. Identify dependencies first, then their metrics. Scaling should be accomplished easily and natively. Maintain consistency across different architectures, and in the performance of APM itself.  Resources  Read about the SkyWalking 8.1 release highlights. Get more SkyWalking updates on Twitter. Sign up to hear more about SkyWalking and observability from Tetrate.  ","excerpt":"Author: Sheng Wu Original link, Tetrate.io blog  SkyWalking, a top-level Apache project, is the open …","ref":"/blog/2020-08-11-observability-at-scale/","title":"Observability at Scale: SkyWalking it is"},{"body":" 作者：吴晟 翻译：董旭 金蝶医疗 原文链接：Tetrate.io blog  SkyWalking做为Apache的顶级项目，是一个开源的APM和可观测性分析平台，它解决了21世纪日益庞大、分布式和异构的系统的问题。它是为应对当前系统管理所面临的困难而构建的：就像大海捞针，SkyWalking可以在服务依赖复杂且多语言环境下，获取服务对应的指标，以及完整而有意义的性能视图。\nSkyWalking是一个非常全面的平台，无论你的微服务是否在服务网格(Service Mesh)架构下，它都可以提供高性能且一致性的监控。\n让我们来看看，SkyWalking是如何解决大规模集群的可观测性问题，并从一个纯粹的链路跟踪系统，发展成为一个每天分析百亿级跟踪数据，功能丰富的可观测性平台。\n为超大规模而生 SkyWalking的诞生，时间要追溯到2015年，当时它主要应用于监控顶级电信公司（例如：中国联通和中国移动）的第一代分布式核心系统。2013-2014年，这些电信公司计划用分布式系统取代传统的单体架构应用。从诞生那天开始，SkyWalking首要的设计目标，就是能够支持超大型分布式系统，并具有很好可扩展性。那么支撑超大规模系统要考虑什么呢？\n拉取vs推送 与数据流向息息相关的：拉取模式和推送模式。Agent（客户端）收集数据并将其推送到后端，再对数据进一步分析，我们称之为“推送”模式。究竟应该使用拉取还是推送？这个话题已经争论已久。关键因素取决于可观测性系统的目标，即：在Agent端花最小的成本，使其适配不同类型的可观测性数据。\nAgent收集数据后，可以在短时间内发送出去。这样，我们就不必担心本地缓存压力过大。举一个典型的例子，任意服务都可以轻松地拥有数百个甚至数千个端点指标（如：HTTP的URI，gRPC的服务）。那么APM系统就必须具有分析这些数量庞大指标的能力。\n此外，度量指标并不是可观测性领域中的唯一关注点，链路跟踪和日志也很重要。在生产环境下，SkyWalking为了能提供100%采样率的跟踪能力，数据推送模式是唯一可行的解决方案。\nSkyWalking即便使用了推送模式，同时也可进行数据拉取。在最近的8.x的发版本中，SkyWalking支持从已经集成Prometheus的服务中获取终端用户的数据，避免重复工程建设，减少资源浪费。另外，比较常见的是基于MQ的传输构建拉取模式，Kafka消费者就是一个比较典型的例子。SkyWalking的Agent端使用推送模式，OAP服务器端使用拉取模式。\n结论：SkyWalking的推送模式是原生方式，但拉取式模式也适用于某些特殊场景。\n度量指标分析并不仅仅是数学统计 度量指标依赖于数学理论和计算。Percentile（百分位数）是用于反映响应时间的长尾效应。服务具备合理的平均响应时间和成功率，说明服务的服务等级目标(SLO）很好。除此之外，分布式跟踪还为跟踪提供了详细的信息，以及可分析的高价值指标。\n运维团队（OPS）和系统稳定性（SRE）团队通过服务拓扑图，用来观察网络情况（当做NOC dashboard使用）、确认系统数据流。SkyWalking依靠trace（跟踪数据），使用STAM（Streaming Topology Analysis Method）方法进行分析拓扑结构。在服务网格环境下，使用ALS（Envoy Access Log Service）进行拓扑分析。节点（services）和线路（service relationships）的拓扑结构和度量指标数据，无法通过sdk轻而易举的拿到。\n为了解决端点度量指标收集的局限性，SkyWalking还要从跟踪数据中分析端点依赖关系，从而拿到链路上游、下游这些关键具体的信息。这些依赖关系和度量指标信息，有助于开发团队定位引起性能问题的边界，甚至代码块。\n预计算还是查询时计算？ 相比查询时计算的灵活性，预计算可以提供更好、更稳定的性能，这在分析场景下尤为重要。回想一下我们的设计原则：SkyWalking是为了一个大规模的分布式系统而设计。查询时计算的使用范围非常有限，大多数度量计算都需要预先定义和预先计算。支持大数据集的关键是：在设计阶段，要减小数据集。预计算允许将原始数据合并到下游的聚合结果中，用于查询，甚至用于警报检查。\n使用SkyWalking的另一个重要因素是：指标的有效期，TTL（Time To Live）。由于采用了预先计算，查询提供了近似线性的高性能。这也帮助“查询系统”这类基础设施系统，提供更好的性能扩展。\n关于警报，使用查询时计算方案，也意味着警报查询需要基于查询引擎。但在这种情况下，随着数据集增加，查询性能会随之下降，其他指标查询也是一样的结果。\n目前使用案例 如今，SkyWalking在许多大型企业的超大规模分布式系统中使用，包括阿里巴巴、华为、腾讯、百度、中国通讯企业以及多家银行和保险公司。上线SkyWalking公司的流量，比银行和电信运营商这种传统公司还要大。\n在很多行业中，SkyWalking是被应用于超大型分布式系统各种场景下的一个可观测性平台：\n  拉勾网\n  SkyWalking正在观测超过100个服务，500多个JVM实例\n  SkyWalking每天收集和分析40多亿个跟踪数据，用来分析性能，其中包括30万个端点和依赖关系的指标\n  在整个群集中监控\u0026gt;50k流量/秒\n    永辉超市\n  SkyWalking每天分析至少100多亿（3B）的跟踪数据\n  其次，SkyWalking用较小的部署，每天分析2亿多个跟踪数据\n    百度\n  SkyWalking每天从1400多个pod中，从120多个服务收集1T以上的跟踪数据\n  随着更多服务的增加，规模会持续增大\n    贝壳找房(ke.com)\n  很早就使用了SkyWalking，有两名成员已经成为PMC\n  Deployments每天收集160多亿个跟踪数据\n    阿里云效\n  SkyWalking每天收集和分析数十亿个span\n  SkyWalking使阿里云的45项服务和~300个实例保持稳定\n    阿里巴巴天猫\n  SkyWalking个性化定制版，每天监控数十亿跟踪数据\n  与此同时，他们基于SkyWalking的Agent技术栈，利用其跟踪和上下文传播能力，正在构建一个全链路压测平台\n    结论 SkyWalking针对可观测性遵循以下原则：\n 理解逻辑模型：不要把可观测性当作数学统计工具。 首先确定依赖关系，然后确定它们的度量指标。 原生和方便的支撑大规模增长。 在不同的架构情况下，APM各方面表现依然保持稳定和一致。  资源  阅读SkyWalking 8.1发布亮点。 在Twitter上获取更多SkyWalking更新。 注册Tetrate以了解更多有关SkyWalking可观测性的信息。  ","excerpt":"作者：吴晟 翻译：董旭 金蝶医疗 原文链接：Tetrate.io blog  SkyWalking做为Apache的顶级项目，是一个开源的APM和可观测性分析平台，它解决了21世纪日益庞大、分布式和异 …","ref":"/zh/2020-08-11-observability-at-scale-skywalking-it-is/","title":"SkyWalking 为超大规模而生"},{"body":"","excerpt":"","ref":"/zh_tags/use-case/","title":"Use Case"},{"body":" Author: Sheng Wu, Hongtao Gao, and Tevah Platt(Tetrate) Original link, Tetrate.io blog  Apache SkyWalking, the observability platform, and open-source application performance monitor (APM) project, today announced the general availability of its 8.1 release that extends its functionalities and provides a transport layer to maintain the lightweight of the platform that observes data continuously.\nBackground SkyWalking is an observability platform and APM tool that works with or without a service mesh, providing automatic instrumentation for microservices, cloud-native and container-based applications. The top-level Apache project is supported by a global community and is used by Alibaba, Huawei, Tencent, Baidu, and scores of others.\nTransport traces For a long time, SkyWalking has used gRPC and HTTP to transport traces, metrics, and logs. They provide good performance and are quite lightweight, but people kept asking about the MQ as a transport layer because they want to keep the observability data continuously as much as possible. From SkyWalking’s perspective, the MQ based transport layer consumes more resources required in the deployment and the complexity of deployment and maintenance but brings more powerful throughput capacity between the agent and backend.\nIn 8.1.0, SkyWalking officially provides the typical MQ implementation, Kafka, to transport all observability data, including traces, metrics, logs, and profiling data. At the same time, the backend can support traditional gRPC and HTTP receivers, with the new Kafka consumer at the same time. Different users could choose the transport layer(s) according to their own requirements. Also, by referring to this implementation, the community could contribute various transport plugins for Apache Pulsar, RabbitMQ.\nAutomatic endpoint dependencies detection The 8.1 SkyWalking release offers automatic detection of endpoint dependencies. SkyWalking has long offered automatic endpoint detection, but endpoint dependencies, including upstream and downstream endpoints, are critical for Ops and SRE teams’ performance analysis. The APM system is expected to detect the relationships powered by the distributed tracing. While SkyWalking has been designed to include this important information at the beginning the latest 8.1 release offers a cool visualization about the dependency and metrics between dependent endpoints. It provides a new drill-down angle from the topology. Once you have the performance issue from the service level, you could check on instance and endpoint perspectives:\nSpringSleuth metrics detection In the Java field, the Spring ecosystem is one of the most widely used. Micrometer, the metrics API lib included in the Spring Boot 2.0, is now adopted by SkyWalking’s native meter system APIs and agent. For applications using Micrometer with the SkyWalking agent installed, all Micrometer collected metrics could then be shipped into SkyWalking OAP. With some configurations in the OAP and UI, all metrics are analyzed and visualized in the SkyWalking UI, with all other metrics detected by SkyWalking agents automatically.\nNotable enhancements The Java agent core is enhanced in this release. It could work better in the concurrency class loader case and is more compatible with another agent solution, such as Alibaba’s Arthas.\n With the logic endpoint supported, the local span can be analyzed to get metrics. One span could carry the raw data of more than one endpoint’s performance. GraphQL, InfluxDB Java Client, and Quasar fiber libs are supported to be observed automatically. Kubernetes Configmap can now for the first time be used as the dynamic configuration center– a more cloud-native solution for k8s deployment environments. OAP supports health checks, especially including the storage health status. If the storage (e.g., ElasticSearch) is not available, you could get the unhealth status with explicit reasons through the health status query. Opencensus receiver supports ingesting OpenTelemetry/OpenCensus agent metrics by meter-system.  Additional resources  Read more about the SkyWalking 8.1 release highlights. Read more about SkyWalking from Tetrate on our blog. Get more SkyWalking updates on Twitter. Sign up to hear more about SkyWalking and observability from Tetrate.  ","excerpt":"Author: Sheng Wu, Hongtao Gao, and Tevah Platt(Tetrate) Original link, Tetrate.io blog  Apache …","ref":"/blog/2020-08-03-skywalking8-1-release/","title":"Features in SkyWalking 8.1: SpringSleuth metrics, endpoint dependency detection, Kafka transport traces and metrics"},{"body":"","excerpt":"","ref":"/tags/kafka/","title":"Kafka"},{"body":"SkyWalking APM 8.1.0 is release. Go to downloads page to find release tars.\nProject  Support Kafka as an optional trace, JVM metrics, profiling snapshots and meter system data transport layer. Support Meter system, including the native metrics APIs and the Spring Sleuth adoption. Support JVM thread metrics.  Java Agent  [Core] Fix the concurrency access bug in the Concurrency ClassLoader Case. [Core] Separate the config of the plugins from the core level. [Core] Support instrumented class cached in memory or file, to be compatible with other agents, such as Arthas. Add logic endpoint concept. Could analysis any span or tags flagged by the logic endpoint. Add Spring annotation component name for UI visualization only. Add support to trace Call procedures in MySQL plugin. Support GraphQL plugin. Support Quasar fiber plugin. Support InfluxDB java client plugin. Support brpc java plugin Support ConsoleAppender in the logback v1 plugin. Enhance vert.x endpoint names. Optimize the code to prevent mongo statements from being too long. Fix WebFlux plugin concurrency access bug. Fix ShardingSphere plugins internal conflicts. Fix duplicated Spring MVC endpoint. Fix lettuce plugin sometimes trace doesn‘t show span layer. Fix @Tag returnedObject bug.  OAP-Backend  Support Jetty Server advanced configurations. Support label based filter in the prometheus fetcher and OpenCensus receiver. Support using k8s configmap as the configuration center. Support OAP health check, and storage module health check. Support sampling rate in the dynamic configuration. Add endpoint_relation_sla and endpoint_relation_percentile for endpoint relationship metrics. Add components for Python plugins, including Kafka, Tornado, Redis, Django, PyMysql. Add components for Golang SDK. Add Nacos 1.3.1 back as an optional cluster coordinator and dynamic configuration center. Enhance the metrics query for ElasticSearch implementation to increase the stability. Reduce the length of storage entity names in the self-observability for MySQL and TiDB storage. Fix labels are missing in Prometheus analysis context. Fix column length issue in MySQL/TiDB storage. Fix no data in 2nd level aggregation in self-observability. Fix searchService bug in ES implementation. Fix wrong validation of endpoint relation entity query. Fix the bug caused by the OAL debug flag. Fix endpoint dependency bug in MQ and uninstrumented proxy cases. Fix time bucket conversion issue in the InfluxDB storage implementation. Update k8s client to 8.0.0  UI  Support endpoint dependency graph. Support x-scroll of trace/profile page Fix database selector issue. Add the bar chart in the UI templates.  Document  Update the user logo wall. Add backend configuration vocabulary document. Add agent installation doc for Tomcat9 on Windows. Add istioctl ALS commands for the document. Fix TTL documentation. Add FAQ doc about thread instrumentation.  CVE  Fix fuzzy query sql injection in the MySQL/TiDB storage.  All issues and pull requests are here\n","excerpt":"SkyWalking APM 8.1.0 is release. Go to downloads page to find release tars.\nProject  Support Kafka …","ref":"/events/release-apache-skywalking-apm-8-1-0/","title":"Release Apache SkyWalking APM 8.1.0"},{"body":"","excerpt":"","ref":"/tags/spring/","title":"Spring"},{"body":"Based on his continuous contributions, Wei Hua (a.k.a alonelaval) has been voted as a new committer.\n","excerpt":"Based on his continuous contributions, Wei Hua (a.k.a alonelaval) has been voted as a new committer.","ref":"/events/welcome-wei-hua-as-new-committer/","title":"Welcome Wei Hua as new committer"},{"body":"SkyWalking Python 0.2.0 is released. Go to downloads page to find release tars.\n  Plugins:\n Kafka Plugin (#50) Tornado Plugin (#48) Redis Plugin (#44) Django Plugin (#37) PyMsql Plugin (#35) Flask plugin (#31)    API\n Add ignore_suffix Config (#40) Add missing log method and simplify test codes (#34) Add content equality of SegmentRef (#30) Validate carrier before using it (#29)    Chores and tests\n Test: print the diff list when validation failed (#46) Created venv builders for linux/windows and req flashers + use documentation (#38)    ","excerpt":"SkyWalking Python 0.2.0 is released. Go to downloads page to find release tars.\n  Plugins:\n Kafka …","ref":"/events/release-apache-skywalking-python-0-2-0/","title":"Release Apache SkyWalking Python 0.2.0"},{"body":"SkyWalking CLI 0.3.0 is released. Go to downloads page to find release tars.\n Command: health check command Command: Add trace command BugFix: Fix wrong metrics graphql path  ","excerpt":"SkyWalking CLI 0.3.0 is released. Go to downloads page to find release tars.\n Command: health check …","ref":"/events/release-apache-skywalking-cli-0-3-0/","title":"Release Apache SkyWalking CLI 0.3.0"},{"body":" Author: Srinivasan Ramaswamy, tetrate Original link, Tetrate.io blog  Asking How are you is more profound than What are your symptoms Background Recently I visited my preferred doctor. Whenever I visit, the doctor greets me with a series of light questions: How’s your day? How about the week before? Any recent trips? Did I break my cycling record? How’s your workout regimen? _Finally _he asks, “Do you have any problems?\u0026rdquo; On those visits when I didn\u0026rsquo;t feel ok, I would say something like, \u0026ldquo;I\u0026rsquo;m feeling dull this week, and I\u0026rsquo;m feeling more tired towards noon….\u0026quot; It\u0026rsquo;s at this point that he takes out his stethoscope, his pulse oximeter, and blood pressure apparatus. Then, if he feels he needs a more in-depth insight, he starts listing out specific tests to be made.\nWhen I asked him if the first part of the discussion was just an ice-breaker, he said, \u0026ldquo;That\u0026rsquo;s the essential part. It helps me find out how you feel, rather than what your symptoms are.\u0026quot; So, despite appearances, our opening chat about life helped him structure subsequent questions on symptoms, investigations and test results.\nOn the way back, I couldn\u0026rsquo;t stop asking myself, \u0026ldquo;Shouldn\u0026rsquo;t we be managing our mesh this way, too?\u0026quot;\nIf I strike parallels between my own health check and a health check, “tests” would be log analysis, “investigations” would be tracing, and “symptoms” would be the traditional RED (Rate, Errors and Duration) metrics. That leaves the “essential part,” which is what we are talking about here: the Wellness Factor, primarily the health of our mesh.\nHealth in the context of service mesh We can measure the performance of any observed service through RED metrics. RED metrics offer immense value in understanding the performance, reliability, and throughput of every service. Compelling visualizations of these metrics across the mesh make monitoring the entire mesh standardized and scalable. Also, setting alerts based on thresholds for each of these metrics helps to detect anomalies as and when they arise.\nTo establish the context of any service and observe them, it\u0026rsquo;s ideal to visualize the mesh as a topology.\nA topology visualization of the mesh not only allows for picking any service and watching its metrics, but also gives vital information about service dependencies and the potential impact of a given service on the mesh.\nWhile RED metrics of each service offer tremendous insights, the user is more concerned with the overall responsiveness of the mesh rather than each of these services in isolation.\nTo describe the performance of any service, right from submitting the request to receiving a completed http response, we’d be measuring the user\u0026rsquo;s perception of responsiveness. This measure of response time compared with a set threshold is called Apdex. This Apdex is an indicator of the health of a service in the mesh.\nApdex Apdex is a measure of response time considered against a set threshold**. **It is the ratio of satisfactory response times and unsatisfactory response times to total response times.\nApdex is an industry standard to measure the satisfaction of users based on the response time of applications and services. It measures how satisfied your users are with your services, as traditional metrics such as average response time could get skewed quickly.\nSatisfactory response time indicates the number of times when the roundtrip response time of a particular service was less than this threshold. Unsatisfactory response time while meaning the opposite, is further categorized as Tolerating and Frustrating. Tolerating accommodates any performance that is up to four times the threshold, and anything over that or any errors encountered is considered Frustrating. The threshold mentioned here is an ideal roundtrip performance that we expect from any service. We could even start with an organization-wide limit of say, 500ms.\nThe Apdex score is a ratio of satisfied and tolerating requests to the total requests made.\nEach satisfied request counts as one request, while each tolerating request counts as half a satisfied request.\nAn Apdex score takes values from 0 to 1, with 0 being the worst possible score indicating that users were always frustrated, and ‘1’ as the best possible score (100% of response times were Satisfactory).\nA percentage representation of this score also serves as the Health Indicator of the service.\nThe Math The actual computation of this Apdex score is achieved through the following formula.\n\tSatisfiedCount + ( ToleratingCount / 2 ) Apdex Score = ------------------------------------------------------ TotalSamples A percentage representation of this score is known as the Health Indicator of a service.\nExample Computation During a 2-minute period, a host handles 200 requests.\nThe Apdex threshold T = 0.5 seconds (500ms).\n 170 of the requests were handled within 500ms, so they are classified as Satisfied. 20 of the requests were handled between 500ms and 2 seconds (2000 ms), so they are classified as Tolerating. The remaining 10 were not handled properly or took longer than 2 seconds, so they are classified as Frustrated.  The resulting Apdex score is 0.9: (170 + (20/2))/200 = 0.9.\nThe next level At the next level, we can attempt to improve our topology visualization by coloring nodes based on their health. Also, we can include health as a part of the information we show when the user taps on a service.\nApdex specifications recommend the following Apdex Quality Ratings by classifying Apdex Score as Excellent (0.94 - 1.00), Good (0.85 - 0.93), Fair (0.70 - 0.84), Poor (0.50 - 0.69) and Unacceptable (0.00 - 0.49).\nTo visualize this, let’s look at our topology using traffic light colors, marking our nodes as Healthy, At-Risk and Unhealthy, where Unhealthy indicates health that falls below 80%. A rate between 80% and 95% indicates At-Risk, and health at 95% and above is termed Healthy.\nLet’s incorporate this coloring into our topology visualization and take its usability to the next level. If implemented, we will be looking at something like this.\nMoving further Apdex provides tremendous visibility into customer satisfaction on the responsiveness of our services. Even more, by extending the implementation to the edges calling this service we get further insight into the health of the mesh itself.\nTwo services with similar Apdex scores offer the same customer satisfaction to the customer. However, the size of traffic that flows into the service can be of immense help in prioritizing between services to address. A service with higher traffic flow is an indication that this experience is impacting a significant number of users on the mesh.\nWhile health relates to a service, we can also analyze the interactions between two services and calculate the health of the interaction. This health calculation of every interaction on the mesh helps us establish a critical path, based on the health of all interactions in the entire topology.\nIn a big mesh, showing traffic as yet another number will make it more challenging to visualize and monitor. We can, with a bit of creativity, improve the entire visualization by rendering the edges that connect services with different thickness depending on the throughput of the service.\nAn unhealthy service participating in a high throughput transaction could lead to excessive consumption of resources. On the other hand, this visualization also offers a great tip to maximize investment in tuning services.\nTuning service that is a part of a high throughput transaction offers exponential benefits when compared to tuning an occasionally used service.\nIf we look at implementing such a visualization, which includes the health of interactions and throughput of such interactions, we would be looking at something like below :\nThe day is not far These capabilities are already available to users today as one of the UI features of Tetrate’s service mesh platform, using the highly configurable and performant observability and performance management framework: Apache SkyWalking (https://skywalking.apache.org), which monitors traffic across the mesh, aggregates RED metrics for both services and their interactions, continuously computes and monitors health of the services, and enables users to configure alerts and notifications when services cross specific thresholds, thereby having a comprehensive health visibility of the mesh.\nWith such tremendous visibility into our mesh performance, the day is not far when we at our NOC (Network Operations Center) for the mesh have this topology as our HUD (Heads Up Display).\nThis HUD, with the insights and patterns gathered over time, would predict situations and proactively prompt us on potential focus areas to improve customer satisfaction.\nThe visualization with rich historical data can also empower the Network Engineers to go back in time and look at the performance of the mesh on a similar day in the past.\nAn earnest implementation of such a visualization would be something like below :\nTo conclude With all the discussion so far, the health of a mesh is more about how our users feel, and what we can proactively do as service providers to sustain, if not enhance, the experience of our users.\nAs the world advances toward personalized medicine, we\u0026rsquo;re not far from a day when my doctor will text me: \u0026ldquo;How about feasting yourself with ice cream today and take the Gray Butte Trail to Mount Shasta!\u0026rdquo; Likewise, we can do more for our customers by having better insight into their overall wellness.\nTetrate’s approach to “service mesh health” is not only to offer management, monitoring and support but to make infrastructure healthy from the start to reduce the probability of incidents. Powered by the Istio, Envoy, and SkyWalking, Tetrate\u0026rsquo;s solutions enable consistent end-to-end observability, runtime security, and traffic management for any workload in any environment.\nOur customers deserve healthy systems! Please do share your thoughts on making service mesh an exciting and robust experience for our customers.\nReferences  https://en.wikipedia.org/wiki/Apdex https://www.apdex.org/overview.html https://www.apdex.org/index.php/specifications/ https://skywalking.apache.org/  ","excerpt":"Author: Srinivasan Ramaswamy, tetrate Original link, Tetrate.io blog  Asking How are you is more …","ref":"/blog/2020-07-26-apdex-and-skywalking/","title":"The Apdex Score for Measuring Service Mesh Health"},{"body":" 作者: Srinivasan Ramaswamy, tetrate 翻译：唐昊杰，南京大学在读学生 校对：吴晟 Original link, Tetrate.io blog July. 26th, 2020  \u0026ldquo;你感觉怎么样\u0026rdquo; 比 \u0026ldquo;你的症状是什么\u0026rdquo; 更重要 背景 最近我拜访了我的医生。每次去看病，医生都会首先问我一连串轻快的问题，比如：你今天过得怎么样？上周过的怎么样？最近有什么出行吗？你打破了自己的骑车记录吗？你的锻炼计划实施如何？最后他会问：“你有什么麻烦吗？”如果这个时候我感觉自己不太好，我会说：“我这周感觉很沉闷，临近中午的时候感觉更累。”这时他就会拿出听诊器、脉搏血氧仪和血压仪。然后，如果他觉得自己需要更深入的了解情况，他就开始列出我需要做的具体检查。\n当我问他，最开始的讨论是否只是为了缓和氛围。他说：“这是必不可少的部分。它帮助我发现你感觉如何，而不是你的症状是什么。\u0026quot;。我们这样关于生活的开场聊天，帮助他组织了后续关于症状、调查和测试结果的问题。\n在回来的路上，我不停地问自己：“我们是不是也应该用这种方式管理我们的网格(service mesh)？”\n如果我把自己的健康检查和网格的健康检查进行类比，“医疗检查”就是日志分析，“调查”就是追踪，“症状”就是传统的RED指标（请求速率、请求错误和请求耗时）。那么根本的问题，就是我们在这里讨论的：健康因素（主要是网格的健康）。\n服务网格中的健康状况 我们可以通过RED指标来衡量任何被观察到的服务的性能。RED指标在了解每个服务的性能、可靠性和吞吐量方面提供了巨大的价值。这些指标在网格上的令人信服的可视化使得监控全部网格变得标准化和可扩展。此外，根据这些指标的阈值设置警报有助于在指标值异常的时候进行异常检测。\n为了建立任何服务的上下文环境并观察它们，理想的做法是将网格可视化为一个拓扑结构。\n网格的拓扑结构可视化不仅允许使用者挑选任意服务并观察其指标，还可以提供有关服务依赖和特定服务在网格上的潜在影响这些重要信息。\n虽然每个服务的RED指标为使用者提供了深刻的洞察能力，但使用者更关心网格的整体响应性，而非每个单独出来的服务的响应性。\n为了描述任意服务的性能（即从提交请求到收到完成了的http响应这段时间内的表现），我们会测量用户对响应性的感知。这种将响应时间与设定的阈值进行比较的衡量标准叫做Apdex。Apdex是衡量一个服务在网格中的健康程度的指标。\nApdex Apdex是根据设定的阈值和响应时间结合考虑的衡量标准。它是满意响应时间和不满意响应时间相对于总响应时间的比率。\nApdex是根据应用和服务的响应时间来衡量使用者满意程度的行业标准。它衡量的是用户对你的服务的满意程度，因为传统的指标（如平均响应时间）可能很快就会容易形成偏差。\n基于满意度的响应时间，表示特定服务的往返响应时间小于设定的阈值的次数。不满意响应时间虽然意思相反，但又进一步分为容忍型和失望型。容忍型包括了了任何响应时间不超过四倍阈值的表现，而任何超过四倍阈值或遇到了错误的表现都被认为是失望型。这里提到的阈值是我们对任意服务所期望的理想响应表现。我们可以设置一个全局范围的阈值，如，500ms。\nApdex得分是满意型请求和容忍型请求与做出的总请求的比率。\n每个_满意的请求_算作一个请求，而每个_容忍的请求_算作半个_满意_的请求。\n一个Apdex得分从0到1的范围内取值。0是最差的分数，表示用户总是感到失望；而'1\u0026rsquo;是最好的分数（100%的响应时间是令人满意的）。\n这个分数的百分比表示也可以用作服务的健康指标。\n数学表示 Apdex得分的实际计算是通过以下公式实现的：\n\t满意请求数 + ( 容忍请求数 / 2 ) Apdex 得分 = ------------------------------------------------------ 总请求数 此公示得到的百分率，即可视为服务的健康度。\n样例计算 在两分钟的采样时间内，主机处理200个请求。\nApdex阈值T设置为0.5秒（500ms）。\n*.\t170个请求在500ms内被处理完成，它们被分类为满意型。 *.\t20个请求在500ms和2秒间被处理，它们被分类为容忍型。 *.\t剩余的10个请求没有被正确处理或者处理时间超过了2秒，所以它们被分类为失望型。\n最终的Apdex得分是0.9，即（170 + （20 / 2））/ 200。\n深入使用 在接下来的层次，我们可以尝试通过根据节点的健康状况来着色节点以改进我们的拓扑可视化。此外，我们还可以在用户点击服务时将健康状况作为我们展示的信息的一部分。\nApdex规范推荐了以下Apdex质量评级，将Apdex得分分为优秀（0.94 - 1.00）、良好（0.85 - 0.93）、一般（0.70 - 0.84）、差（0.50 - 0.69）和不可接受（0.00 - 0.49）。\n为了可视化网格的健康状况，我们用交通灯的颜色将我们的节点标记为健康、有风险和不健康，其中不健康表示健康率低于80%。健康率在80%到95%之间的表示有风险，健康率在95%及以上的称为健康。\n让我们将这种着色融入到我们的拓扑可视化中，并将其可用性提升到一个新的水平。如果实施，我们将看到下图所示的情况。\n更进一步 Apdex为客户对我们服务响应性的满意度提供了可见性。更有甚者，通过将实施范围扩展到调用该服务的调用关系，我们可以进一步了解网格本身的健康状况。\n两个有着相似Apdex分数的服务，为客户提供了相同的客户满意度。然而，流入服务的流量大小对于优先处理哪一服务有着巨大的帮助。流量较高的服务表明这种服务体验影响了网格上更大量的使用者。\n虽然健康程度与单个服务有关，但我们也可以分析两个服务之间的交互并计算交互过程的健康程度。这种对网格上每一个交互的健康程度的计算，可以帮助我们根据整个拓扑结构中所有交互的健康程度，建立一个关键路径。\n在一个大的网格中，将流量展示为另一个数字将使可视化和监控更具挑战性。我们可以根据服务的吞吐量，通过用不同的粗细程度渲染连接服务的边来改善整个可视化的效果。\n一个位于高吞吐量事务的不健康的服务可能会导致资源的过度消耗。另一方面，这种可视化也为调整服务时获取最大化投资效果提供了一个很好的提示。\n与调整一个偶尔使用的服务相比，调整作为高吞吐量事务的一部分的那些服务会带来指数级的收益。\n实施这种包括了交互的健康状况和吞吐量的可视化，我们会看到下图所示的情况:\n这一天即将到来 目前，这些功能已经作为Tetrate服务网格平台的UI功能之一来提供给用户。该平台使用了高速可配置化、高性能的可观测性和监控性能管理平台：Apache SkyWalking (https://skywalking.apache.org)，SkyWalking可以监控整个网格的流量，为服务及它们的交互合计RED指标，持续计算和监控服务的健康状况，并使用户能够在服务超过特定阈值时配置报警和通知。这些功能使得SkyWalking对网格拥有全面的健康状况可见性。\n有了这样强大的网格性能可视性，我们将可以在为网格准备的网络运营中心使用这种拓扑结构作为我们的HUD（Heads Up Display）。\nHUD随着时间的推移收集了解到的信息和模式，并将预测各种情况和主动提示我们潜在的重点领域以提高客户满意度。\n丰富的历史数据的可视化也可以使网络工程师能够看看过去中类似的一天的网格表现。\n可视化效果如下图所示。\n总结 综合到目前为止的所有讨论，网格的健康状况更多地是关于用户的感受，以及我们作为服务提供商可以采取积极行动来维持（如果不能增强）用户的体验。\n着个人化医学的发展，现在距离我的医生给我发这样短信的日子并不遥远：“要不今天享用冰淇淋并且沿着灰色小山步道到达沙斯塔山！”相似的，我们可以通过更好地了解客户的整体健康状况为他们做更多的事情。\nTetrate的“服务网格健康程度”方法不仅提供了管理，监视和支持，而且从一开始就使基础架构保持健康以减少事故发生的可能性。在Istio，Envoy和SkyWalking的支持下，Tetrate的解决方案可为任何环境中的任何工作负载提供持续的端到端可观察性，运行时安全性和流量管理。\n我们的客户应该拥有健康的系统！请分享您对使用服务网格为我们的客户带来令人兴奋和强健的体验的想法。\n引用  https://en.wikipedia.org/wiki/Apdex https://www.apdex.org/overview.html https://www.apdex.org/index.php/specifications/ https://skywalking.apache.org/  ","excerpt":"作者: Srinivasan Ramaswamy, tetrate 翻译：唐昊杰，南京大学在读学生 校对：吴晟 Original link, Tetrate.io blog July. 26th, …","ref":"/zh/2020-07-26-apdex-and-skywalking/","title":"度量服务网格健康度——Apdex得分"},{"body":"SkyWalking Python 0.1.0 is released. Go to downloads page to find release tars.\n API: agent core APIs, check the APIs and the examples Plugin: built-in libraries http, urllib.request and third-party library requests are supported. Test: agent test framework is setup, and the corresponding tests of aforementioned plugins are also added.  ","excerpt":"SkyWalking Python 0.1.0 is released. Go to downloads page to find release tars.\n API: agent core …","ref":"/events/release-apache-skywalking-python-0-1-0/","title":"Release Apache SkyWalking Python 0.1.0"},{"body":"SkyWalking Chart 3.0.0 is released. Go to downloads page to find release tars.\n Support SkyWalking 8.0.1  ","excerpt":"SkyWalking Chart 3.0.0 is released. Go to downloads page to find release tars.\n Support SkyWalking …","ref":"/events/release-apache-skywalking-chart-3-0-0-for-skywalking-8-0-1/","title":"Release Apache SkyWalking Chart 3.0.0 for SkyWalking 8.0.1"},{"body":"Apache SkyWalking 8.0.1 已发布。SkyWalking 是观察性分析平台和应用性能管理系统，提供分布式追踪、服务网格遥测分析、度量聚合和可视化一体化解决方案，支持 Java, .Net Core, PHP, NodeJS, Golang, LUA 语言探针，支持 Envoy + Istio 构建的 Service Mesh。\n与 8.0.0 相比，此版本包含一个热修复程序。\nOAP-Backend\n 修复 no-init 模式在 Elasticsearch 存储中无法运行的错误  8.0.0 值得关注的变化：\n 添加并实现了 v3 协议，旧版本与 8.x 不兼容 移除服务、实例、端点注册机制和 inventory 存储实体 (inventory storage entities) 提供新的 GraphQL 查询协议，同时支持旧协议（计划在今年年底移除） 支持 Prometheus 网络协议，可将 Prometheus 格式的指标传输到 SkyWalking 中 提供 Python agent 移除所有 inventory 缓存 提供 Apache ShardingSphere (4.0.0, 4.1.1) agent 插件 UI dashboard 100% 可配置，可采用后台定义的新指标 修复 H2/MySQL 实现中的 SQL 注入漏洞 Upgrade Nacos to avoid the FastJson CVE in high frequency. 升级 Nacos 以避免 FastJson CVE 升级 jasckson-databind 至 2.9.10  下载地址：http://skywalking.apache.org/downloads/\n","excerpt":"Apache SkyWalking 8.0.1 已发布。SkyWalking 是观察性分析平台和应用性能管理系统，提供分布式追踪、服务网格遥测分析、度量聚合和可视化一体化解决方案，支持 Java, …","ref":"/zh/2020-06-21-skywalking8-0-1-release/","title":"Apache SkyWalking 8.0.1 发布"},{"body":"SkyWalking Nginx LUA 0.2.0 is release. Go to downloads page to find release tars.\n Adapt the new v3 protocol. Implement correlation protocol. Support batch segment report.  ","excerpt":"SkyWalking Nginx LUA 0.2.0 is release. Go to downloads page to find release tars.\n Adapt the new v3 …","ref":"/events/release-apache-skywalking-nginx-lua-0-2-0/","title":"Relase Apache SkyWalking Nginx LUA 0.2.0"},{"body":"SkyWalking APM 8.0.0 is release. Go to downloads page to find release tars.\nProject  v3 protocol is added and implemented. All previous releases are incompatible with 8.x releases. Service, Instance, Endpoint register mechanism and inventory storage entities are removed. New GraphQL query protocol is provided, the legacy procotol is still supported(plan to remove at the end of this year). Support Prometheus network protocol. Metrics in Prometheus format could be transferred into SkyWalking. Python agent provided. All inventory caches have been removed. Apache ShardingSphere(4.1.0, 4.1.1) agent plugin provided.  Java Agent  Add MariaDB plugin. Vert.x plugin enhancement. More cases are covered. Support v3 extension header. Fix ElasticSearch 5.x plugin TransportClient error. Support Correlation protocol v1. Fix Finagle plugin bug, in processing Noop Span. Make CommandService daemon to avoid blocking target application shutting down gracefully. Refactor spring cloud gateway plugin and support tracing spring cloud gateway 2.2.x  OAP-Backend  Support meter system for Prometheus adoption. In future releases, we will add native meter APIs and MicroMeter(Sleuth) system. Support endpoint grouping. Add SuperDataSet annotation for storage entity. Add superDatasetIndexShardsFactor in the ElasticSearch storage, to provide more shards for @SuperDataSet annotated entites. Typically TraceSegment. Support alarm settings for relationship of service, instance, and endpoint level metrics. Support alarm settings for database(conjecture node in tracing scenario). Data Model could be added in the runtime, don\u0026rsquo;t depend on the bootstrap sequence anymore. Reduce the memory cost, due to no inventory caches. No buffer files in tracing and service mesh cases. New ReadWriteSafe cache implementation. Simplify codes. Provide default way for metrics query, even the metrics doesn\u0026rsquo;t exist. New GraphQL query protocol is provided. Support the metrics type query. Set up length rule of service, instance, and endpoint. Adjust the default jks for ElasticSearch to empty. Fix Apdex function integer overflow issue. Fix profile storage issue. Fix TTL issue. Fix H2 column type bug. Add JRE 8-14 test for the backend.  UI  UI dashboard is 100% configurable to adopt new metrics definited in the backend.  Document  Add v8 upgrade document. Make the coverage accurate including UT and e2e tests. Add miss doc about collecting parameters in the profiled traces.  CVE  Fix SQL Injection vulnerability in H2/MySQL implementation. Upgrade Nacos to avoid the FastJson CVE in high frequency. Upgrade jasckson-databind to 2.9.10.  All issues and pull requests are here\n","excerpt":"SkyWalking APM 8.0.0 is release. Go to downloads page to find release tars.\nProject  v3 protocol is …","ref":"/events/release-apache-skywalking-apm-8-0-0/","title":"Release Apache SkyWalking APM 8.0.0"},{"body":"可观察性平台和开源应用程序性能监控（APM）项目 Apache SkyWalking，今天刚宣布 8.0 的发布版本。素以强劲指标、追踪与服务网格能力见称的 SkyWalking ，在最新版本中的功能性延展到用户渴求已久的功能 —— 将指标功能和包括 Prometheus 的其他指标收集系统进行了融合。\n什么是 Apache SkyWalking？ SkyWalking 是可观察性平台和 APM 工具，可以选择是否搭载服务网格的使用，为微服务、云原生和容器化应用提供自动度量功能。顶尖的 Apache 项目由来自世界各地的社区人员支持，应用在阿里巴巴、华为、腾讯、百度和大量其他企业。SkyWalking 提供记录、监控和追踪功能，同时也得力于其架构而拥有数据收集终端、分析平台，还有用户界面。\n值得关注的优化包括：  用户界面 Dashboard 上提供百分百的自由度，用户可以任意进行配置，采用后台新定义的指标。 支持 Prometheus 导出格式。Prometheus 格式的指标可以转换至 SkyWalking。 SkyWalking 现已可以自主监控服务网格，为 Istio 和 Envoy 提供指标。 服务、实例、终端地址的注册机制，和库存存储实体已经被移除了。  无须修改原始码的前提下，为用户界面加入新的指标 对于 SkyWalking 的用户，8.0 版本的亮点将会是数据模型的更新，而且传播格式也针对更多语言进行优化。再加上引进了新的 MeterSystem ，除了可以同步运行传统追踪模式，用户还可自定义需要收集的指标。追踪和服务网格专注在拓扑和服务流量的指标上，而 MeterSystem 则汇报用户感兴趣的业务指标，例如是数据库存取性能、圣诞节期间的下单率，或者用户注册或下单的百分比。这些指标数据会在 SkyWalking 的用户界面 Dashboard 上以图像显示。指标的面板数据和拓扑图可以通过 Envoy 的指标绘制，而追踪分析也可以支持 Istio 的遥测。Dashboard 还支持以 JSON 格式导入、导出，而 Dashboard 上的自定义指标也支持设定指标名称、实体种类（服务、实例、终端地址或全部）、标记值等。用户界面模板上已详细描述了用户界面的逻辑和原型配置，以及它的 Dashboard、tab 和组件。\n观察任何配备了 Prometheus 的应用 在这次最新的社区发布中，SkyWalking 可以观察任何配备了 Prometheus 或者提供了 Prometheus 终端地址的应用。这项更新为很多想采用 SkyWalking 指标和追踪的用户节省了不少时间，现在你不再需要重新设置指标工具，就可以获得 Prometheus 数据。因为 Prometheus 更简单、更为人熟悉，是不少用户的不二选择。有了 8.0 版本，Prometheus 网络协议就能够读取所有已设定在 API 上的数据，另外 Prometheus 格式的指标也可转换至 SkyWalking 上。如此一来，通过图像方式展示，所有的指标和拓扑都能一目了然。同时，也支持 Prometheus 的 fetcher。\n监控你的网格 SkyWalking 现在不再只是监控服务或平台，而是监控整个网格。有了 8.0 版本，你除了能获取关于你的网格的指标（包括 Istio 和 Envoy 在内），同时也能通过 SkyWalking 监控自身的性能。因为当监控服务在观察业务集群的同时，它也能实现自我观察，确保运维团队拥有稳定可靠的平台。\n性能优化 最后，8.0 发布移除了注册机制，也不再需要使用独一无二的整数来代表实体。这项改变将大幅优化性能。想了解完整的更新功能列表，可以阅读在 SkyWalking 社区发布的公告页面。\n额外资源  追踪 Twitter 获取更多 SkyWalking 最新资讯 SkyWalking 未来的发布会加入原生指标 API 和融合 Micrometer (Sleuth) 指标集合。  ","excerpt":"可观察性平台和开源应用程序性能监控（APM）项目 Apache SkyWalking，今天刚宣布 8.0 的发布版本。素以强劲指标、追踪与服务网格能力见称的 SkyWalking ，在最新版本中的功能 …","ref":"/zh/whats-new-in-skywalking-metersystem-and-mesh-monitoring-in-8-0/","title":"SkyWalking 的最新动向？8.0 版本的 MeterSystem 和网格监控"},{"body":"作者：宋净超、张伟\n日前，云原生网络代理 MOSN v0.12.0 发布，观察性分析平台和应用性能管理系统 SkyWalking 完成了与 MOSN 的集成，作为 MOSN 中的支持的分布式追踪系统之一，旨在实现在微服务和 Service Mesh 中的更强大的可观察性。\n背景 相比传统的巨石（Monolith）应用，微服务的一个主要变化是将应用中的不同模块拆分为了独立的进程。在微服务架构下，原来进程内的方法调用成为了跨进程的远程方法调用。相对于单一进程内的方法调用而言，跨进程调用的调试和故障分析是非常困难的，难以使用传统的代码调试程序或者日志打印来对分布式的调用过程进行查看和分析。\n如上图右边所示，微服务架构中系统中各个微服务之间存在复杂的调用关系。\n一个来自客户端的请求在其业务处理过程中经过了多个微服务进程。我们如果想要对该请求的端到端调用过程进行完整的分析，则必须将该请求经过的所有进程的相关信息都收集起来并关联在一起，这就是“分布式追踪”。\n以上关于分布式追踪的介绍引用自 Istio Handbook。\nMOSN 中 tracing 的架构 MOSN 的 tracing 框架由 Driver、Tracer 和 Span 三个部分组成。\nDriver 是 Tracer 的容器，管理注册的 Tracer 实例，Tracer 是 tracing 的入口，根据请求信息创建一个 Span，Span 存储当前跨度的链路信息。\n目前 MOSN tracing 有 SOFATracer 和 SkyWalking 两种实现。SOFATracer 支持 http1 和 xprotocol 协议的链路追踪，将 trace 数据写入本地日志文件中。SkyWalking 支持 http1 协议的链路追踪，使用原生的 Go 语言探针 go2sky 将 trace 数据通过 gRPC 上报到 SkyWalking 后端服务。\n快速开始 下面将使用 Docker 和 docker-compose 来快速开始运行一个集成了 SkyWalking 的分布式追踪示例，该示例代码请见 MOSN GitHub。\n准备 安装 docker 和 docker-compose。\n  安装 docker\n  安装 docker-compose\n  需要一个编译好的 MOSN 程序，您可以下载 MOSN 源码自行编译，或者直接下载 MOSN v0.12.0 发行版以获取 MOSN 的运行时二进制文件。\n下面将以源码编译的方式演示 MOSN 如何与 SkyWalking 集成。\ncd ${projectpath}/cmd/mosn/main go build 获取示例代码目录。\n${targetpath} = ${projectpath}/examples/codes/trace/skywalking/http/ 将编译好的程序移动到示例代码目录。\nmv main ${targetpath}/ cd ${targetpath} 目录结构 下面是 SkyWalking 的目录结构。\n* skywalking └─── http │ main # 编译完成的 MOSN 程序 | server.go # 模拟的 Http Server | clint.go # 模拟的 Http Client | config.json # MOSN 配置 | skywalking-docker-compose.yaml # skywalking docker-compose 运行说明 启动 SkyWalking oap \u0026amp; ui。\ndocker-compose -f skywalking-docker-compose.yaml up -d 启动一个 HTTP Server。\ngo run server.go 启动 MOSN。\n./main start -c config.json 启动一个 HTTP Client。\ngo run client.go 打开 http://127.0.0.1:8080 查看 SkyWalking-UI，SkyWalking Dashboard 界面如下图所示。\n在打开 Dashboard 后请点击右上角的 Auto 按钮以使页面自动刷新。\nDemo 视频 下面来看一下该 Demo 的操作视频。\n\n清理 要想销毁 SkyWalking 后台运行的 docker 容器只需要下面的命令。\ncd ${projectpath}/examples/codes/trace/skywalking/http/ docker-compose -f skywalking-docker-compose.yaml down 未来计划 在今年五月份，SkyWalking 8.0 版本会进行一次全面升级，采用新的探针协议和分析逻辑，探针将更具互感知能力，更好的在 Service Mesh 下使用探针进行监控。同时，SkyWalking 将开放之前仅存在于内核中的 metrics 指标分析体系。Prmoetheus、Spring Cloud Sleuth、Zabbix 等常用的 metrics 监控方式，都会被统一的接入进来，进行分析。此外， SkyWalking 与 MOSN 社区将继续合作：支持追踪 Dubbo 和 SOFARPC，同时适配 sidecar 模式下的链路追踪。\n关于 MOSN MOSN 是一款使用 Go 语言开发的网络代理软件，由蚂蚁金服开源并经过几十万容器的生产级验证。 MOSN 作为云原生的网络数据平面，旨在为服务提供多协议、模块化、智能化、安全的代理能力。 MOSN 是 Modular Open Smart Network 的简称。 MOSN 可以与任何支持 xDS API 的 Service Mesh 集成，亦可以作为独立的四、七层负载均衡，API Gateway、云原生 Ingress 等使用。\n GitHub：https://github.com/mosn/mosn 官网：https://mosn.io  关于 Skywalking SkyWalking 是观察性分析平台和应用性能管理系统。提供分布式追踪、服务网格遥测分析、度量聚合和可视化一体化解决方案。支持 Java、.Net Core、PHP、NodeJS、Golang、LUA 语言探针，支持 Envoy/MOSN + Istio 构建的 Service Mesh。\n GitHub：https://github.com/apache/skywalking 官网：https://skywalking.apache.org  关于本文中的示例请参考 MOSN GitHub 和 MOSN 官方文档。\n","excerpt":"作者：宋净超、张伟\n日前，云原生网络代理 MOSN v0.12.0 发布，观察性分析平台和应用性能管理系统 SkyWalking 完成了与 MOSN 的集成，作为 MOSN 中的支持的分布式追踪系统之 …","ref":"/zh/2020-04-28-skywalking-and-mosn/","title":"SkyWalking 支持云原生网络代理 MOSN 做分布式追踪"},{"body":"Based on his continuous contributions, Wei Zhang (a.k.a arugal) has been invited to join the PMC. Welcome aboard.\n","excerpt":"Based on his continuous contributions, Wei Zhang (a.k.a arugal) has been invited to join the PMC. …","ref":"/events/welcome-wei-zhang-to-join-the-pmc/","title":"Welcome Wei Zhang to join the PMC"},{"body":"目录：\n 1. 概述 2. 搭建 SkyWalking 单机环境 3. 搭建 SkyWalking 集群环境 4. 告警 5. 注意事项 6. Spring Boot 使用示例 6. Spring Cloud 使用示例    作者：芋道源码 原文地址   1. 概述 1.1 概念 SkyWalking 是什么？\n FROM http://skywalking.apache.org/\n分布式系统的应用程序性能监视工具，专为微服务、云原生架构和基于容器（Docker、K8s、Mesos）架构而设计。\n提供分布式追踪、服务网格遥测分析、度量聚合和可视化一体化解决方案。\n 1.2 功能列表 SkyWalking 有哪些功能？\n FROM http://skywalking.apache.org/\n 多种监控手段。可以通过语言探针和 service mesh 获得监控是数据。 多个语言自动探针。包括 Java，.NET Core 和 Node.JS。 轻量高效。无需大数据平台，和大量的服务器资源。 模块化。UI、存储、集群管理都有多种机制可选。 支持告警。 优秀的可视化解决方案。   1.3 整体架构 SkyWalking 整体架构如何？\n FROM http://skywalking.apache.org/\n 整个架构，分成上、下、左、右四部分：\n 考虑到让描述更简单，我们舍弃掉 Metric 指标相关，而着重在 Tracing 链路相关功能。\n  上部分 Agent ：负责从应用中，收集链路信息，发送给 SkyWalking OAP 服务器。目前支持 SkyWalking、Zikpin、Jaeger 等提供的 Tracing 数据信息。而我们目前采用的是，SkyWalking Agent 收集 SkyWalking Tracing 数据，传递给服务器。 下部分 SkyWalking OAP ：负责接收 Agent 发送的 Tracing 数据信息，然后进行分析(Analysis Core) ，存储到外部存储器( Storage )，最终提供查询( Query )功能。 右部分 Storage ：Tracing 数据存储。目前支持 ES、MySQL、Sharding Sphere、TiDB、H2 多种存储器。而我们目前采用的是 ES ，主要考虑是 SkyWalking 开发团队自己的生产环境采用 ES 为主。 左部分 SkyWalking UI ：负责提供控台，查看链路等等。  1.4 官方文档 在 https://github.com/apache/skywalking/tree/master/docs 地址下，提供了 SkyWalking 的英文文档。\n考虑到大多数胖友的英语水平和艿艿不相伯仲，再加上胖友一开始对 SkyWalking 比较陌生，所以比较推荐先阅读 https://github.com/SkyAPM/document-cn-translation-of-skywalking 地址，提供了 SkyWalking 的中文文档。\n考虑到胖友使用 SkyWalking 的目的，是实现分布式链路追踪的功能，所以最好去了解下相关的知识。这里推荐阅读两篇文章：\n 《OpenTracing 官方标准 —— 中文版》 Google 论文 《Dapper，大规模分布式系统的跟踪系统》  2. 搭建 SkyWalking 单机环境 考虑到让胖友更快的入门，我们来搭建一个 SkyWalking 单机环境，步骤如下：\n 第一步，搭建一个 Elasticsearch 服务。 第二步，下载 SkyWalking 软件包。 第三步，搭建一个 SkyWalking OAP 服务。 第四步，启动一个 Spring Boot 应用，并配置 SkyWalking Agent。 第五步，搭建一个 SkyWalking UI 服务。  仅仅五步，按照艿艿标题党的性格，应该给本文取个《10 分钟快速搭建 SkyWalking 服务》标题才对，哈哈哈。\n2.1 Elasticsearch 搭建  FROM https://www.elastic.co/cn/products/elasticsearch\nElasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。 作为 Elastic Stack 的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。\n 参考《Elasticsearch 极简入门》的「1. 单机部署」小节，搭建一个 Elasticsearch 单机服务。\n不过要注意，本文使用的是 Elasticsearch 7.5.1 版本。因为 SkyWalking 6.6.0 版本，增加了对 Elasticsearch 7.X 版本的支持。当然，如果胖友使用 Elasticsearch 6.X 版本也是可以的。\n2.2 下载 SkyWalking 软件包 对于 SkyWalking 的软件包，有两种方式获取：\n 手动编译 官方包  一般情况下，我们建议使用官方包。手动编译，更多是尝鲜或者等着急修复的 BUG 的版本。\n2.2.1 官方包 在 http://skywalking.apache.org/downloads/ 下，我们下载操作系统对应的发布版。\n这里，我们选择 Binary Distribution for ElasticSearch 7 (Linux) 版本，因为艿艿是 Mac 环境，再加上想使用 Elasticsearch 7.X 版本作为存储。如果胖友想用 Elasticsearch 6.X 版本作为存储，记得下载 Binary Distribution (Linux) 版本。\n① 下载：\n# 创建目录 $ mkdir -p /Users/yunai/skywalking $ cd /Users/yunai/skywalking # 下载 $ wget http://mirror.bit.edu.cn/apache/skywalking/6.6.0/apache-skywalking-apm-es7-6.6.0.tar.gz ② 解压：\n# 解压 $ tar -zxvf apache-skywalking-apm-es7-6.6.0.tar.gz $ cd apache-skywalking-apm-bin-es7 $ ls -ls 4 drwxr-xr-x 8 root root 4096 Sep 9 15:09 agent # SkyWalking Agent 4 drwxr-xr-x 2 root root 4096 Sep 9 15:44 bin # 执行脚本 4 drwxr-xr-x 2 root root 4096 Sep 9 15:44 config # SkyWalking OAP Server 配置文件 32 -rwxr-xr-x 1 root root 28903 Sep 9 14:32 LICENSE 4 drwxr-xr-x 3 root root 4096 Sep 9 15:44 licenses 32 -rwxr-xr-x 1 root root 31850 Sep 9 14:32 NOTICE 16 drwxr-xr-x 2 root root 16384 Sep 9 15:22 oap-libs # SkyWalking OAP Server 4 -rw-r--r-- 1 root root 1978 Sep 9 14:32 README.txt 4 drwxr-xr-x 2 root root 4096 Sep 9 15:44 webapp # SkyWalking UI 2.2.2 手动编译  友情提示：如果胖友没有编译 SkyWalking 源码的诉求，可以跳过本小节。\n 参考 How to build project 文章。\n需要前置安装如下：\n GIT JDK 8+ Maven  ① 克隆代码：\n$ git clone https://github.com/apache/skywalking.git  因为网络问题，可能克隆会有点久。  ② 初始化子模块：\n$ cd skywalking $ git submodule init $ git submodule update ③ 编译\n$ ./mvnw clean package -DskipTests  编译过程，如果机子比较差，花费时间会比较久。  ④ 查看编译结果\n$ cd apm-dist # 编译结果目录 $ cd target $ tar -zxvf apache-skywalking-apm-bin.tar.gz # 解压 Linux 包 $ cd apache-skywalking-apm-bin $ ls -ls 4 drwxr-xr-x 8 root root 4096 Sep 9 15:09 agent # SkyWalking Agent 4 drwxr-xr-x 2 root root 4096 Sep 9 15:44 bin # 执行脚本 4 drwxr-xr-x 2 root root 4096 Sep 9 15:44 config # SkyWalking OAP Server 配置文件 32 -rwxr-xr-x 1 root root 28903 Sep 9 14:32 LICENSE 4 drwxr-xr-x 3 root root 4096 Sep 9 15:44 licenses 32 -rwxr-xr-x 1 root root 31850 Sep 9 14:32 NOTICE 16 drwxr-xr-x 2 root root 16384 Sep 9 15:22 oap-libs # SkyWalking OAP Server 4 -rw-r--r-- 1 root root 1978 Sep 9 14:32 README.txt 4 drwxr-xr-x 2 root root 4096 Sep 9 15:44 webapp # SkyWalking UI 2.3 SkyWalking OAP 搭建 ① 修改 OAP 配置文件\n 友情提示：如果配置文件，适合 SkyWalking 6.X 版本。\n $ vi config/application.yml storage: elasticsearch7: nameSpace: ${SW_NAMESPACE:\u0026#34;elasticsearch\u0026#34;} clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200} protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\u0026#34;http\u0026#34;} # trustStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\u0026#34;../es_keystore.jks\u0026#34;} # trustStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\u0026#34;\u0026#34;} user: ${SW_ES_USER:\u0026#34;\u0026#34;} password: ${SW_ES_PASSWORD:\u0026#34;\u0026#34;} indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2} indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0} # Those data TTL settings will override the same settings in core module. recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000} metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000} segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200} # h2: # driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource} # url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db} # user: ${SW_STORAGE_H2_USER:sa} # metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000}  storage.elasticsearch7 配置项，设置使用 Elasticsearch 7.X 版本作为存储器。  这里，我们打开注释，并记得通过 nameSpace 设置 Elasticsearch 集群名。   storage.elasticsearch 配置项，设置使用 Elasticsearch 6.X 版本作为存储器。  这里，我们无需做任何改动。 如果胖友使用 Elasticsearch 6.X 版本作为存储器，记得设置这个配置项，而不是 storage.elasticsearch7 配置项。   storage.h2 配置项，设置使用 H2 作为存储器。  这里，我们需要手动注释掉，因为 H2 是默认配置的存储器。     友情提示：如果配置文件，适合 SkyWalking 7.X 版本。\n  重点修改 storage 配置项，通过 storage.selector 配置项来设置具体使用的存储器。 storage.elasticsearch 配置项，设置使用 Elasticsearch 6.X 版本作为存储器。胖友可以主要修改 nameSpace、clusterNodes 两个配置项即可，设置使用的 Elasticsearch 的集群和命名空间。 storage.elasticsearch7 配置项，设置使用 Elasticsearch 7.X 版本作为存储器。 还有 MySQL、H2、InfluxDB 等等存储器的配置可以选择，胖友自己根据需要去选择哈~  ② 启动 SkyWalking OAP 服务\n$ bin/oapService.sh SkyWalking OAP started successfully! 是否真正启动成功，胖友打开 logs/skywalking-oap-server.log 日志文件，查看是否有错误日志。首次启动时，因为 SkyWalking OAP 会创建 Elasticsearch 的索引，所以会“疯狂”的打印日志。最终，我们看到如下日志，基本可以代表 SkyWalking OAP 服务启动成功：\n 友情提示：因为首次启动会创建 Elasticsearch 索引，所以可能会比较慢。\n 2020-01-02 18:22:53,635 - org.eclipse.jetty.server.Server - 444 [main] INFO [] - Started @35249ms 2.4 SkyWalking UI 搭建 ① 启动 SkyWalking UI 服务\nbin/webappService.sh SkyWalking Web Application started successfully! 是否真正启动成功，胖友打开 logs/logs/webapp.log 日志文件，查看是否有错误日志。最终，我们看到如下日志，基本可以代表 SkyWalking UI 服务启动成功：\n2020-01-02 18:27:02.824 INFO 48250 --- [main] o.a.s.apm.webapp.ApplicationStartUp : Started ApplicationStartUp in 7.774 seconds (JVM running for 8.316) 如果想要修改 SkyWalking UI 服务的参数，可以编辑 webapp/webapp.yml 配置文件。例如说：\n server.port ：SkyWalking UI 服务端口。 collector.ribbon.listOfServers ：SkyWalking OAP 服务地址数组。因为 SkyWalking UI 界面的数据，是通过请求 SkyWalking OAP 服务来获得的。  ② 访问 UI 界面：\n浏览器打开 http://127.0.0.1:8080 。界面如下图：2.5 SkyWalking Agent 大多数情况下，我们在启动项目的 Shell 脚本上，通过 -javaagent 参数进行配置 SkyWalking Agent 。我们在 「2.3.1 Shell」 小节来看。\n考虑到偶尔我们需要在 IDE 中，也希望使用 SkyWalking Agent ，所以我们在 「2.3.2 IDEA」 小节来看。\n2.3.1 Shell ① Agent 软件包\n我们需要将 apache-skywalking-apm-bin/agent 目录，拷贝到 Java 应用所在的服务器上。这样，Java 应用才可以配置使用该 SkyWalking Agent。我们来看看 Agent 目录下有哪些：\n$ ls -ls total 35176 0 drwxr-xr-x@ 7 yunai staff 224 Dec 24 14:20 activations 0 drwxr-xr-x@ 4 yunai staff 128 Dec 24 14:21 bootstrap-plugins 0 drwxr-xr-x@ 3 yunai staff 96 Dec 24 14:12 config # SkyWalking Agent 配置 0 drwxr-xr-x@ 3 yunai staff 96 Jan 2 19:29 logs # SkyWalking Agent 日志 0 drwxr-xr-x@ 13 yunai staff 416 Dec 24 14:22 optional-plugins # 可选插件 0 drwxr-xr-x@ 68 yunai staff 2176 Dec 24 14:20 plugins # 插件 35176 -rw-r--r--@ 1 yunai staff 18006420 Dec 24 14:12 skywalking-agent.jar # SkyWalking Agent  关于 SkyWalking Agent 提供的插件列表，可以看看《SkyWalking 文档 —— 插件支持列表》。  因为艿艿是在本机测试，所以无需拷贝，SkyWalking Agent 目录是 /Users/yunai/skywalking/apache-skywalking-apm-bin-es7/agent/。\n考虑到方便胖友，艿艿这里提供了一个最简的 Spring Boot 应用 lab-39-demo-2.2.2.RELEASE.jar。对应 Github 仓库是 lab-39-demo。\n② 配置 Java 启动脚本\n# SkyWalking Agent 配置 export SW_AGENT_NAME=demo-application # 配置 Agent 名字。一般来说，我们直接使用 Spring Boot 项目的 `spring.application.name` 。 export SW_AGENT_COLLECTOR_BACKEND_SERVICES=127.0.0.1:11800 # 配置 Collector 地址。 export SW_AGENT_SPAN_LIMIT=2000 # 配置链路的最大 Span 数量。一般情况下，不需要配置，默认为 300 。主要考虑，有些新上 SkyWalking Agent 的项目，代码可能比较糟糕。 export JAVA_AGENT=-javaagent:/Users/yunai/skywalking/apache-skywalking-apm-bin-es7/agent/skywalking-agent.jar # SkyWalking Agent jar 地址。 # Jar 启动 java -jar $JAVA_AGENT -jar lab-39-demo-2.2.2.RELEASE.jar  通过环境变量，进行配置。 更多的变量，可以在 /work/programs/skywalking/apache-skywalking-apm-bin/agent/config/agent.config 查看。要注意，可能有些变量是被注释掉的，例如说 SW_AGENT_SPAN_LIMIT 对应的 agent.span_limit_per_segment 。  ③ 执行脚本：\n直接执行上述的 Shell 脚本，启动 Java 项目。在启动日志中，我们可以看到 SkyWalking Agent 被加载的日志。日志示例如下：\nDEBUG 2020-01-02 19:29:29:400 main AgentPackagePath : The beacon class location is jar:file:/Users/yunai/skywalking/apache-skywalking-apm-bin-es7/agent/skywalking-agent.jar!/org/apache/skywalking/apm/agent/core/boot/AgentPackagePath.class. INFO 2020-01-02 19:29:29:402 main SnifferConfigInitializer : Config file found in /Users/yunai/skywalking/apache-skywalking-apm-bin-es7/agent/config/agent.config. 同时，也可以在 /Users/yunai/skywalking/apache-skywalking-apm-bin-es7/agent/agent/logs/skywalking-api.log 查看对应的 SkyWalking Agent 日志。日志示例如下：\nDEBUG 2020-01-02 19:37:22:539 SkywalkingAgent-5-ServiceAndEndpointRegisterClient-0 ServiceAndEndpointRegisterClient : ServiceAndEndpointRegisterClient running, status:CONNECTED.  这里，我们看到 status:CONNECTED ，表示 SkyWalking Agent 连接 SkyWalking OAP 服务成功。  ④ 简单测试\n完事，可以去 SkyWalking UI 查看是否链路收集成功。\n1、首先，使用浏览器，访问下 http://127.0.0.1:8079/demo/echo 地址，请求下 Spring Boot 应用提供的 API。因为，我们要追踪下该链路。\n2、然后，继续使用浏览器，打开 http://127.0.0.1:8080/ 地址，进入 SkyWalking UI 界面。如下图所示：这里，我们会看到 SkyWalking 中非常重要的三个概念：\n  服务(Service) ：表示对请求提供相同行为的一系列或一组工作负载。在使用 Agent 或 SDK 的时候，你可以定义服务的名字。如果不定义的话，SkyWalking 将会使用你在平台（例如说 Istio）上定义的名字。\n 这里，我们可以看到 Spring Boot 应用的服务为 \u0026quot;demo-application\u0026quot;，就是我们在环境变量 SW_AGENT_NAME 中所定义的。\n   服务实例(Service Instance) ：上述的一组工作负载中的每一个工作负载称为一个实例。就像 Kubernetes 中的 pods 一样, 服务实例未必就是操作系统上的一个进程。但当你在使用 Agent 的时候, 一个服务实例实际就是操作系统上的一个真实进程。\n 这里，我们可以看到 Spring Boot 应用的服务为 {agent_name}-pid:{pid}@{hostname}，由 Agent 自动生成。关于它，我们在「5.1 hostname」小节中，有进一步的讲解，胖友可以瞅瞅。\n   端点(Endpoint) ：对于特定服务所接收的请求路径, 如 HTTP 的 URI 路径和 gRPC 服务的类名 + 方法签名。\n 这里，我们可以看到 Spring Boot 应用的一个端点，为 API 接口 /demo/echo。\n   3、之后，点击「拓扑图」菜单，进入查看拓扑图的界面。如下图所示：4、再之后，点击「追踪」菜单，进入查看链路数据的界面。如下图所示：2.3.2 IDEA 我们统一使用 IDEA 作为开发 IDE ，所以忽略 Eclipse 的配置方式。\n具体参考下图，比较简单：3. 搭建 SkyWalking 集群环境 在生产环境下，我们一般推荐搭建 SkyWalking 集群环境。😈 当然，如果公司比较抠门，也可以在生产环境下使用 SkyWalking 单机环境，毕竟 SkyWalking 挂了之后，不影响业务的正常运行。\n搭建一个 SkyWalking 集群环境，步骤如下：\n 第一步，搭建一个 Elasticsearch 服务的集群。 第二步，搭建一个注册中心的集群。目前 SkyWalking 支持 Zookeeper、Kubernetes、Consul、Nacos 作为注册中心。 第三步，搭建一个 SkyWalking OAP 服务的集群，同时参考《SkyWalking 文档 —— 集群管理》，将 SkyWalking OAP 服务注册到注册中心上。 第四步，启动一个 Spring Boot 应用，并配置 SkyWalking Agent。另外，在设置 SkyWaling Agent 的 SW_AGENT_COLLECTOR_BACKEND_SERVICES 地址时，需要设置多个 SkyWalking OAP 服务的地址数组。 第五步，搭建一个 SkyWalking UI 服务的集群，同时使用 Nginx 进行负载均衡。另外，在设置 SkyWalking UI 的 collector.ribbon.listOfServers 地址时，也需要设置多个 SkyWalking OAP 服务的地址数组。  😈 具体的搭建过程，并不复杂，胖友自己去尝试下。\n4. 告警 在 SkyWaling 中，已经提供了告警功能，具体可见《SkyWalking 文档 —— 告警》。\n默认情况下，SkyWalking 已经内置告警规则。同时，我们可以参考告警规则，进行自定义。\n在满足 SkyWalking 告警规则的触发规则时，我们在 SkyWaling UI 的告警界面，可以看到告警内容。如下图所示：同时，我们自定义 Webhook ，对接 SkyWalking 的告警请求。而具体的邮箱、钉钉等告警方式，需要自己进行开发。至于自定义 WebHook 如何实现，可以参考：\n Java 语言：  《基于 SkyWalking 的分布式跟踪系统 - 异常告警》   Go 语言：  dingding-notify-for-skywalking infra-skywalking-webhook    5. 注意事项 5.1 hostname 配置 在 SkyWalking 中，每个被监控的实例的名字，会包含 hostname 。格式为：{agent_name}-pid:{pid}@{hostname} ，例如说：\u0026quot;scrm-scheduler-pid:27629@iZbp1e2xlyvr7fh67qi59oZ\u0026quot; 。\n因为有些服务器未正确设置 hostname ，所以我们一定要去修改，不然都不知道是哪个服务器上的实例（😈 鬼知道 \u0026quot;iZbp1e2xlyvr7fh67qi59oZ\u0026quot; 一串是哪个服务器啊）。\n修改方式如下：\n1、修改 /etc/hosts 的 hostname ：\n127.0.0.1 localhost ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 10.80.62.151 pre-app-01 # 就是这个，其中 10.80.62.151 是本机内网 IP ，pre-app-01 是 hostname 。 2、修改本机 hostname ：\n参考 《CentOS7 修改主机名（hostname）》\n$ hostname pre-app-01 # 其中 pre-app-01 就是你希望的 hostname 。 $ hostnamectl set-hostname pre-app-01 # 其中 pre-app-01 就是你希望的 hostname 。 6. Spring Boot 使用示例 在 《芋道 Spring Boot 链路追踪 SkyWalking 入门》 中，我们来详细学习如何在 Spring Boot 中，整合并使用 SkyWalking 收集链路数据。😈 相比「2.5 SkyWaling Agent」来说，我们会提供更加丰富的示例哟。\n7. Spring Cloud 使用示例 在 《芋道 Spring Cloud 链路追踪 SkyWalking 入门》 中，我们来详细学习如何在 Spring Cloud 中，整合并使用 SkyWalking 收集链路数据。😈 相比「2.5 SkyWaling Agent」来说，我们会提供更加丰富的示例哟。\n666. 彩蛋 本文仅仅是简单的 SkyWalking 入门文章，如果胖友想要更好的使用 SkyWalking，推荐通读下《SkyWalking 文档》。\n想要进一步深入的胖友，也可以阅读如下资料：\n 《SkyWalking 源码解析》 《APM 巅峰对决：Apache Skywalking P.K. Pinpoint》 《SkyWalking 官方 —— 博客合集》  😈 最后弱弱的问一句，上完 SkyWaling 之后，有没发现自己系统各种地方慢慢慢！嘻嘻。\n","excerpt":"目录：\n 1. 概述 2. 搭建 SkyWalking 单机环境 3. 搭建 SkyWalking 集群环境 4. 告警 5. 注意事项 6. Spring Boot 使用示例 6. Spring …","ref":"/zh/2020-04-19-skywalking-quick-start/","title":"SkyWalking 极简入门"},{"body":"","excerpt":"","ref":"/tags/agent/","title":"Agent"},{"body":"This post originally appears on The New Stack\nThis post introduces a way to automatically profile code in production with Apache SkyWalking. We believe the profile method helps reduce maintenance and overhead while increasing the precision in root cause analysis.\nLimitations of the Distributed Tracing In the early days, metrics and logging systems were the key solutions in monitoring platforms. With the adoption of microservice and distributed system-based architecture, distributed tracing has become more important. Distributed tracing provides relevant service context, such as system topology map and RPC parent-child relationships.\nSome claim that distributed tracing is the best way to discover the cause of performance issues in a distributed system. It’s good at finding issues at the RPC abstraction, or in the scope of components instrumented with spans. However, it isn’t that perfect.\nHave you been surprised to find a span duration longer than expected, but no insight into why? What should you do next? Some may think that the next step is to add more instrumentation, more spans into the trace, thinking that you would eventually find the root cause, with more data points. We’ll argue this is not a good option within a production environment. Here’s why:\n There is a risk of application overhead and system overload. Ad-hoc spans measure the performance of specific scopes or methods, but picking the right place can be difficult. To identify the precise cause, you can “instrument” (add spans to) many suspicious places. The additional instrumentation costs more CPU and memory in the production environment. Next, ad-hoc instrumentation that didn’t help is often forgotten, not deleted. This creates a valueless overhead load. In the worst case, excess instrumentation can cause performance problems in the production app or overload the tracing system. The process of ad-hoc (manual) instrumentation usually implies at least a restart. Trace instrumentation libraries, like Zipkin Brave, are integrated into many framework libraries. To instrument a method’s performance typically implies changing code, even if only an annotation. This implies a re-deploy. Even if you have the way to do auto instrumentation, like Apache SkyWalking, you still need to change the configuration and reboot the app. Otherwise, you take the risk of GC caused by hot dynamic instrumentation. Injecting instrumentation into an uninstrumented third party library is hard and complex. It takes more time and many won’t know how to do this. Usually, we don’t have code line numbers in the distributed tracing. Particularly when lambdas are in use, it can be difficult to identify the line of code associated with a span. Regardless of the above choices, to dive deeper requires collaboration with your Ops or SRE team, and a shared deep level of knowledge in distributed tracing.  Regardless of the above choices, to dive deeper requires collaboration with your Ops or SRE team, and a shared deep level of knowledge in distributed tracing.\nProfiling in Production Introduction To reuse distributed tracing to achieve method scope precision requires an understanding of the above limitations and a different approach. We called it PROFILE.\nMost high-level languages build and run on a thread concept. The profile approach takes continuous thread dumps. We merge the thread dumps to estimate the execution time of every method shown in the thread dumps. The key for distributed tracing is the tracing context, identifiers active (or current) for the profiled method. Using this trace context, we can weave data harvested from profiling into existing traces. This allows the system to automate otherwise ad-hoc instrumentation. Let’s dig deeper into how profiling works:\nWe consider a method invocation with the same stack depth and signature (method, line number etc), the same operation. We derive span timestamps from the thread dumps the same operation is in. Let’s put this visually:\nAbove, represents 10 successive thread dumps. If this method is in dumps 4-8, we assume it started before dump 4 and finished after dump 8. We can’t tell exactly when the method started and stopped. but the timestamps of thread dumps are close enough.\nTo reduce overhead caused by thread dumps, we only profile methods enclosed by a specific entry point, such as a URI or MVC Controller method. We identify these entry points through the trace context and the APM system.\nThe profile does thread dump analysis and gives us:\n The root cause, precise to the line number in the code. Reduced maintenance as ad-hoc instrumentation is obviated. Reduced overload risk caused by ad-hoc instrumentation. Dynamic activation: only when necessary and with a very clear profile target.  Implementing Precise Profiling with Apache SkyWalking 7 Distributed profiling is built-into Apache SkyWalking application performance monitoring (APM). Let’s demonstrate how the profiling approach locates the root cause of the performance issue.\nfinal CountDownLatchcountDownLatch= new CountDownLatch(2); threadPool.submit(new Task1(countDownLatch)); threadPool.submit(new Task2(countDownLatch)); try { countDownLatch.await(500, TimeUnit.MILLISECONDS); } catch (InterruptedExceptione) { } Task1 and Task2 have a race condition and unstable execution time: they will impact the performance of each other and anything calling them. While this code looks suspicious, it is representative of real life. People in the OPS/SRE team are not usually aware of all code changes and who did them. They only know something in the new code is causing a problem.\nTo make matters interesting, the above code is not always slow: it only happens when the condition is locked. In SkyWalking APM, we have metrics of endpoint p99/p95 latency, so, we are easy to find out the p99 of this endpoint is far from the avg response time. However, this is not the same as understanding the cause of the latency. To locate the root cause, add a profile condition to this endpoint: duration greater than 500ms. This means faster executions will not add profiling load.\nThis is a typical profiled trace segment (part of the whole distributed trace) shown on the SkyWalking UI. We now notice the “service/processWithThreadPool” span is slow as we expected, but why? This method is the one we added the faulty code to. As the UI shows that method, we know the profiler is working. Now, let’s see what the profile analysis result say.\nThis is the profile analysis stack view. We see the stack element names, duration (include/exclude the children) and slowest methods have been highlighted. It shows clearly, “sun.misc.Unsafe.park” costs the most time. If we look for the caller, it is the code we added: CountDownLatch.await.\nThe Limitations of the Profile Method No diagnostic tool can fit all cases, not even the profile method.\nThe first consideration is mistaking a repeatedly called method for a slow method. Thread dumps are periodic. If there is a loop of calling one method, the profile analysis result would say the target method is slow because it is captured every time in the dump process. There could be another reason. A method called many times can also end up captured in each thread dump. Even so, the profile did what it is designed for. It still helps the OPS/SRE team to locate the code having the issue.\nThe second consideration is overhead, the impact of repeated thread dumps is real and can’t be ignored. In SkyWalking, we set the profile dump period to at least 10ms. This means we can’t locate method performance issues if they complete in less than 10ms. SkyWalking has a threshold to control the maximum parallel degree as well.\nUnderstanding the above keeps distributed tracing and APM systems useful for your OPS/SRE team.\nHow to Try This Everything we discussed, including the Apache SkyWalking Java Agent, profile analysis code, and UI, could be found in our GitHub repository. We hope you enjoyed this new profile method, and love Apache SkyWalking. If so, give us a star on GitHub to encourage us.\nSkyWalking 7 has just been released. You can contact the project team through the following channels:\n Follow SkyWalking twitter. Subscribe mailing list: dev@skywalking.apache.org. Send to dev-subscribe@kywalking.apache.org to subscribe to the mail list.  Co-author Sheng Wu is a Tetrate founding engineer and the founder and VP of Apache SkyWalking. He is solving the problem of observability for large-scale service meshes in hybrid and multi-cloud environments.\nAdrian Cole works in the Spring Cloud team at VMware, mostly on Zipkin\nHan Liu is a tech expert at Lagou. He is an Apache SkyWalking committer\n","excerpt":"This post originally appears on The New Stack\nThis post introduces a way to automatically profile …","ref":"/blog/2020-04-13-apache-skywalking-profiling/","title":"Apache SkyWalking: Use Profiling to Fix the Blind Spot of Distributed Tracing"},{"body":"","excerpt":"","ref":"/tags/java/","title":"Java"},{"body":"","excerpt":"","ref":"/tags/profiling/","title":"Profiling"},{"body":"","excerpt":"","ref":"/tags/tracing/","title":"Tracing"},{"body":"SkyWalking Chart 2.0.0 is released. Go to downloads page to find release tars.\n Support SkyWalking 7.0.0 Support set ES user/password Add CI for release  ","excerpt":"SkyWalking Chart 2.0.0 is released. Go to downloads page to find release tars.\n Support SkyWalking …","ref":"/events/release-apache-skywalking-chart-2-0-0-for-skywalking-7-0-0/","title":"Release Apache SkyWalking Chart 2.0.0 for SkyWalking 7.0.0"},{"body":"SkyWalking APM 7.0.0 is release. Go to downloads page to find release tars.\n Upgrade JDK minimal JDK requirement to JDK8 Support profiling code level performance Don\u0026rsquo;t support SkyWalking v5 agent in-wire and out-wire protocol. V6 is required.  ","excerpt":"SkyWalking APM 7.0.0 is release. Go to downloads page to find release tars.\n Upgrade JDK minimal JDK …","ref":"/events/release-apache-skywalking-apm-7-0-0/","title":"Release Apache SkyWalking APM 7.0.0"},{"body":"","excerpt":"","ref":"/zh_tags/agent/","title":"Agent"},{"body":"","excerpt":"","ref":"/zh_tags/java/","title":"Java"},{"body":"","excerpt":"","ref":"/zh_tags/profiling/","title":"Profiling"},{"body":"","excerpt":"","ref":"/zh_tags/tracing/","title":"Tracing"},{"body":" 作者：吴晟，刘晗 原文地址  在本文中，我们详细介绍了代码级的性能剖析方法，以及我们在 Apache SkyWalking 中的实践。希望能够帮助大家在线定位系统性能短板，缓解系统压力。\n分布式链路追踪的局限性 在传统的监控系统中，我们如果想要得知系统中的业务是否正常，会采用进程监控、日志收集分析等方式来对系统进行监控。当机器或者服务出现问题时，则会触发告警及时通知负责人。通过这种方式，我们可以得知具体哪些服务出现了问题。但是这时我们并不能得知具体的错误原因出在了哪里，开发人员或者运维人员需要到日志系统里面查看错误日志，甚至需要到真实的业务服务器上查看执行情况来解决问题。\n如此一来，仅仅是发现问题的阶段，可能就会耗费相当长的时间；另外，发现问题但是并不能追溯到问题产生具体原因的情况，也常有发生。这样反反复复极其耗费时间和精力，为此我们便有了基于分布式追踪的 APM 系统。\n通过将业务系统接入分布式追踪中，我们就像是给程序增加了一个放大镜功能，可以清晰看到真实业务请求的整体链路，包括请求时间、请求路径，甚至是操作数据库的语句都可以看得一清二楚。通过这种方式，我们结合告警便可以快速追踪到真实用户请求的完整链路信息，并且这些数据信息完全是持久化的，可以随时进行查询，复盘错误的原因。\n然而随着我们对服务监控理解的加深，我们发现事情并没有那么简单。在分布式链路追踪中我们有这样的两个流派：代码埋点和字节码增强。无论使用哪种方式，底层逻辑一定都逃不过面向切面这个基础逻辑。因为只有这样才可以做到大面积的使用。这也就决定了它只能做到框架级别和 RPC 粒度的监控。这时我们可能依旧会遇到程序执行缓慢或者响应时间不稳定等情况，但无法具体查询到原因。这时候，大家很自然的会考虑到增加埋点粒度，比如对所有的 Spring Bean 方法、甚至主要的业务层方法都加上埋点。但是这种思路会遇到不小的挑战：\n第一，增加埋点时系统开销大，埋点覆盖不够全面。通过这种方式我们确实可以做到具体业务场景具体分析。但随着业务不断迭代上线，弊端也很明显：大量的埋点无疑会加大系统资源的开销，造成 CPU、内存使用率增加，更有可能拖慢整个链路的执行效率。虽然每个埋点消耗的性能很小，在微秒级别，但是因为数量的增加，甚至因为业务代码重用造成重复埋点或者循环使用，此时的性能开销已经无法忽略。\n第二，动态埋点作为一项埋点技术，和手动埋点的性能消耗上十分类似，只是减少的代码修改量，但是因为通用技术的特别，上一个挑战中提到的循环埋点和重复使用的场景甚至更为严重。比如选择所有方法或者特定包下的所有方法埋点，很可能造成系统性能彻底崩溃。\n第三，即使我们通过合理设计和埋点，解决了上述问题，但是 JDK 函数是广泛使用的，我们很难限制对 JDK API 的使用场景。对 JDK 过多方法、特别是非 RPC 方法的监控会造成系统的巨大延迟风险。而且有一些基础类型和底层工具类，是很难通过字节码进行增强的。当我们的 SDK 使用不当或者出现 bug 时，我们无法具体得知真实的错误原因。\n代码级性能剖析方法 方法介绍 基于以上问题，在系统性能监控方法上，我们提出了代码级性能剖析这种在线诊断方法。这种方法基于一个高级语言编程模型共性，即使再复杂的系统，再复杂的业务逻辑，都是基于线程去进行执行的，而且多数逻辑是在单个线程状态下执行的。\n代码级性能剖析就是利用方法栈快照，并对方法执行情况进行分析和汇总。并结合有限的分布式追踪 span 上下文，对代码执行速度进行估算。\n性能剖析激活时，会对指定线程周期性的进行线程栈快照，并将所有的快照进行汇总分析，如果两个连续的快照含有同样的方法栈，则说明此栈中的方法大概率在这个时间间隔内都处于执行状态。从而，通过这种连续快照的时间间隔累加成为估算的方法执行时间。时间估算方法如下图所示：\n在上图中，d0-d10 代表 10 次连续的内存栈快照，实际方法执行时间在 d3-d4 区间，结束时间在 d8-d9 之间。性能剖析无法告诉你方法的准确执行时间，但是他会估算出方法执行时间为 d4-d8 的 4 个快照采集间隔时间之和，这已经是非常的精确的时间估算了。\n而这个过程因为不涉及代码埋点，所以自然性能消耗是稳定和可控的，也无需担心是否被埋点，是否是 JDK 方法等问题。同时，由于上层已经在分布式追踪之下，性能剖析方法可以明确地确定分析开始和结束时间，减少不必要的性能开销。\n性能剖析可以很好的对线程的堆栈信息进行监控，主要有以下几点优势：\n 精确的问题定位，直接到代码方法和代码行； 无需反复的增删埋点，大大减少了人力开发成本； 不用承担过多埋点对目标系统和监控系统的压力和性能风险； 按需使用，平时对系统无消耗，使用时的消耗稳定可能。  SkyWalking 实践实例 我们首先在 Apache SkyWalking APM 中实现此技术方法，下面我们就以一个真实的例子来说明此方法的执行效果。\nfinal CountDownLatchcountDownLatch= new CountDownLatch(2); threadPool.submit(new Task1(countDownLatch)); threadPool.submit(new Task2(countDownLatch)); try { countDownLatch.await(500, TimeUnit.MILLISECONDS); } catch (InterruptedExceptione) { } 这是我们故意加入的问题代码，我们使用 CountDownLanth 设置了两个任务完成后方法执行结束，Task1 和 Task2 是两个执行时间不稳定的任务，所以主任务也会执行速度不稳定。但对于运维和监控团队来说，很难定位到这个方法片段。\n针对于这种情况，我们看看性能剖析会怎样直接定位此问题。\n上图所示的就是我们在进行链路追踪时所看到的真实执行情况，其中我们可以看到在 service/processWithThreadPool 执行速度缓慢，这正是我们植入问题代码的方法。此时在这个调用中没有后续链路了，所以并没有更细致的原因，我们也不打算去 review 代码，从而增加新埋点。这时，我们可以对 HelloService 进行性能剖析，并执行只剖析响应速度大于 500 毫秒的请求。\n注意，指定特定响应时间的剖析是保证剖析有效性的重要特性，如果方法在平均响应时间上已经出现问题，往往通过分布式链路可以快速定位，因为此时链路总时间长，新埋点带来的性能影响相对可控。但是方法性能抖动是不容易用新增埋点来解决的，而且往往只发生在生产环境。\n上图就是我们进行性能剖析后的真实结果图。从左到右分别表示：栈帧名称、该栈帧总计耗时（包含其下面所有自栈帧）、当前栈帧自身耗时和监控次数。我们可以在最后一行看到，线程卡在了 sun.misc.Unsafe.park 中了。如果你熟悉 Java 就可以知道此时进行了锁等待，我们继续按照树的结构向上推，便可以看到线程真正是卡在了 CountDownLatch.await 方法中。\n方法局限性 当然任何的方法都不是万能的，性能剖析也有一些局限性。\n第一， 对于高频反复执行的方法，如循环调用，可能会误报为缓慢方法。但这并不是大问题，因为如果反复执行的耗时较长，必然是系统需要关注的性能瓶颈。\n第二， 由于性能栈快照有一定的性能消耗，所以采集周期不宜过密，如 SkyWalking 实践中，不支持小于 10ms 的采集间隔。所以如果问题方法执行时间过小（比如在 10 毫秒内波动），此方法并不适用。我们也再此强调，方法论和工具的强大，始终不能代替程序员。\n","excerpt":"作者：吴晟，刘晗 原文地址  在本文中，我们详细介绍了代码级的性能剖析方法，以及我们在 Apache SkyWalking 中的实践。希望能够帮助大家在线定位系统性能短板，缓解系统压力。\n分布式链路追 …","ref":"/zh/2020-03-23-using-profiling-to-fix-the-blind-spot-of-distributed-tracing/","title":"在线代码级性能剖析，补全分布式追踪的最后一块“短板”"},{"body":"SkyWalking CLI 0.2.0 is released. Go to downloads page to find release tars.\n Support visualization of heat map Support top N entities, swctl metrics top 5 --name service_sla Support thermodynamic metrics, swctl metrics thermodynamic --name all_heatmap Support multiple linear metrics, swctl --display=graph --debug metrics multiple-linear --name all_percentile  ","excerpt":"SkyWalking CLI 0.2.0 is released. Go to downloads page to find release tars.\n Support visualization …","ref":"/events/release-apache-skywalking-cli-0-2-0/","title":"Release Apache SkyWalking CLI 0.2.0"},{"body":"SkyWalking Chart 1.1.0 is released. Go to downloads page to find release tars.\n Support SkyWalking 6.6.0 Support deploy Elasticsearch 7 The official helm repo was changed to the official Elasticsearch repo (https://helm.elastic.co/)  ","excerpt":"SkyWalking Chart 1.1.0 is released. Go to downloads page to find release tars.\n Support SkyWalking …","ref":"/events/release-apache-skywalking-chart-1-1-0-for-skywalking-6-6-0/","title":"Release Apache SkyWalking Chart 1.1.0 for SkyWalking 6.6.0"},{"body":"Support tracing and collect metrics from Nginx server. Require SkyWalking APM 7.0+.\n","excerpt":"Support tracing and collect metrics from Nginx server. Require SkyWalking APM 7.0+.","ref":"/events/skywalking-nginx-lua-0-1-0-release/","title":"SkyWalking Nginx LUA 0.1.0 release"},{"body":"Based on his continuous contributions, Ming Wen (a.k.a moonming) has been voted as a new committer.\n","excerpt":"Based on his continuous contributions, Ming Wen (a.k.a moonming) has been voted as a new committer.","ref":"/events/welcome-ming-wen-as-new-committer/","title":"Welcome Ming Wen as new committer"},{"body":"Based on his continuous contributions, Haochao Zhuang (a.k.a dmsolr) has been invited to join the PMC. Welcome aboard.\n","excerpt":"Based on his continuous contributions, Haochao Zhuang (a.k.a dmsolr) has been invited to join the …","ref":"/events/welcome-haochao-zhuang-to-join-the-pmc/","title":"Welcome Haochao Zhuang to join the PMC"},{"body":"Based on his continuous contributions, Zhusheng Xu (a.k.a aderm) has been voted as a new committer.\n","excerpt":"Based on his continuous contributions, Zhusheng Xu (a.k.a aderm) has been voted as a new committer.","ref":"/events/welcome-zhusheng-xu-as-new-committer/","title":"Welcome Zhusheng Xu as new committer"},{"body":"Based on his continuous contributions, Han Liu (a.k.a mrproliu) has been voted as a new committer.\n","excerpt":"Based on his continuous contributions, Han Liu (a.k.a mrproliu) has been voted as a new committer.","ref":"/events/welcome-han-liu-as-new-committer/","title":"Welcome Han Liu as new committer"},{"body":" Author: Wu Sheng, tetrate.io, SkyWalking original creator, SkyWalking V.P. GitHub, Twitter, Linkedin  The SkyWalking project provides distributed tracing, topology map analysis, service mesh telemetry analysis, metrics analysis and a super cool visualization targeting distributed systems in k8s or traditional VM deployments.\nThe project is widely used in Alibaba, Huawei, Tencent, DiDi, xiaomi, Pingan, China’s top 3 telecom companies (China Mobile, China telecom, China Unicom), airlines, banks and more. It has over 140 company users listed on our powered by page.\nToday, we welcome and celebrate reaching 200 code contributors on our main repo. We hereby mark this milestone as official today, : Jan. 20th 2020.\nAt this great moment, I would like to share SkyWalking’s 4-year open source journey.\nI wrote the first line on Nov. 1st, 2015, guiding people to understand a distributed system just as micro-services and distributed architecture were becoming popular. In the first 2 years, I never thought it would become such a big and active community. I didn’t even expect it would be an open source project. Initially, the goal was primarily to teach others about distributed tracing and analysis.\nIt was a typical open source project in obscurity in its first two years. But people still showed up, asked questions, and tried to improve the project. I got several invitations to share the project at local meetups.All these made me realize people really needed a good open source APM project.\nIn 2017, I decided to dedicate myself as much as possible to make the project successful, and it became my day job. To be honest, I had no clue about how to do that; at that time in China, it was rare to have this kind of job. So, I began to ask friends around me, “Do you want to collaborate on the open source APM with me?” Most people were busy and gave a clear NO, but two of them agreed to help: Xin Zhang and Yongsheng Peng. We built SkyWalking 3.x and shared the 3.2 release at GOPS Shanghai, China.\nIt became the first adoption version used in production\nCompared to today\u0026rsquo;s SkyWalking, it was a toy prototype, but it had the same tracing design, protocol and analysis method.\nThat year the contributor team was 15-20, and the project had obvious potential to expand. I began to consider bringing the project into a worldwide, top-level open source foundation. Thanks to our initial incubator mentors, Michael Semb Wever, William Jiang, and Luke Han, this really worked. At the end of 2017, SkyWalking joined the Apache Incubator, and kept following the Apache Way to build community. More contributors joined the community.\nWith more people spending time on the project collaborations, including codes, tests, blogs, conference talks, books and uses of the project, a chemical reaction happens. New developers begin to provide bug fixes, new feature requirements and new proposals. At the moment of graduation in spring 2019, the project had 100 contributors. Now, only 9 months later, it’s surged to 200 super quickly. They enhance the project and extend it to frontiers we never imaged: 5 popular language agents, service mesh adoption, CLI tool, super cool visualization. We are even moving on thread profiling, browser performance and Nginx tracing NOW.\nOver the whole 4+ years open source journey, we have had supports from leaders in the tracing open source community around the world, including Adrian Cole, William Jiang, Luke Han, Michael Semb Wever, Ben Sigelman, and Jonah Kowall. And we’ve had critical foundations\u0026rsquo; help, especially Apache Software Foundation and the Cloud Native Computing Foundation.\nOur contributors also have their support from their employers, including, to the best of my knowledge, Alibaba, Huawei, China Mobile, ke.com, DaoCloud, Lizhi.fm, Yonghui Supermarket, and dangdang.com. I also have support from my employers, tetrate.io, Huawei, and OneAPM.\nThanks to our 200+ contributors and the companies behind them. You make this magic happen.\n","excerpt":"Author: Wu Sheng, tetrate.io, SkyWalking original creator, SkyWalking V.P. GitHub, Twitter, Linkedin …","ref":"/blog/2020-01-20-celebrate-200th-contributor/","title":"SkyWalking hits 200 contributors mark"},{"body":"Based on his continuous contributions, Hongwei Zhai (a.k.a innerpeacez) has been invited to join the PMC. Welcome aboard.\n","excerpt":"Based on his continuous contributions, Hongwei Zhai (a.k.a innerpeacez) has been invited to join the …","ref":"/events/welcome-hongwei-zhai-to-join-the-pmc/","title":"Welcome Hongwei Zhai to join the PMC"},{"body":"Apache APM 6.6.0 release. Go to downloads page to find release tars.\n Service Instance dependency detection are available. Support ElasticSearch 7 as a storage option. Reduce the register load.  ","excerpt":"Apache APM 6.6.0 release. Go to downloads page to find release tars.\n Service Instance dependency …","ref":"/events/release-apache-skywalking-apm-6-6-0/","title":"Release Apache SkyWalking APM 6.6.0"},{"body":"SkyWalking Chart 1.0.0 is released. Go to downloads page to find release tars.\n Deploy SkyWalking 6.5.0 by Chart. Elasticsearch deploy optional.  ","excerpt":"SkyWalking Chart 1.0.0 is released. Go to downloads page to find release tars.\n Deploy SkyWalking …","ref":"/events/release-apache-skywalking-chart-1-0-0-for-skywalking-6-5-0/","title":"Release Apache SkyWalking Chart 1.0.0 for SkyWalking 6.5.0"},{"body":"SkyWalking CLI 0.1.0 is released. Go to downloads page to find release tars.\n Add command swctl service to list services Add command swctl instance and swctl search to list and search instances of service. Add command swctl endpoint to list endpoints of service. Add command swctl linear-metrics to query linear metrics and plot the metrics in Ascii Graph mode. Add command swctl single-metrics to query single-value metrics.  ","excerpt":"SkyWalking CLI 0.1.0 is released. Go to downloads page to find release tars.\n Add command swctl …","ref":"/events/release-apache-skywalking-cli-0-1-0/","title":"Release Apache SkyWalking CLI 0.1.0"},{"body":"Based on his continuous contributions, Weiyi Liu (a.k.a wayilau) has been voted as a new committer.\n","excerpt":"Based on his continuous contributions, Weiyi Liu (a.k.a wayilau) has been voted as a new committer.","ref":"/events/welcome-weiyi-liu-as-new-committer/","title":"Welcome Weiyi Liu as new committer"},{"body":"Based on his contributions to the project, he has been accepted as SkyWalking committer. Welcome aboard.\n","excerpt":"Based on his contributions to the project, he has been accepted as SkyWalking committer. Welcome …","ref":"/events/welcome-lang-li-as-a-new-committer/","title":"Welcome Lang Li as a new committer"},{"body":"Based on her continuous contributions, Qiuxia Fan (a.k.a Fine0830) has been voted as a new committer.\n","excerpt":"Based on her continuous contributions, Qiuxia Fan (a.k.a Fine0830) has been voted as a new …","ref":"/events/welcome-qiuxia-fan-as-new-committer/","title":"Welcome Qiuxia Fan as new committer"},{"body":"6.5.0 release. Go to downloads page to find release tars.\n New metrics comparison view in UI. Dynamic Alert setting supported. JDK9-12 supported in backend.  ","excerpt":"6.5.0 release. Go to downloads page to find release tars.\n New metrics comparison view in UI. …","ref":"/events/release-apache-skywalking-apm-6-5-0/","title":"Release Apache SkyWalking APM 6.5.0"},{"body":"Based on his continuous contributions, Wei Zhang (a.k.a arugal) has been voted as a new committer.\n","excerpt":"Based on his continuous contributions, Wei Zhang (a.k.a arugal) has been voted as a new committer.","ref":"/events/welcome-wei-zhang-as-new-committer/","title":"Welcome Wei Zhang as new committer"},{"body":"PS：本文仅仅是在我的测试环境实验过，如果有问题，请自行优化调整\n前记：记得skywlking还是6.0版本的时候我就在试用，当时是skywalking基本在两三天左右就会监控数据完全查不出来，elasticsearch日志报错，由于当时也算是初用es，主要用来日志收集，并且时间有限，没有继续深入研究，最近空闲，更新到最新的6.5.0(开发版本)还是会出现同样的问题，下定决心解决下，于是有了本文的浅知拙见\n本次调优环境 skywalking: 6.5.0 elasticsearch:6.3.2(下文用es代替)\n调优过程   当然是百度了，百度后其实翻来翻去就找到一个相关的文章https://my.oschina.net/keking/blog/3025303 ，参考之。\n  调整skywalking的这两个参数试试 bulkActions: 4000 # Execute the bulk every 2000 requests  bulkSize: 60 # flush the bulk every 20mb 然后es还是继续挂，继续频繁的重启\n  继续看这个文章，发现了另外一篇https://www.easyice.cn/archives/207 ，继续参考之\n  这篇文章发现每一个字我都认识，看起来也能懂，但是对于es小白的我来说，着实不知道怎么调整这些参数，姑且先加到es的配置文件里边试试看吧，于是就加了，然后重启es的时候说发现index参数配置，自从5.0之后就不支持这样配置了，还给调了个es的接口去设置，但是设置失败（真够不错的），朝着这个思路去百度，百度到快放弃，后来就寻思，再试试看吧，（百度的结果是知道了index有静态参数和动态参数，动态的参数是可以随时设置，静态的只能创建或者关闭状态的索引才可以设置） 然鹅并不知道怎么关闭索引，继续百度，（怎么全特么百度，好吧不百度了，直接来干货）\n 关闭索引（我的skywalking索引命名空间是dry_trace） curl -XPOST \u0026quot;http://localhost:9200/dry_trace*/_close\u0026quot; 设置参数 curl -XPUT 'http://localhost:9200/dry_trace*/_settings?preserve_existing=true' -H 'Content-type:application/json' -d '{ \u0026quot;index.refresh_interval\u0026quot; : \u0026quot;10s\u0026quot;, \u0026quot;index.translog.durability\u0026quot; : \u0026quot;async\u0026quot;, \u0026quot;index.translog.flush_threshold_size\u0026quot; : \u0026quot;1024mb\u0026quot;, \u0026quot;index.translog.sync_interval\u0026quot; : \u0026quot;120s\u0026quot; }'  打开索引 curl -XPOST \u0026quot;http://localhost:9200/dry_trace*/_open\u0026quot;    还有一点，第四步的方式只适用于现有的索引设置，那么新的索引设置呢，总不能每天重复下第四步吧。当然不需要，来干货 首先登陆kinaba控制台找到开发工具 贴入以下代码\nPUT /_template/dry_trace_tmp { \u0026quot;index_patterns\u0026quot;: \u0026quot;dry_trace*\u0026quot;, \u0026quot;order\u0026quot;: 1, \u0026quot;settings\u0026quot;: { \u0026quot;index\u0026quot;: { \u0026quot;refresh_interval\u0026quot;: \u0026quot;30s\u0026quot;, \u0026quot;translog\u0026quot;: { \u0026quot;flush_threshold_size\u0026quot;: \u0026quot;1GB\u0026quot;, \u0026quot;sync_interval\u0026quot;: \u0026quot;60s\u0026quot;, \u0026quot;durability\u0026quot;: \u0026quot;async\u0026quot; } } } }   截止目前为止运行一周，还未发现挂掉，一切看起来正常\n   完结\u0026mdash; 于 2019年11月\n","excerpt":"PS：本文仅仅是在我的测试环境实验过，如果有问题，请自行优化调整\n前记：记得skywlking还是6.0版本的时候我就在试用，当时是skywalking基本在两三天左右就会监控数据完全查不出 …","ref":"/zh/2019-11-07-skywalking-elasticsearch-storage-optimization/","title":"SkyWalking 使用 ElasticSearch 存储的优化"},{"body":"Based on his continuous contributions, Haochao Zhuang (a.k.a dmsolr) has been voted as a new committer.\n","excerpt":"Based on his continuous contributions, Haochao Zhuang (a.k.a dmsolr) has been voted as a new …","ref":"/events/welcome-haochao-zhuang-as-new-committer/","title":"Welcome Haochao Zhuang as new committer"},{"body":" 作者：innerpeacez 原文地址  本文主要讲述的是如何使用 Helm Charts 将 SkyWalking 部署到 Kubernetes 集群中，相关文档可以参考skywalking-kubernetes 和 backend-k8s 文档 。\n目前推荐的四种方式：\n 使用 helm 2 提供的 helm serve 启动本地 helm repo 使用本地 chart 文件部署 使用 harbor 提供的 repo 功能 直接从官方 repo 进行部署  注意：目前 skywalking 的 chart 还没有提交到官方仓库，请先参照前三种方式进行部署\nHelm 2 提供的 helm serve 打包对应版本的 skywalking chart 1.配置 helm 环境，参考 Helm 环境配置 ，如果你要部署 helm2 相关 chart 可以直接配置 helm2 的相关环境\n2.克隆/下载ZIP skywalking-kubernetes 这个仓库，仓库关于chart的目录结构如下\n helm-chart\n helm2  6.0.0-GA 6.1.0   helm3  6.3.0 6.4.0     克隆/下载ZIP 完成后进入指定目录打包对应版本的chart\ncd skywalking-kubernetes/helm-chart/\u0026lt;helm-version\u0026gt;/\u0026lt;skywalking-version\u0026gt; 注意：helm-version 为对应的 helm 版本目录，skywalking-version 为对应的 skywalking 版本目录，下面以helm3 和 skywalking 6.3.0 为例\ncd skywalking-kubernetes/helm-chart/helm3/6.3.0 3.由于skywalking 依赖 elasticsearch 作为存储库，执行以下命令更新依赖，默认会从官方repo进行拉取\nhelm dep up skywalking  Hang tight while we grab the latest from your chart repositories\u0026hellip; \u0026hellip;Successfully got an update from the \u0026ldquo;stable\u0026rdquo; chart repository Update Complete. ⎈Happy Helming!⎈ Saving 1 charts Downloading elasticsearch from repo https://kubernetes-charts.storage.googleapis.com/ Deleting outdated charts\n 如果官方 repo 不存在，请先添加官方仓库\nhelm repo add stable https://kubernetes-charts.storage.googleapis.com  \u0026ldquo;stable\u0026rdquo; has been added to your repositories\n 4.打包 skywalking , 执行以下命令\nhelm package skywalking/  Successfully packaged chart and saved it to: C:\\code\\innerpeacez_github\\skywalking-kubernetes\\helm-chart\\helm3\\6.3.0\\skywalking-0.1.0.tgz\n 打包完成后会在当前目录的同级目录生成 .tgz 文件\n ls  skywalking/ skywalking-0.1.0.tgz\n 启动 helm serve 由于上文配置的 helm 为 helm3 ,但是 helm 3中移除了 helm serve 的相关命令，所以需要另外一个环境配置helm2 的相关环境，下载 helm 2.14.3 的二进制文件，配置基本上没有大的差别，不在赘述\n初始化 helm\nhelm init 将上文生成的 skywalking-0.1.0.tgz 文件复制到 helm 相关目录 /root/.helm/repository/local,启动 serve\nhelm serve --address \u0026lt;ip\u0026gt;:8879 --repo-path /root/.helm/repository/local 注意： ip 为要能够被上文配置 helm 3 环境的机器访问到\n可以访问一下看看服务 serve 是否启动成功\ncurl ip:8879 部署 skywalking 1.在helm3 环境中添加启动的本地 repo\nhelm repo add local http://\u0026lt;ip\u0026gt;:8879 2.查看 skywalking chart 是否存在于本地仓库中\nhelm search skywalking  NAME CHART VERSION\tAPP VERSION\tDESCRIPTION local/skywalking 0.1.0 6.3.0 Apache SkyWalking APM System\n 3.部署\nhelm -n test install skywalking local/skywalking 这样 skywalking 就部署到了 k8s 集群中的 test 命名空间了，至此本地安装skywalking 就完成了。\n本地文件部署 如果你不想存储到 chart 到仓库中也可以直接使用本地文件部署 skywalking,按照上面的步骤将skywalking chart 打包完成之后，直接使用以下命令进行部署\nhelm -n test install skywalking skywalking-0.1.0.tgz harbor 作为 repo 存储 charts harbor 目前已经提供了，charts repo 的能力，这样就可以将 docker 镜像和 chart 存储在一个仓库中了，方便维护，具体harbor 的部署方法参考 Harbor 作为存储仓库存储 chart\n官方 repo 部署 目前没有发布到官方 repo 中，后续发布完成后，只需要执行下面命令即可\nhelm install -n test stable/skywalking 总结 四种方式都可以进行部署，如果你想要自定义 chart ,需要使用上述两种本地方法及 harbor 存储的方式，以便你修改好 chart 之后进行部署.\n","excerpt":"作者：innerpeacez 原文地址  本文主要讲述的是如何使用 Helm Charts 将 SkyWalking 部署到 Kubernetes 集群中，相关文档可以参 …","ref":"/zh/2019-10-08-how-to-use-sw-chart/","title":"使用 chart 部署 SkyWalking"},{"body":" Author: Wei Qiang GitHub  Background SkyWalking backend provides the alarm function, we can define some Alarm rules, call webhook after the rule is triggered. I share my implementation\nDemonstration SkyWalking alarm UI\ndingtalk message body\nIntroduction  install  go get -u github.com/weiqiang333/infra-skywalking-webhook cd $GOPATH/src/github.com/weiqiang333/infra-skywalking-webhook/ bash build/build.sh ./bin/infra-skywalking-webhook help  Configuration  main configs file: configs/production.yml dingtalk: p3: token...  Example  ./bin/infra-skywalking-webhook --config configs/production.yml --address 0.0.0.0:8000  SkyWalking backend alarm settings  webhooks: - http://127.0.0.1:8000/dingtalk Collaboration Hope that we can improve together webhook\nSkyWalking alarm rules may add more metric names (eg priority name), we can send different channels by locating different levels of alerts (dingtalk / SMS / phone)\nThanks.\n","excerpt":"Author: Wei Qiang GitHub  Background SkyWalking backend provides the alarm function, we can define …","ref":"/blog/2019-09-25-alarm-webhook-share/","title":"SkyWalking alarm webhook sharing"},{"body":"","excerpt":"","ref":"/tags/user-manual/","title":"User Manual"},{"body":"作者： SkyWalking committer，Kdump\n本文介绍申请Apache SkyWalking Committer流程, 流程包括以下步骤\n 与PMC成员表达想成为committer的意愿(主动/被动) PMC内部投票 PMC正式邮件邀请 填写Apache iCLA申请表 设置ApacheID和邮箱 设置GitHub加入Apache组织 GitHub其它一些不重要设置  前期过程  与PMC成员表达想成为committer的意愿(主动/被动) PMC内部投票  当你对项目的贡献活跃度足够高或足够多时, Skywalking项目的PMC(项目管理委员会)会找到你并询问你是否有意愿成为项目的Committer, 或者也可以主动联系项目的PMC表达自己的意向, 在此之后PMC们会进行内部讨论和投票并告知你是否可以进入下一个环节.这个过程可能需要一周. 如果PMC主动邀请你进行非正式的意愿咨询, 你可以选择接受或拒绝.\nPS:PMC会向你索要你的个人邮箱, 建议提供Gmail, 因为后期绑定Apache邮箱需要用到, 其它邮箱我不确定是否能绑定.\nPS:从Apache官方的流程来讲, 现有的PMC会在没有通知候选人的情况下先进行候选人投票, 但是Skywalking项目的PMC有可能更倾向于先得到候选人的意愿再进行投票.\n正式阶段   PMC正式邮件邀请\n 当你收到PMC正式的邀请邮件时, 恭喜你, 你已经通过了PMC的内部投票, 你需要用英文回答接受邀请或者拒绝邀请, 记住回复的时候一定要选择全部回复.    填写Apache iCLA申请表\n  在你收到的PMC邮件中, 有几个ASF官方链接需要你去浏览, 重点的内容是查看CLAs, 并填写Individual Contributor License Agreement, 你可以将icla.pdf文件下载到本地, 使用PDF工具填写里面所需的信息, 并打印出来签名(一定要手写签名, 否则会被要求重新签名), 再扫描(或手机拍照)成电子文档(需要回复PDF格式, 文件名建议重命名为你的名字-icla.pdf), 使用gpg对电子文档进行签名(参考[HOW-TO: SUBMITTING LICENSE AGREEMENTS AND GRANTS\n](http://www.apache.org/licenses/contributor-agreements.html#submitting)), Window可以使用GnuPG或者Gpg4win.\n  完成gpg签名后, 请将你签名用的公钥上送到pool.sks-keyservers.net服务器, 并在这个页面中验证你的公钥是否可以被搜索到, 搜索关键词可以是你秘钥中填写的名字或者邮箱地址.\n  gpg签名后, 会生成.pdf.asc的文件, 需要将你的你的名字-icla.pdf和你的名字-icla.pdf.asc以附件的方式一起发送到secretary@apache.org, 并抄送给private@skywalking.apache.org.\n    设置ApacheID和邮箱\n 大概5个工作日内, 你会收到一封来至于root@apache.org的邮件, 主题为Welcome to the Apache Software Foundation (ASF)!, 恭喜你, 你已经获得了ApacheID, 这时候你需要根据邮件内容的提示去设置你的ApacheID密码, 密码设置完成后, 需要在Apache Account Utility页面中重点设置Forwarding email address和Your GitHub Username两个信息.保存信息的时候需要你填写当前的ApacheID的密码. 现在进入Gmail, 选择右上角的齿轮-\u0026gt;设置-\u0026gt;账号和导入-\u0026gt;添加其他电子邮件地址-\u0026gt;参考Sending email from your apache.org email address给出的信息根据向导填写Apache邮箱.    设置GitHub加入Apache组织\n 进入Welcome to the GitBox Account Linking Utility!, 按照顺序将Apache Account和GitHub Account点绿, 想点绿MFA Status, 需要去GitHub开启2FA, 请参考配置双重身份验证完成2FA的功能. 等待1~2小时后登陆自己的GitHub的dashboard界面, 你应该会看到一条Apache组织邀请你加入的通知, 这个时候接受即可享有Skywalking相关GitHub项目权限了.    其它提示  GitHub其它一些不重要设置  在GitHub首页展示Apache组织的logo: 进入Apache GitHub组织-\u0026gt;People-\u0026gt;搜索自己的GitHubID-\u0026gt;将Private改成Public    ","excerpt":"作者： SkyWalking committer，Kdump\n本文介绍申请Apache SkyWalking Committer流程, 流程包括以下步骤\n 与PMC成员表达想成为committer的意 …","ref":"/zh/2019-09-12-apache-skywalking-committer-apply-process/","title":"Apache SkyWalking Committer申请流程"},{"body":"Based on his contributions to the skywalking ui project, Weijie Zou (a.k.a Kdump) has been accepted as a new committer.\n","excerpt":"Based on his contributions to the skywalking ui project, Weijie Zou (a.k.a Kdump) has been accepted …","ref":"/events/welcome-weijie-zou-as-a-new-committer/","title":"Welcome Weijie Zou as a new committer"},{"body":"6.4.0 release. Go to downloads page to find release tars.\n Highly recommend to upgrade due to Pxx metrics calculation bug. Make agent working in JDK9+ Module system.  Read changelog for the details.\n","excerpt":"6.4.0 release. Go to downloads page to find release tars.\n Highly recommend to upgrade due to Pxx …","ref":"/events/release-apache-skywalking-apm-6-4-0/","title":"Release Apache SkyWalking APM 6.4.0"},{"body":"  作者：innerpeacez 原文地址   如果你还不知道 Skywalking agent 是什么，请点击这里查看 Probe 或者这里查看快速了解agent,由于我这边大部分都是 JAVA 服务，所以下文以 Java 中使用 agent 为例，提供了以下三种方式供你选择\n三种方式：  使用官方提供的基础镜像 将 agent 包构建到已经存在的基础镜像中 sidecar 模式挂载 agent  1.使用官方提供的基础镜像 查看官方 docker hub 提供的基础镜像，只需要在你构建服务镜像是 From 这个镜像即可，直接集成到 Jenkins 中可以更加方便\n2.将 agent 包构建到已经存在的基础镜像中 提供这种方式的原因是：官方的镜像属于精简镜像，并且是 openjdk ，可能很多命令没有，需要自己二次安装，以下是我构建的过程\n  下载 oracle jdk\n这个现在 oracle 有点恶心了，wget 各种不行，然后我放弃了，直接从官网下载了\n  下载 skywalking 官方发行包，并解压（以6.3.0为例）\nwget https://www.apache.org/dyn/closer.cgi/skywalking/6.3.0/apache-skywalking-apm-6.3.0.tar.gz \u0026amp;\u0026amp; tar -zxvf apache-skywalking-apm-6.3.0.tar.gz   通过以下 dockerfile 构建基础镜像\nFROMalpine:3.8  ENV LANG=C.UTF-8 RUN set -eux \u0026amp;\u0026amp; \\  apk update \u0026amp;\u0026amp; apk upgrade \u0026amp;\u0026amp; \\  wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pub \u0026amp;\u0026amp;\\  wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-2.30-r0.apk \u0026amp;\u0026amp;\\  apk --no-cache add unzip vim curl git bash ca-certificates glibc-2.30-r0.apk file \u0026amp;\u0026amp; \\  rm -rf /var/lib/apk/* \u0026amp;\u0026amp;\\  mkdir -p /usr/skywalking/agent/ # A streamlined jreADD jdk1.8.0_221/ /usr/java/jdk1.8.0_221/ADD apache-skywalking-apm-bin/agent/ /usr/skywalking/agent/ # set envENV JAVA_HOME /usr/java/jdk1.8.0_221ENV PATH ${PATH}:${JAVA_HOME}/bin # run container with base path:/WORKDIR/ CMD bash  这里由于 alpine 是基于mini lib 的，但是 java 需要 glibc ,所以加入了 glibc 相关的东西，最后构建出的镜像大小在 490M 左右，因为加了挺多命令还是有点大，仅供参考，同样构建出的镜像也可以直接配置到 jenkins 中。\n3.sidecar 模式挂载 agent 如果你们的服务是部署在 Kubernetes 中，你还可以使用这种方式来使用 Skywalking Agent ,这种方式的好处在与不需要修改原来的基础镜像，也不用重新构建新的服务镜像，而是以sidecar 模式，通过共享volume的方式将agent 所需的相关文件挂载到已经存在的服务镜像中\n构建 skywalking agent sidecar 镜像的方法\n  下载skywalking 官方发行包，并解压\nwget https://www.apache.org/dyn/closer.cgi/skywalking/6.3.0/apache-skywalking-apm-6.3.0.tar.gz \u0026amp;\u0026amp; tar -zxvf apache-skywalking-apm-6.3.0.tar.gz   通过以下 dockerfile 进行构建\nFROMbusybox:latest  ENV LANG=C.UTF-8 RUN set -eux \u0026amp;\u0026amp; mkdir -p /usr/skywalking/agent/ ADD apache-skywalking-apm-bin/agent/ /usr/skywalking/agent/ WORKDIR/  注意：这里我没有在dockerfile中下载skywalking 发行包是因为保证构建出的 sidecar 镜像保持最小，bosybox 只有700 k左右，加上 agent 最后大小小于20M\n如何使用 sidecar 呢？\napiVersion: apps/v1 kind: Deployment metadata: labels: name: demo-sw name: demo-sw spec: replicas: 1 selector: matchLabels: name: demo-sw template: metadata: labels: name: demo-sw spec: initContainers: - image: innerpeacez/sw-agent-sidecar:latest name: sw-agent-sidecar imagePullPolicy: IfNotPresent command: [\u0026#39;sh\u0026#39;] args: [\u0026#39;-c\u0026#39;,\u0026#39;mkdir -p /skywalking/agent \u0026amp;\u0026amp; cp -r /usr/skywalking/agent/* /skywalking/agent\u0026#39;] volumeMounts: - mountPath: /skywalking/agent name: sw-agent containers: - image: nginx:1.7.9 name: nginx volumeMounts: - mountPath: /usr/skywalking/agent name: sw-agent ports: - containerPort: 80 volumes: - name: sw-agent emptyDir: {} 以上是挂载 sidecar 的 deployment.yaml 文件，以nginx 作为服务为例，主要是通过共享 volume 的方式挂载 agent，首先 initContainers 通过 sw-agent 卷挂载了 sw-agent-sidecar 中的 /skywalking/agent ，并且将上面构建好的镜像中的 agent 目录 cp 到了 /skywalking/agent 目录，完成之后 nginx 启动时也挂载了 sw-agent 卷，并将其挂载到了容器的 /usr/skywalking/agent 目录，这样就完成了共享过程。\n总结 这样除去 ServiceMesh 以外，我能想到的方式就介绍完了，希望可以帮助到你。最后给 Skywalking 一个 Star 吧，国人的骄傲。\n","excerpt":"作者：innerpeacez 原文地址   如果你还不知道 Skywalking agent 是什么，请点击这里查看 Probe 或者这里查看快速了解agent,由于我这边大部分都是 JAVA 服务， …","ref":"/zh/2019-08-30-how-to-use-skywalking-agent/","title":"如何使用 SkyWalking Agent ？"},{"body":"Based on his continuous contributions, Yuguang Zhao (a.k.a zhaoyuguang) has been invited to join the PMC. Welcome aboard.\n","excerpt":"Based on his continuous contributions, Yuguang Zhao (a.k.a zhaoyuguang) has been invited to join the …","ref":"/events/welcome-yuguang-zhao-to-join-the-pmc/","title":"Welcome Yuguang Zhao to join the PMC"},{"body":"Based on his continuous contributions, Zhenxu Ke (a.k.a kezhenxu94) has been invited to join the PMC. Welcome aboard.\n","excerpt":"Based on his continuous contributions, Zhenxu Ke (a.k.a kezhenxu94) has been invited to join the …","ref":"/events/welcome-zhenxu-ke-to-join-the-pmc/","title":"Welcome Zhenxu Ke to join the PMC"},{"body":"Based on his contributions to the skywalking PHP project, Yanlong He (a.k.a heyanlong has been accepted as a new committer.\n","excerpt":"Based on his contributions to the skywalking PHP project, Yanlong He (a.k.a heyanlong has been …","ref":"/events/welcome-yanlong-he-as-a-new-committer/","title":"Welcome Yanlong He as a new committer"},{"body":"6.3.0 release. Go to downloads page to find release tars.\n Improve ElasticSearch storage implementation performance again. OAP backend re-install w/o agent reboot required.  Read changelog for the details.\n","excerpt":"6.3.0 release. Go to downloads page to find release tars.\n Improve ElasticSearch storage …","ref":"/events/release-apache-skywalking-apm-6-3-0/","title":"Release Apache SkyWalking APM 6.3.0"},{"body":"6.2.0 release. Go to downloads page to find release tars. ElasticSearch storage implementation changed, high reduce payload to ElasticSearch cluster.\nRead changelog for the details.\n","excerpt":"6.2.0 release. Go to downloads page to find release tars. ElasticSearch storage implementation …","ref":"/events/release-apache-skywalking-apm-6-2-0/","title":"Release Apache SkyWalking APM 6.2.0"},{"body":"Based on his continuous contributions, Zhenxu Ke (a.k.a kezhenxu94) has been voted as a new committer.\n","excerpt":"Based on his continuous contributions, Zhenxu Ke (a.k.a kezhenxu94) has been voted as a new …","ref":"/events/welcome-zhenxu-ke-as-a-new-committer/","title":"Welcome Zhenxu Ke as a new committer"},{"body":"6.1.0 release. Go to downloads page to find release tars. This is the first top level project version.\nKey updates\n RocketBot UI OAP performance improvement  ","excerpt":"6.1.0 release. Go to downloads page to find release tars. This is the first top level project …","ref":"/events/release-apache-skywalking-apm-6-1-0/","title":"Release Apache SkyWalking APM 6.1.0"},{"body":"Apache SkyWalking PMC accept the RocketBot UI contributions. After IP clearance, it will be released in SkyWalking 6.1 soon.\n","excerpt":"Apache SkyWalking PMC accept the RocketBot UI contributions. After IP clearance, it will be released …","ref":"/events/rocketbot-ui-has-been-accepted-as-skywalking-primary-ui/","title":"RocketBot UI has been accepted as SkyWalking primary UI"},{"body":"Apache board approved SkyWalking graduated as TLP at April 17th 2019.\n","excerpt":"Apache board approved SkyWalking graduated as TLP at April 17th 2019.","ref":"/events/skywalking-graduated-as-apache-top-level-project/","title":"SkyWalking graduated as Apache Top Level Project"},{"body":"Based on his continuous contributions, he has been accepted as a new committer.\n","excerpt":"Based on his continuous contributions, he has been accepted as a new committer.","ref":"/events/welcome-yuguang-zhao-as-a-new-committer/","title":"Welcome Yuguang Zhao as a new committer"},{"body":"APM和调用链跟踪 随着企业经营规模的扩大，以及对内快速诊断效率和对外SLA（服务品质协议，service-level agreement)的追求，对于业务系统的掌控度的要求越来越高，主要体现在：\n 对于第三方依赖的监控，实时/准实时了解第三方的健康状况/服务品质，降低第三方依赖对于自身系统的扰动（服务降级、故障转移） 对于容器的监控，实时/准实时的了解应用部署环境（CPU、内存、进程、线程、网络、带宽）情况，以便快速扩容/缩容、流量控制、业务迁移 业务方对于自己的调用情况，方便作容量规划，同时对于突发的请求也能进行异常告警和应急准备 自己业务的健康、性能监控，实时/准实时的了解自身的业务运行情况，排查业务瓶颈，快速诊断和定位异常，增加对自己业务的掌控力  同时，对于企业来说，能够更精确的了解资源的使用情况，对于成本核算和控制也有非常大的裨益。\n在这种情况下，一般都会引入APM（Application Performance Management \u0026amp; Monitoring）系统，通过各种探针采集数据，收集关键指标，同时搭配数据呈现和监控告警，能够解决上述的大部分问题。\n然而随着RPC框架、微服务、云计算、大数据的发展，同时业务的规模和深度相比过往也都增加了很多，一次业务可能横跨多个模块/服务/容器，依赖的中间件也越来越多，其中任何一个节点出现异常，都可能导致业务出现波动或者异常，这就导致服务质量监控和异常诊断/定位变得异常复杂，于是催生了新的业务监控模式：调用链跟踪\n 能够分布式的抓取多个节点的业务记录，并且通过统一的业务id（traceId，messageId，requestId等）将一次业务在各个节点的记录串联起来，方便排查业务的瓶颈或者异常点  产品对比 APM和调用链跟踪均不是新诞生事务，很多公司已经有了大量的实践，不过开源的并且能够开箱即用的产品并不多，这里主要选取了Pinpoint，Skywalking，CAT来进行对比（当然也有其他的例如Zipkin，Jaeger等产品，不过总体来说不如前面选取的3个完成度高），了解一下APM和调用链跟踪在开源方面的发展状态。\nPinpoint Pinpoint是一个比较早并且成熟度也非常高的APM+调用链监控的项目，在全世界范围内均有用户使用，支持Java和PHP的探针，数据容器为HBase，其界面参考：\nSkywalking Skywalking是一个新晋的项目，最近一两年发展非常迅猛，本身支持OpenTracing规范，优秀的设计提供了良好的扩展性，支持Java、PHP、.Net、NodeJs探针，数据容器为ElasticSearch，其界面参考：\nCAT CAT是由美团开源的一个APM项目，也历经了多年的迭代升级，拥有大量的企业级用户，对于监控和报警整合比较紧密，支持Java、C/C++、.Net、Python、Go、NodeJs，不过CAT目前主要通过侵入性的方式接入，数据容器包括HDFS（存储原始数据）和mysql（二次统计），其界面参考：\n横向对比 上面只是做了一个简介，那这三个项目各自有什么特色或者优势/劣势呢（三者的主要产品均针对Java，这里也主要针对Java的特性）？\n Pinpoint  优势  大企业/长时间验证，稳定性和完成度高 探针收集的数据粒度比较细 HBase的数据密度较大，支持PB级别下的数据查询 代码设计考虑的扩展性较弱，二次开发难度较大（探针为插件式，开发比较简单） 拥有完整的APM和调用链跟踪功能   劣势  代码针对性强，扩展较难 容器为HBase，查询功能较弱（主要为时间维度） 探针的额外消耗较多（探针采集粒度细，大概10%~20%） 项目趋于成熟，而扩展难度较大，目前社区活跃度偏低，基本只进行探针的增加或者升级 缺少自定义指标的设计     Skywalking  优势  数据容器为ES，查询支持的维度较多并且扩展潜力大 项目设计采用微内核+插件，易读性和扩展性都比较强 主要的研发人员为华人并且均比较活跃，能够进行更加直接的沟通 拥有完整的APM和调用链跟踪功能   劣势  项目发展非常快，稳定性有待验证 ES数据密度较小，在PB级别可能会有性能压力 缺少自定义指标的设计     CAT  优势  大企业/长时间验证，稳定性和完成度高 采用手动数据埋点而不是探针，数据采集的灵活性更强 支持自定义指标 代码设计考虑的扩展性较弱，并且数据结构复杂，二次开发难度较大 拥有完善的监控告警机制   劣势  代码针对性强，扩展较难 需要手动接入埋点，代码侵入性强 APM功能完善，但是不支持调用链跟踪      基本组件 如果分别去看Pinpoint/Skywalking/CAT的整体设计，我们会发现三者更像是一个规范的三种实现，虽然各自有不同的机制和特性，但是从模块划分和功能基本是一致的：\n当然也有一些微小的区别：\n Pinpoint基本没有aggregator，同时query和alarm集成在了web中，只有agent，collector和web Skywalking则是把collector、aggregator、alarm集成为OAP（Observability Analysis Platform），并且可以通过集群部署，不同的实例可以分别承担collector或者aggregator+alarm的角色 CAT则和Skywalking类似，把collector、aggregator、alarm集成为cat-consumer，而由于CAT有比较复杂的配置管理，所以query和配置一起集成为cat-home 当然最大的区别是Pinpoint和Skywalking均是通过javaagent做字节码的扩展，通过切面编程采集数据，类似于探针，而CAT的agent则更像是一个工具集，用于手动埋点  Skywalking 前戏这么多，终于开始进入主题，介绍今天的主角：Skywalking，不过通过之前的铺垫，我们基本都知道了Skywalking期望解决的问题以及总体的结构，下面我们则从细节来看Skywalking是怎么一步一步实现的。\n模块构成 首先，Skywalking进行了精准的领域模型划分：\n整个系统分为三部分：\n agent：采集tracing（调用链数据）和metric（指标）信息并上报 OAP：收集tracing和metric信息通过analysis core模块将数据放入持久化容器中（ES，H2（内存数据库），mysql等等），并进行二次统计和监控告警 webapp：前后端分离，前端负责呈现，并将查询请求封装为graphQL提交给后端，后端通过ribbon做负载均衡转发给OAP集群，再将查询结果渲染展示  而整个Skywalking（包括agent和OAP，而webapp后端业务非常简单主要就是认证和请求转发）均通过微内核+插件式的模式进行编码，代码结构和扩展性均非常强，具体设计可以参考： 从Skywalking看如何设计一个微核+插件式扩展的高扩展框架 ，Spring Cloud Gateway的GatewayFilterFactory的扩展也是通过这种plugin define的方式来实现的。\nSkywalking也提供了其他的一些特性：\n 配置重载：支持通过jvm参数覆写默认配置，支持动态配置管理 集群管理：这个主要体现在OAP，通过集群部署分担数据上报的流量压力和二次计算的计算压力，同时集群也可以通过配置切换角色，分别面向数据采集（collector）和计算（aggregator，alarm），需要注意的是agent目前不支持多collector负载均衡，而是随机从集群中选择一个实例进行数据上报 支持k8s和mesh 支持数据容器的扩展，例如官方主推是ES，通过扩展接口，也可以实现插件去支持其他的数据容器 支持数据上报receiver的扩展，例如目前主要是支持gRPC接受agent的上报，但是也可以实现插件支持其他类型的数据上报（官方默认实现了对Zipkin，telemetry和envoy的支持） 支持客户端采样和服务端采样，不过服务端采样最有意义 官方制定了一个数据查询脚本规范：OAL（Observability Analysis Language），语法类似Linq，以简化数据查询扩展的工作量 支持监控预警，通过OAL获取数据指标和阈值进行对比来触发告警，支持webhook扩展告警方式，支持统计周期的自定义，以及告警静默防止重复告警  数据容器 由于Skywalking并没有自己定制的数据容器或者使用多种数据容器增加复杂度，而是主要使用ElasticSearch（当然开源的基本上都是这样来保持简洁，例如Pinpoint也只使用了HBase），所以数据容器的特性以及自己数据结构基本上就限制了业务的上限，以ES为例：\n ES查询功能异常强大，在数据筛选方面碾压其他所有容器，在数据筛选潜力巨大（Skywalking默认的查询维度就比使用HBase的Pinpoint强很多） 支持sharding分片和replicas数据备份，在高可用/高性能/大数据支持都非常好 支持批量插入，高并发下的插入性能大大增强 数据密度低，源于ES会提前构建大量的索引来优化搜索查询，这是查询功能强大和性能好的代价，但是链路跟踪往往有非常多的上下文需要记录，所以Skywalking把这些上下文二进制化然后通过Base64编码放入data_binary字段并且将字段标记为not_analyzed来避免进行预处理建立查询索引  总体来说，Skywalking尽量使用ES在大数据和查询方面的优势，同时尽量减少ES数据密度低的劣势带来的影响，从目前来看，ES在调用链跟踪方面是不二的数据容器，而在数据指标方面，ES也能中规中矩的完成业务，虽然和时序数据库相比要弱一些，但在PB级以下的数据支持也不会有太大问题。\n数据结构 如果说数据容器决定了上限，那么数据结构则决定了实际到达的高度。Skywalking的数据结构主要为：\n 数据维度（ES索引为skywalking_*_inventory)  service：服务 instance：实例 endpoint：接口 network_adress：外部依赖   数据内容  原始数据  调用链跟踪数据（调用链的trace信息，ES索引为skywalking_segment，Skywalking主要的数据消耗都在这里） 指标（主要是jvm或者envoy的运行时指标，例如ES索引skywalking_instance_jvm_cpu）   二次统计指标  指标（按维度/时间二次统计出来的例如pxx、sla等指标，例如ES索引skywalking_database_access_p75_month） 数据库慢查询记录（数据库索引：skywalking_top_n_database_statement）   关联关系（维度/指标之间的关联关系，ES索引为skywalking_*_relation_*) 特别记录  告警信息（ES索引为skywalking_alarm_record） 并发控制（ES索引为skywalking_register_lock）      其中数量占比最大的就是调用链跟踪数据和各种指标，而这些数据均可以通过OAP设置过期时间，以降低历史数据的对磁盘占用和查询效率的影响。\n调用链跟踪数据 作为Skywalking的核心数据，调用链跟踪数据（skywalking_segment）基本上奠定了整个系统的基础，而如果要详细的了解调用链跟踪的话，就不得不提到openTracing。\nopenTracing基本上是目前开源调用链跟踪系统的一个事实标准，它制定了调用链跟踪的基本流程和基本的数据结构，同时也提供了各个语言的实现。如果用一张图来表现openTracing，则是如下：\n其中：\n SpanContext：一个类似于MDC（Slfj)或者ThreadLocal的组件，负责整个调用链数据采集过程中的上下文保持和传递 Trace：一次调用的完整记录  Span：一次调用中的某个节点/步骤，类似于一层堆栈信息，Trace是由多个Span组成，Span和Span之间也有父子或者并列的关系来标志这个节点/步骤在整个调用中的位置  Tag：节点/步骤中的关键信息 Log：节点/步骤中的详细记录，例如异常时的异常堆栈   Baggage：和SpanContext一样并不属于数据结构而是一种机制，主要用于跨Span或者跨实例的上下文传递，Baggage的数据更多是用于运行时，而不会进行持久化    以一个Trace为例：\n首先是外部请求调用A，然后A依次同步调用了B和C，而B被调用时会去同步调用D，C被调用的时候会依次同步调用E和F，F被调用的时候会通过异步调用G，G则会异步调用H，最终完成一次调用。\n上图是通过Span之间的依赖关系来表现一个Trace，而在时间线上，则可以有如下的表达：\n当然，如果是同步调用的话，父Span的时间占用是包括子Span的时间消耗的。\n而落地到Skywalking中，我们以一条skywalking_segment的记录为例：\n{ \u0026quot;trace_id\u0026quot;: \u0026quot;52.70.15530767312125341\u0026quot;, \u0026quot;endpoint_name\u0026quot;: \u0026quot;Mysql/JDBI/Connection/commit\u0026quot;, \u0026quot;latency\u0026quot;: 0, \u0026quot;end_time\u0026quot;: 1553076731212, \u0026quot;endpoint_id\u0026quot;: 96142, \u0026quot;service_instance_id\u0026quot;: 52, \u0026quot;version\u0026quot;: 2, \u0026quot;start_time\u0026quot;: 1553076731212, \u0026quot;data_binary\u0026quot;: \u0026quot;CgwKCjRGnPvp5eikyxsSXhD///////////8BGMz62NSZLSDM+tjUmS0wju8FQChQAVgBYCF6DgoHZGIudHlwZRIDc3FsehcKC2RiLmluc3RhbmNlEghyaXNrZGF0YXoOCgxkYi5zdGF0ZW1lbnQYAiA0\u0026quot;, \u0026quot;service_id\u0026quot;: 2, \u0026quot;time_bucket\u0026quot;: 20190320181211, \u0026quot;is_error\u0026quot;: 0, \u0026quot;segment_id\u0026quot;: \u0026quot;52.70.15530767312125340\u0026quot; } 其中：\n trace_id：本次调用的唯一id，通过snowflake模式生成 endpoint_name：被调用的接口 latency：耗时 end_time：结束时间戳 endpoint_id：被调用的接口的唯一id service_instance_id：被调用的实例的唯一id version：本数据结构的版本号 start_time：开始时间戳 data_binary：里面保存了本次调用的所有Span的数据，序列化并用Base64编码，不会进行分析和用于查询 service_id：服务的唯一id time_bucket：调用所处的时段 is_error：是否失败 segment_id：数据本身的唯一id，类似于主键，通过snowflake模式生成  这里可以看到，目前Skywalking虽然相较于Pinpoint来说查询的维度要多一些，但是也很有限，而且除了endPoint，并没有和业务有关联的字段，只能通过时间/服务/实例/接口/成功标志/耗时来进行非业务相关的查询，如果后续要增强业务相关的搜索查询的话，应该还需要增加一些用于保存动态内容（如messageId，orderId等业务关键字）的字段用于快速定位。\n指标 指标数据相对于Tracing则要简单得多了，一般来说就是指标标志、时间戳、指标值，而Skywalking中的指标有两种：一种是采集的原始指标值，例如jvm的各种运行时指标（例如cpu消耗、内存结构、GC信息等）；一种是各种二次统计指标（例如tp性能指标、SLA等，当然也有为了便于查询的更高时间维度的指标，例如基于分钟、小时、天、周、月）\n例如以下是索引skywalking_endpoint_cpm_hour中的一条记录，用于标志一个小时内某个接口的cpm指标：\n{ \u0026quot;total\u0026quot;: 8900, \u0026quot;service_id\u0026quot;: 5, \u0026quot;time_bucket\u0026quot;: 2019031816, \u0026quot;service_instance_id\u0026quot;: 5, \u0026quot;entity_id\u0026quot;: \u0026quot;7\u0026quot;, \u0026quot;value\u0026quot;: 148 } 各个字段的释义如下：\n total：一分钟内的调用总量 service_id：所属服务的唯一id time_bucket：统计的时段 service_instance_id：所属实例的唯一id entity_id：接口（endpoint）的唯一id value：cpm的指标值（cpm=call per minute，即total/60）  工程实现 Skywalking的工程实现堪比Dubbo，框架设计和代码质量都达到非常高的水准，以dubbo为例，即使2012年发布的老版本放到当今，其设计和编码看起来也依然赏心悦目，设计简洁但是覆盖了所有的核心需求，同时又具备非常强的扩展性，二次开发非常简单，然而却又不会像Spring那样过度封装（当然Spring作为一个更加高度通用的框架，更高的封装也是有必要的）导致代码阅读异常困难。\nagent agent（apm-sniffer）是Skywalking的Java探针实现，主要负责：\n 采集应用实例的jvm指标 通过切向编程进行数据埋点，采集调用链数据 通过RPC将采集的数据上报  当然，agent还实现了客户端采样，不过在APM监控系统里进行客户端数据采样都是没有灵魂的，所以这里就不再赘述了。\n首先，agent通过 org.apache.skywalking.apm.agent.core.boot.BootService 实现了整体的插件化，agent启动会加载所有的BootService实现，并通过 ServiceManager 来管理这些插件的生命周期，采集jvm指标、gRPC连接管理、调用链数据维护、数据上报OAP这些服务均是通过这种方式扩展。\n然后，agent还通过bytebuddy以javaagent的模式，通过字节码增强的机制来构造AOP环境，再提供PluginDefine的规范方便探针的开发，最终实现非侵入性的数据埋点，采集调用链数据。\n最终落地到代码上则异常清晰：\n//通过bytebuddy的AgentBuilder构造javaagent增强classLoader new AgentBuilder.Default(byteBuddy) .ignore( //忽略这些包的内容，不进行增强 nameStartsWith(\u0026quot;net.bytebuddy.\u0026quot;) .or(nameStartsWith(\u0026quot;org.slf4j.\u0026quot;)) .or(nameStartsWith(\u0026quot;org.apache.logging.\u0026quot;)) .or(nameStartsWith(\u0026quot;org.groovy.\u0026quot;)) .or(nameContains(\u0026quot;javassist\u0026quot;)) .or(nameContains(\u0026quot;.asm.\u0026quot;)) .or(nameStartsWith(\u0026quot;sun.reflect\u0026quot;)) .or(allSkyWalkingAgentExcludeToolkit()) .or(ElementMatchers.\u0026lt;TypeDescription\u0026gt;isSynthetic())) //通过pluginFinder加载所有的探针扩展，并获取所有可以增强的class .type(pluginFinder.buildMatch()) //按照pluginFinder的实现，去改变字节码增强类 .transform(new Transformer(pluginFinder)) //通过listener订阅增强的操作记录，方便调试 .with(new Listener()) .installOn(instrumentation); try { //加载所有的service实现并启动 ServiceManager.INSTANCE.boot(); } catch (Exception e) { logger.error(e, \u0026quot;Skywalking agent boot failure.\u0026quot;); } agent也提供了非常简单的扩展实现机制，以增强一个普通类的方法为例，首先你需要定义一个切向点：\npublic interface InstanceMethodsInterceptPoint { //定义切向方法的适配器，符合适配器的class将被增强 ElementMatcher\u0026lt;MethodDescription\u0026gt; getMethodsMatcher(); //增强的具体实现类，classReference String getMethodsInterceptor(); //是否重写参数 boolean isOverrideArgs(); } 然后你还需要一个增强的实现类：\npublic interface InstanceMethodsAroundInterceptor { //方法真正执行前执行 void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class\u0026lt;?\u0026gt;[] argumentsTypes, MethodInterceptResult result) throws Throwable; //方法真正执行后执行 Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class\u0026lt;?\u0026gt;[] argumentsTypes, Object ret) throws Throwable; //当异常发生时执行 void handleMethodException(EnhancedInstance objInst, Method method, Object[] allArguments, Class\u0026lt;?\u0026gt;[] argumentsTypes, Throwable t); } 一般在执行前和执行后进行数据埋点，就可以采集到想要的数据，当然实际编程要稍微复杂一点，不过官方也实现了对应的abstract类和数据埋点工具类，所以探针的二次开发在Skywalking这个级别确实是非常简单，只需要处理好资源占用和并发问题即可。真正的难点是要对需要增强的对象非常了解，熟悉其运作机制，才能找准切向点，既要所有的流程都需要经过这个点，又可以抓取到期望抓取的上下文信息。同时，多版本的适配和测试也是非常大的工作量，官方虽然提供witness的机制（通过验证某个class是否存在来验证版本），但是作为影响全局的探针，开发和测试都是需要慎之又慎的。\nOAP 同agent类似，OAP作为Skywalking最核心的模块，也实现了自己的扩展机制，不过在这里叫做Module，具体可以参考library-module，在module的机制下，Skywalking实现了自己必须核心组件：\n core：整个OAP核心业务（remoting、cluster、storage、analysis、query、alarm）的规范和接口 cluster：集群管理的具体实现 storage：数据容器的具体实现 query：为前端提供的查询接口的具体实现 receiver：接收探针上报数据的接收器的具体实现 alarm：监控告警的具体实现  以及一个可选组件：\n telemetry：用于监控OAP自身的健康状况  而前面提到的OAP的高扩展性则体现在核心业务的规范均定义在了core中，如果有需要自己扩展的，只需要自己单独做自己的实现，而不需要做侵入式的改动，最典型的示例则是官方支持的storage，不仅支持单机demo的内存数据库H2和经典的ES，连目前开源的Tidb都可以接入。\n初步实践 对于Skywalking的实践我们经历了三个阶段\n 线下测试 第一次生产环境小规模测试 第二次生产环境小规模测试+全量接入  线下测试 环境 由于是线下测试，所以我们直接使用物理机（E5-2680v2 x2, 128G)虚拟了一个集群（实际性能相比云服务器应该偏好一些）：\n ES：单机实例，v6.5，4C8G，jvm内存分配为4G OAP：单机实例，v6.1.0-SNAPSHOT，4C8G，jvm内存分配为4G 应用：基于SpringCloud的4个测试实例,调用关系为A-\u0026gt;B-\u0026gt;C-\u0026gt;D，QPS为200  测试结果 拓扑图：\nOAP机器监控：\nES机器监控：\n服务监控面板：\n其中一个调用链记录：\n可以看出，Skywalking非常依赖CPU（不论是OAP还是ES），同时对于网络IO也有一定的要求，至于ES的文件IO在可接受范围内，毕竟确实有大量内容需要持久化。测试结果也基本达到预期要求，调用链和各个指标的监控都工作良好。\n第一次生产环境测试 在线下测试之后，我们再进行了一次基于实际业务针对探针的测试，测试没有发现探针的异常问题，也没有影响业务的正常运作，同时对于jvm实例影响也不是很大，CPU大概提高了5%左右，并不很明显。在这个基础上我们选择了线上的一台服务器，进行了我们第一次生产环境的测试。\n环境  ES：基于现有的一个ES集群，node x 3，v6.0 OAP：2C4G x 2，v6.1.0-SNAPSHOT，jvm内存分配为2G 应用：两个jvm实例  测试时间：03.11-03.16\n测试结果 业务机器负载情况：\n从最敏感的CPU指标上来看，增加agent并没有导致可见的CPU使用率的变化，而其他的内存、网络IO、连接数也基本没有变化。\nOAP负载情况：\n可以看到机器的CPU和网络均有较大的波动，但是也都没有真正打爆服务器，但是我们的实例却经常出现两种日志：\n One trace segment has been abandoned, cause by buffer is full.\n  Collector traceSegment service doesn\u0026rsquo;t response in xxx seconds.\n 通过阅读源码发现：\n agent和OAP只会使用一个长连接阻塞式的交换数据，如果某次数据交换没有得到响应，则会阻塞后续的上报流程（一般长连接的RPC请求会在数据传输期间互相阻塞，但是不会在等待期间互相阻塞，当然这也是源于agent并没有并发上报的机制），所以一旦OAP在接收数据的过程中发生阻塞，就会导致agent本地的缓冲区满，最终只能将监控数据直接丢弃防止内存泄漏  而导致OAP没有及时响应的一方面是OAP本身性能不够（OAP需要承担大量的二次统计工作，通过Jstack统计，长期有超过几十个线程处于RUNNABLE状态，据吴晟描述目前OAP都是高性能模式，后续将会提供配置来支持低性能模式），另一方面可能是ES批量插入效率不够，因此我们修改了OAP的批量插入参数来增加插入频率，降低单次插入数量：\n bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:2000 -\u0026gt; 20} # Execute the bulk every 2000 requests bulkSize: ${SW_STORAGE_ES_BULK_SIZE:20 -\u0026gt; 2} # flush the bulk every 20mb flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10 -\u0026gt; 2} # flush the bulk every 10 seconds whatever the number of requests  虽然 service doesn\u0026rsquo;t response 出现的频率明显降低，但是依然还是会偶尔出现，而每一次出现都会伴随大量的 trace segment has been abandoned ，推测OAP和ES可能都存在性能瓶颈（应该进行更进一步的诊断确定问题，不过当时直接和吴晟沟通，确认确实OAP非常消耗CPU资源，考虑到当时部署只是2C，并且还部署有其他业务，就没有进一步的测试）。\n同时，在频繁的数据丢弃过程中，也偶发了一个bug：当agent上报数据超时并且大量丢弃数据之后，即使后续恢复正常也能通过日志看到数据正常上报，在查询界面查询的时候，会查不到这个实例上报的数据，不过在重启OAP和agent之后，之前上报的数据又能查询到，这个也和吴晟沟通过，没有其他的案例，后续想重现却也一直没有成功。\n而同时还发现两个更加严重的问题：\n 我们使用的是线上已经部署好的ES集群，其版本只有6.0，而新的Skywalking使用了6.3的查询特性，导致很多查询执行报错，只能使用最简单的查询 我们的kafka集群版本也非常古老，不支持v1或者更高版本的header，而kafka的探针强依赖header来传输上下文信息，导致kafka客户端直接报错影响业务，所以也立即移除了kafka的探针  在这一次测试中，我们基本确认了agent对于应用的影响，同时也发现了一些我们和Skywalking的一些问题，留待后续测试确认。\n第二次生产环境测试 为了排除性能和ES版本的影响，测试Skywalking本身的可用性，参考吴晟的建议（这也是在最初技术选型的时候没有选择Pinpoint和CAT的部分原因：一方面Skywalking的功能符合我们的要求，更重要的是有更加直接和效率的和项目维护者直接沟通的渠道），所以这一次我们新申请了ES集群和OAP机器。\n环境  ES：腾讯云托管ES集群，4C16G x 3 SSD，v6.4 OAP：16C32G，standalone，jvm分配24G 应用：2~8个jvm实例  测试时间：03.18-至今\n测试结果 OAP负载情况：\nES集群负载：\n测试过程中，我们先接入了一台机器上的两个实例，完全没有遇到一测中的延迟或者数据丢弃的问题，三天后我们又接入了另外两台机器的4个实例，这之后两天我们又接入了另外两台机器的2个实例。依然没有遇到一测中的延迟或者数据丢弃的问题。\n而ES负载的监控也基本验证了一测延迟的问题，Skywalking由于较高的并发插入，对于ES的性能压力很大（批量插入时需要针对每条数据分析并且构建查询索引），大概率是ES批量插入性能不够导致延迟，考虑到我们仅仅接入了8个实例，日均segment插入量大概5000万条（即日均5000万次独立调用），如果想支持更大规模的监控，对于ES容量规划势必要留够足够的冗余。同时OAP和ES集群的网络开销也不容忽视，在支撑大规模的监控时，需要集群并且receiver和aggregattor分离部署来分担网络IO的压力。\n而在磁盘容量占用上，我们设置的原始数据7天过期，目前刚刚开始滚动过期，目前segment索引已经累计了314757240条记录总计158G数据，当然我们目前异常记录较少，如果异常记录较多的话，其磁盘开销将会急剧增加（span中会记录异常堆栈信息）。而由于选择的SSD，磁盘的写入和查询性能都很高，即使只有3个节点，也完全没有任何压力。\n而在新版本的ES集群下，Skywalking的所有查询功能都变得可用，和我们之前自己的单独编写的异常指标监控都能完美对照。当然我们也遇到一个问题：Skywalking仅采集了调用记录，但是对于调用过程中的过程数据，除了异常堆栈其他均没有采集，导致真的出现异常也缺少充足的上下文信息还原现场，于是我们扩展了Skywalking的两个探针（我们项目目前重度依赖的组件）：OkHttp（增加对requestBody和responseBody的采集）和SpringMVC（增加了对requestBody的采集），目前工作正常，如果进一步的增加其他的探针，采集到足够的数据，那么我们基本可以脱离ELK了。\n而OAP方面，CPU和内存的消耗远远低于预期的估计，CPU占用率一直较低，而分配的24G内存也仅使用了10+G，完全可以支持更大规模的接入量，不过在网络IO方面可能存在一定的风险，推测应该8C16G的容器就足以支持十万CPM级别的数据接入。\n当然我们在查询也遇到了一些瓶颈，最大的问题就是无法精确的命中某一条调用记录，就如前面的分析，因为segment的数据结构问题，无法进行面向业务的查询（例如messageId、requestId、orderId等），所以如果想精确匹配某一次调用请求，需要通过各个维度的条件约束慢慢缩小范围最后定位。\nSkywalking展望 通过上述对Skywalking的剖析和实践，Skywalking确实是一个优秀的APM+调用链跟踪监控系统，能够覆盖大部分使用场景，让研发和运维能够更加实时/准实时的了解线上服务的运行情况。当然Skywailking也不是尽善尽美，例如下面就是个人觉得目前可见的不满足我们期望的：\n 数据准实时通过gRPC上报，本地缓存的瓶颈（当然官方主要是为了简化模型，减少依赖，否则Skywalking还依赖ELK就玩得有点大了）  缓存队列的长度，过长占据内存，过短容易buffer满丢弃数据 优雅停机同时又不丢失缓存   数据上报需要在起点上报，链路回传的时候需要携带SPAN及子SPAN的信息，当链路较长或者SPAN保存的信息较多时，会额外消耗一定的带宽 skywalking更多是一个APM系统而不是分布式调用链跟踪系统  在整个链路的探针上均缺少输入输出的抓取 在调用链的筛查上并没用进行增强，并且体现在数据结构的设计，例如TAG信息均保存在SPAN信息中，而SPAN信息均被BASE64编码作为数据保存，无法检索，最终trace的筛查只能通过时间/traceId/service/endPoint/state进行非业务相关的搜索   skywalking缺少对三方接口依赖的指标，这个对于系统稳定往往非常重要  而作为一个初级的使用者，个人觉得我们可以使用有限的人力在以下方向进行扩展：\n 增加receiver：整合ELK，通过日志采集采集数据，降低异构系统的采集开发成本 优化数据结构，提供基于业务关键数据的查询接口 优化探针，采集更多的业务数据，争取代替传统的ELK日志简单查询，绝大部分异常诊断和定位均可以通过Skywalking即可完成 增加业务指标监控的模式，能够自定义业务指标（目前官方已经在实现 Metric Exporter ）  ","excerpt":"APM和调用链跟踪 随着企业经营规模的扩大，以及对内快速诊断效率和对外SLA（服务品质协议，service-level agreement)的追求，对于业务系统的掌控度的要求越来越高，主要体现在：\n  …","ref":"/zh/2019-03-29-introduction-of-skywalking-and-simple-practice/","title":"SkyWalking调研与初步实践"},{"body":"前言 首先描述下问题的背景，博主有个习惯，每天上下班的时候看下skywalking的trace页面的error情况。但是某天突然发现生产环境skywalking页面没有任何数据了，页面也没有显示任何的异常，有点慌，我们线上虽然没有全面铺开对接skywalking，但是也有十多个应用。看了应用agent端日志后，其实也不用太担心，对应用毫无影响。大概情况就是这样，但是问题还是要解决，下面就开始排查skywalking不可用的问题。\n使用到的工具arthas Arthas是阿里巴巴开源的一款在线诊断java应用程序的工具，是greys工具的升级版本，深受开发者喜爱。当你遇到以下类似问题而束手无策时，Arthas可以帮助你解决：\n 这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？ 我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？ 遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？ 线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！ 是否有一个全局视角来查看系统的运行状况？ 有什么办法可以监控到JVM的实时运行状态？ Arthas采用命令行交互模式，同时提供丰富的 Tab 自动补全功能，进一步方便进行问题的定位和诊断。  项目地址：https://github.com/alibaba/arthas\n先定位问题一 查看skywalking-oap-server.log的日志，发现会有一条异常疯狂的在输出，异常详情如下：\n2019-03-01 09:12:11,578 - org.apache.skywalking.oap.server.core.register.worker.RegisterPersistentWorker -3264081149 [DataCarrier.IndicatorPersistentWorker.endpoint_inventory.Consumser.0.Thread] ERROR [] - Validation Failed: 1: id is too long, must be no longer than 512 bytes but was: 684; org.elasticsearch.action.ActionRequestValidationException: Validation Failed: 1: id is too long, must be no longer than 512 bytes but was: 684; at org.elasticsearch.action.ValidateActions.addValidationError(ValidateActions.java:26) ~[elasticsearch-6.3.2.jar:6.3.2] at org.elasticsearch.action.index.IndexRequest.validate(IndexRequest.java:183) ~[elasticsearch-6.3.2.jar:6.3.2] at org.elasticsearch.client.RestHighLevelClient.performRequest(RestHighLevelClient.java:515) ~[elasticsearch-rest-high-level-client-6.3.2.jar:6.3.2] at org.elasticsearch.client.RestHighLevelClient.performRequestAndParseEntity(RestHighLevelClient.java:508) ~[elasticsearch-rest-high-level-client-6.3.2.jar:6.3.2] at org.elasticsearch.client.RestHighLevelClient.index(RestHighLevelClient.java:348) ~[elasticsearch-rest-high-level-client-6.3.2.jar:6.3.2] at org.apache.skywalking.oap.server.library.client.elasticsearch.ElasticSearchClient.forceInsert(ElasticSearchClient.java:141) ~[library-client-6.0.0-alpha.jar:6.0.0-alpha] at org.apache.skywalking.oap.server.storage.plugin.elasticsearch.base.RegisterEsDAO.forceInsert(RegisterEsDAO.java:66) ~[storage-elasticsearch-plugin-6.0.0-alpha.jar:6.0.0-alpha] at org.apache.skywalking.oap.server.core.register.worker.RegisterPersistentWorker.lambda$onWork$0(RegisterPersistentWorker.java:83) ~[server-core-6.0.0-alpha.jar:6.0.0-alpha] at java.util.HashMap$Values.forEach(HashMap.java:981) [?:1.8.0_201] at org.apache.skywalking.oap.server.core.register.worker.RegisterPersistentWorker.onWork(RegisterPersistentWorker.java:74) [server-core-6.0.0-alpha.jar:6.0.0-alpha] at org.apache.skywalking.oap.server.core.register.worker.RegisterPersistentWorker.access$100(RegisterPersistentWorker.java:35) [server-core-6.0.0-alpha.jar:6.0.0-alpha] at org.apache.skywalking.oap.server.core.register.worker.RegisterPersistentWorker$PersistentConsumer.consume(RegisterPersistentWorker.java:120) [server-core-6.0.0-alpha.jar:6.0.0-alpha] at org.apache.skywalking.apm.commons.datacarrier.consumer.ConsumerThread.consume(ConsumerThread.java:101) [apm-datacarrier-6.0.0-alpha.jar:6.0.0-alpha] at org.apache.skywalking.apm.commons.datacarrier.consumer.ConsumerThread.run(ConsumerThread.java:68) [apm-datacarrier-6.0.0-alpha.jar:6.0.0-alpha] 2019-03-01 09:12:11,627 - org.apache.skywalking.oap.server.core.register.worker.RegisterPersistentWorker -3264081198 [DataCarrier.IndicatorPersistentWorker.endpoint_inventory.Consumser.0.Thread] ERROR [] - Validation Failed: 1: id is too long, must be no longer than 512 bytes but was: 684; org.elasticsearch.action.ActionRequestValidationException: Validation Failed: 1: id is too long, must be no longer than 512 bytes but was: 684; at org.elasticsearch.action.ValidateActions.addValidationError(ValidateActions.java:26) ~[elasticsearch-6.3.2.jar:6.3.2] at org.elasticsearch.action.index.IndexRequest.validate(IndexRequest.java:183) ~[elasticsearch-6.3.2.jar:6.3.2] at org.elasticsearch.client.RestHighLevelClient.performRequest(RestHighLevelClient.java:515) ~[elasticsearch-rest-high-level-client-6.3.2.jar:6.3.2] at org.elasticsearch.client.RestHighLevelClient.performRequestAndParseEntity(RestHighLevelClient.java:508) ~[elasticsearch-rest-high-level-client-6.3.2.jar:6.3.2] at org.elasticsearch.client.RestHighLevelClient.index(RestHighLevelClient.java:348) ~[elasticsearch-rest-high-level-client-6.3.2.jar:6.3.2] at org.apache.skywalking.oap.server.library.client.elasticsearch.ElasticSearchClient.forceInsert(ElasticSearchClient.java:141) ~[library-client-6.0.0-alpha.jar:6.0.0-alpha] at org.apache.skywalking.oap.server.storage.plugin.elasticsearch.base.RegisterEsDAO.forceInsert(RegisterEsDAO.java:66) ~[storage-elasticsearch-plugin-6.0.0-alpha.jar:6.0.0-alpha] at org.apache.skywalking.oap.server.core.register.worker.RegisterPersistentWorker.lambda$onWork$0(RegisterPersistentWorker.java:83) ~[server-core-6.0.0-alpha.jar:6.0.0-alpha] at java.util.HashMap$Values.forEach(HashMap.java:981) [?:1.8.0_201] at org.apache.skywalking.oap.server.core.register.worker.RegisterPersistentWorker.onWork(RegisterPersistentWorker.java:74) [server-core-6.0.0-alpha.jar:6.0.0-alpha] at org.apache.skywalking.oap.server.core.register.worker.RegisterPersistentWorker.access$100(RegisterPersistentWorker.java:35) [server-core-6.0.0-alpha.jar:6.0.0-alpha] at org.apache.skywalking.oap.server.core.register.worker.RegisterPersistentWorker$PersistentConsumer.consume(RegisterPersistentWorker.java:120) [server-core-6.0.0-alpha.jar:6.0.0-alpha] at org.apache.skywalking.apm.commons.datacarrier.consumer.ConsumerThread.consume(ConsumerThread.java:101) [apm-datacarrier-6.0.0-alpha.jar:6.0.0-alpha] at org.apache.skywalking.apm.commons.datacarrier.consumer.ConsumerThread.run(ConsumerThread.java:68) [apm-datacarrier-6.0.0-alpha.jar:6.0.0-alpha] 可以看到，上面的异常输出的时间节点，以这种频率在疯狂的刷新。通过异常message，得知到是因为skywalking在写elasticsearch时，索引的id太长了。下面是elasticsearch的源码：\nif (id != null \u0026amp;\u0026amp; id.getBytes(StandardCharsets.UTF_8).length \u0026gt; 512) { validationException = addValidationError(\u0026#34;id is too long, must be no longer than 512 bytes but was: \u0026#34; + id.getBytes(StandardCharsets.UTF_8).length, validationException); } 具体可见：elasticsearch/action/index/IndexRequest.java#L240\n问题一： 通过日志，初步定位是哪个系统的url太长，skywalking在注册url数据时触发elasticsearch针对索引id校验的异常，而skywalking注册失败后会不断的重试，所以才有了上面日志不断刷的现象。\n问题解决： elasticsearch client在写es前通过硬编码的方式写死了索引id的长度不能超过512字节大小。也就是我们不能通过从ES侧找解决方案了。回到异常的message，只能看到提示id太长，并没有写明id具体是什么，这个异常提示其实是不合格的，博主觉得应该把id的具体内容抛出来，问题就简单了。因为异常没有明确提示，系统又比较多，不能十多个系统依次关闭重启来验证到底是哪个系统的哪个url有问题。这个时候Arthas就派上用场了，在不重启应用不开启debug模式下，查看实例中的属性对象。下面通过Arthas找到具体的url。\n从异常中得知，org.elasticsearch.action.index.IndexRequest这个类的validate方法触发的，这个方法是没有入参的，校验的id属性其实是对象本身的属性，那么我们使用Arthas的watch指令来看下这个实例id属性。先介绍下watch的用法：\n功能说明 让你能方便的观察到指定方法的调用情况。能观察到的范围为：返回值、抛出异常、入参，通过编写 \u0008OGNL 表达式进行对应变量的查看。\n参数说明 watch 的参数比较多，主要是因为它能在 4 个不同的场景观察对象\n   参数名称 参数说明     class-pattern 类名表达式匹配   method-pattern 方法名表达式匹配   express 观察表达式   condition-express 条件表达式   [b] 在方法调用之前观察   [e] 在方法异常之后观察   [s] 在方法返回之后观察   [f] 在方法结束之后(正常返回和异常返回)观察   [E] 开启正则表达式匹配，默认为通配符匹配   [x:] 指定输出结果的属性遍历深度，默认为 1    从上面的用法说明结合异常信息，我们得到了如下的指令脚本：\nwatch org.elasticsearch.action.index.IndexRequest validate \u0026ldquo;target\u0026rdquo;\n执行后，就看到了我们希望了解到的内容，如：\n索引id的具体内容看到后，就好办了。我们暂时把定位到的这个应用启动脚本中的的skywalking agent移除后（计划后面重新设计下接口）重启了下系统验证下。果然疯狂输出的日志停住了，但是问题并没完全解决，skywalking页面上的数据还是没有恢复。\n定位问题二 skywalking数据存储使用了elasticsearch，页面没有数据，很有可能是elasticsearch出问题了。查看elasticsearch日志后，发现elasticsearch正在疯狂的GC，日志如：\n: 139939K-\u0026gt;3479K(153344K), 0.0285655 secs] 473293K-\u0026gt;336991K(5225856K), 0.0286918 secs] [Times: user=0.05 sys=0.00, real=0.03 secs] 2019-02-28T20:05:38.276+0800: 3216940.387: Total time for which application threads were stopped: 0.0301495 seconds, Stopping threads took: 0.0001549 seconds 2019-02-28T20:05:38.535+0800: 3216940.646: [GC (Allocation Failure) 2019-02-28T20:05:38.535+0800: 3216940.646: [ParNew Desired survivor size 8716288 bytes, new threshold 6 (max 6) - age 1: 1220136 bytes, 1220136 total - age 2: 158496 bytes, 1378632 total - age 3: 88200 bytes, 1466832 total - age 4: 46240 bytes, 1513072 total - age 5: 126584 bytes, 1639656 total - age 6: 159224 bytes, 1798880 total : 139799K-\u0026gt;3295K(153344K), 0.0261667 secs] 473311K-\u0026gt;336837K(5225856K), 0.0263158 secs] [Times: user=0.06 sys=0.00, real=0.03 secs] 2019-02-28T20:05:38.562+0800: 3216940.673: Total time for which application threads were stopped: 0.0276971 seconds, Stopping threads took: 0.0001030 seconds 2019-02-28T20:05:38.901+0800: 3216941.012: [GC (Allocation Failure) 2019-02-28T20:05:38.901+0800: 3216941.012: [ParNew Desired survivor size 8716288 bytes, new threshold 6 (max 6) 问题二： 查询后得知，elasticsearch的内存配置偏大了，GC时间太长，导致elasticsearch脱离服务了。elasticsearch所在主机的内存是8G的实际内存7.6G,刚开始配置了5G的堆内存大小，可能Full GC的时候耗时太久了。查询elasticsearch官方文档后，得到如下的jvm优化建议：\n 将最小堆大小（Xms）和最大堆大小（Xmx）设置为彼此相等。 Elasticsearch可用的堆越多，它可用于缓存的内存就越多。但请注意，过多的堆可能会使您陷入长时间的垃圾收集暂停。 设置Xmx为不超过物理RAM的50％，以确保有足够的物理RAM用于内核文件系统缓存。 不要设置Xmx为JVM用于压缩对象指针（压缩oops）的截止值之上; 确切的截止值变化但接近32 GB。  详情见：https://www.elastic.co/guide/en/elasticsearch/reference/6.5/heap-size.html\n问题解决： 根据Xmx不超过物理RAM的50％上面的jvm优化建议。后面将Xms和Xmx都设置成了3G。然后先停掉skywalking（由于skywalking中会缓存部分数据，如果直接先停ES，会报索引找不到的类似异常，这个大部分skywalking用户应该有遇到过），清空skywalking缓存目录下的内容，如：\n在重启elasticsearch，接着启动skywalking后页面终于恢复了\n结语 整个问题排查到解决大概花了半天时间，幸好一点也不影响线上应用的使用，这个要得益于skywalking的设计，不然就是大灾难了。然后要感谢下Arthas的技术团队，写了这么好用的一款产品并且开源了，如果没有Arthas，这个问题真的不好定位，甚至一度想到了换掉elasticsearch，采用mysql来解决索引id过长的问题。Arthas真的是线上找问题的利器，博主在Arthas刚面世的时候就关注了，并且一直在公司推广使用，在这里在硬推一波。\n作者简介： 陈凯玲，2016年5月加入凯京科技。曾任职高级研发和项目经理，现任凯京科技研发中心架构\u0026amp;运维部负责人。pmp项目管理认证，阿里云MVP。热爱开源，先后开源过多个热门项目。热爱分享技术点滴，独立博客KL博客（http://www.kailing.pub）博主。\n","excerpt":"前言 首先描述下问题的背景，博主有个习惯，每天上下班的时候看下skywalking的trace页面的error情况。但是某天突然发现生产环境skywalking页面没有任何数据了，页面也没有显示任何的 …","ref":"/zh/2019-03-01-skywalking-troubleshoot/","title":"SkyWalking线上问题排查定位"},{"body":" 作者：王振飞, 写于：2019-02-24 说明：此文是个人所写，版本归属作者，代表个人观点，仅供参考，不代表skywalking官方观点。 说明：本次对比基于skywalking-6.0.0-GA和Pinpoint-1.8.2（截止2019-02-19最新版本）。另外，我们这次技术选型直接否定了Zipkin，其最大原因是它对代码有侵入性，CAT也是一样。这是我们所完全无法接受的。\n 这应该是目前最优秀的两款开源APM产品了，而且两款产品都通过字节码注入的方式，实现了对代码完全无任何侵入，他们的对比信息如下：\nOAP说明: skywalking6.x才有OAP这个概念，skywalking5.x叫collector。\n接下来，对每个PK项进行深入分析和对比。更多精彩和首发内容请关注公众号：【阿飞的博客】。\n社区比较\n这一点上面skywalking肯定完胜。一方面，skywalking已经进入apache孵化，社区相当活跃。而且项目发起人是中国人，我们能够进入官方群（Apache SkyWalking交流群：392443393）和项目发起人吴晟零距离沟通，很多问题能第一时间得到大家的帮助（玩过开源的都知道，这个价值有多大）。 而Pinpoint是韩国人开发的，免不了有沟通障碍。至于github上最近一年的commit频率，skywalking和Pinpoint旗鼓相当，都是接近20的水平: 所以，社区方面，skywalking更胜一筹。\n支持语言比较 Pinpoint只支持Java和PHP，而skywalking支持5种语言：Java, C#, PHP, Node.js, Go。如果公司的服务涉及到多个开发语言，那么skywalking会是你更好的选择。并且，如果你要实现自己的探针（比如python语言），skywalking的二次开发成本也比Pinpoint更低。\n 说明：Github上有开发者为Pinpoint贡献了对Node.js的支持，请戳链接：https://github.com/peaksnail/pinpoint-node-agent。但是已经停止维护，几年没更新了！\n 所以，支持语言方面，skywalking更胜一筹。\n协议比较 SkyWalking支持gRPC和http，不过建议使用gRPC，skywalking6.x版本已经不提供http方式（但是还会保留接收5.x的数据），以后会考虑删除。 而Pinpoint使用的是thrift协议。 协议本身没有谁好谁坏。\n存储比较(重要) 笔者认为，存储是skywalking和Pinpoint最大的差异所在，因为底层存储决定了上层功能。\nPinpoint只支持HBase，且扩展代价较大。这就意味着，如果选择Pinpoint，还要有能力hold住一套HBase集群（daocloud从Pinpoint切换到skywalking就是因为HBase的维护代价有点大）。在这方面，skywalking支持的存储就多很多，这样的话，技术选型时可以根据团队技术特点选择合适的存储，而且还可以自行扩展（不过生产环境上应该大部分是以es存储为主）。\nPinpoint只支持HBase的另一个缺陷就是，HBase本身查询能力有限（HBase只能支持三种方式查询：RowKey精确查找，SCAN范围查找，全表扫描）限制了Pinpoint的查询能力，所以其支持的查询一定是在时间的基础上（Pinpoint通过鼠标圈定一个时间范围后查看这个范围内的Trace信息）。而skywalking可以多个维度任意组合查询，例如：时间范围，服务名，Trace状态，请求路径，TraceId等。\n另外，Pinpoint和skywalking都支持TTL，即历史数据保留策略。skywalking是在OAP模块的application.yml中配置从而指定保留时间。而Pinpoint是通过HBase的ttl功能实现，通过Pinpoint提供的hbase脚本https://github.com/naver/pinpoint/blob/master/hbase/scripts/hbase-create.hbase可以看到：ApplicationTraceIndex配置了TTL =\u0026gt; 5184000，SqlMetaData_Ver2配合了TTL =\u0026gt; 15552000，单位是秒。\n 说明：es并不是完全碾压HBase，es和HBase没有绝对的好和坏。es强在检索能力，存储能力偏弱(千亿以下，es还是完全有能力hold的住的)。HBase强在存储能力，检索能力偏弱。如果搜集的日志量非常庞大，那么es存储就比较吃力。当然，没有蹩脚的中间件，只有蹩脚的程序员，无论是es还是HBase，调优才是最关键的。同样的，如果对检索能力有一定的要求，那么HBase肯定满足不了你。所以，又到了根据你的业务和需求决定的时刻了，trade-off真是无所不在。\n UI比较 Pinpoint的UI确实比skywalking稍微好些，尤其是服务的拓扑图展示。不过daocloud根据Pinpoint的风格为skywalking定制了一款UI。请戳链接：https://github.com/TinyAllen/rocketbot，项目介绍是：rocketbot: A UI for Skywalking。截图如下所示； 所以，只比较原生UI的话，Pinpoint更胜一筹。\n扩展性比较 Pinpoint好像设计之初就没有过多考虑扩展性，无论是底层的存储，还是自定义探针实现等。而skywalking核心设计目标之一就是Pluggable，即可插拔。\n以存储为例，pinpoint完全没有考虑扩展性，而skywalking如果要自定义实现一套存储，只需要定义一个类实现接口org.apache.skywalking.oap.server.library.module.ModuleProvider，然后实现一些DAO即可。至于Pinpoint则完全没有考虑过扩展底层存储。\n再以实现一个自己的探针为例（比如我要实现python语言的探针），Pinpoint选择thrift作为数据传输协议标准，而且为了节省数据传输大小，在传递常量的时候也尽量使用数据参考字典，传递一个数字而不是直接传递字符串等等。这些优化也增加了系统的复杂度：包括使用 Thrift 接口的难度、UDP 数据传输的问题、以及数据常量字典的注册问题等等。Pinpoint发展这么年才支持Java和PHP，可见一斑。而skywalking的数据接口就标准很多，并且支持OpenTracing协议，除了官方支持Java以外，C#、PHP和Node.js的支持都是由社区开发并维护。\n还有后面会提到的告警，skywalking的可扩展性也要远好于Pinpoint。\n最后，Pinpoint和skywalking都支持插件开发，Pinpoint插件开发参考：http://naver.github.io/pinpoint/1.8.2/plugindevguide.html。skywalking插件开发参考：https://github.com/apache/incubator-skywalking/blob/master/docs/en/guides/Java-Plugin-Development-Guide.md。\n所以，扩展性方面skywalking更胜一筹。\n告警比较 Pinpoint和skywalking都支持自定义告警规则。\n但是恼人的是，Pinpoint如果要配置告警规则，还需要安装MySQL(配置告警时的用户，用户组信息以及告警规则都持久化保存在MySQL中)，这就导致Pinpoint的维护成本又高了一些，既要维护HBase又要维护MySQL。\nPinpoint支持的告警规则有：SLOW COUNT|RATE, ERROR COUNT|RATE, TOTAL COUNT, SLOW COUNT|RATE TO CALLEE, ERROR COUNT|RATE TO CALLEE, ERROR RATE TO CALLEE, HEAP USAGE RATE, JVM CPU USAGE RATE, DATASOURCE CONNECTION USAGE RATE。\nPinpoint每3分钟周期性检查过去5分钟的数据，如果有符合规则的告警，就会发送sms/email给用户组下的所有用户。需要说明的是，实现发送sms/email的逻辑需要自己实现，Pinpoint只提供了接口com.navercorp.pinpoint.web.alarm.AlarmMessageSender。并且Pinpoint发现告警持续时，会递增发送sms/email的时间间隔 3min -\u0026gt; 6min -\u0026gt; 12min -\u0026gt; 24min，防止sms/email狂刷。\n Pinpoint告警参考：http://naver.github.io/pinpoint/1.8.2/alarm.html\n skywalking配置告警不需要引入任何其他存储。skywalking在config/alarm-settings.xml中可以配置告警规则，告警规则支持自定义。\nskywalking支持的告警规则（配置项中的名称是indicator-name）有：service_resp_time, service_sla, service_cpm, service_p99, service_p95, service_p90, service_p75, service_p50, service_instance_sla, service_instance_resp_time, service_instance_cpm, endpoint_cpm, endpoint_avg, endpoint_sla, endpoint_p99, endpoint_p95, endpoint_p90, endpoint_p75, endpoint_p50。\nSkywalking通过HttpClient的方式远程调用在配置项webhooks中定义的告警通知服务地址。skywalking也支持silence-period配置，假设在TN这个时间点触发了告警，那么TN -\u0026gt; TN+period 这段时间内不会再重复发送该告警。\n skywalking告警参考：https://github.com/apache/incubator-skywalking/blob/master/docs/en/setup/backend/backend-alarm.md。目前只支持official_analysis.oal脚本中Service, Service Instance, Endpoint scope的metric，其他scope的metric需要等待后续扩展。\n Pinpoint和skywalking都支持常用的告警规则配置，但是skywalking采用webhooks的方式就灵活很多：短信通知，邮件通知，微信通知都是可以支持的。而Pinpoint只能sms/email通知，并且还需要引入MySQL存储，增加了整个系统复杂度。所以，告警方面，skywalking更胜一筹。\nJVM监控 skywalking支持监控：Heap, Non-Heap, GC(YGC和FGC)。 Pinpoint能够监控的指标主要有：Heap, Non-Heap, FGC, DirectBufferMemory, MappedBufferMemory，但是没有YGC。另外，Pinpoint还支持多个指标同一时间点查看的功能。如下图所示：\n所以，对JVM的监控方面，Pinpoint更胜一筹。\n服务监控 包括操作系统，和部署的服务实例的监控。 Pinpoint支持的维度有：CPU使用率，Open File Descriptor，数据源，活动线程数，RT，TPS。 skywalking支持的维度有：CPU使用率，SLA，RT，CPM（Call Per Minutes）。 所以，这方面两者旗鼓相当，没有明显的差距。\n跟踪粒度比较 Pinpoint在这方面做的非常好，跟踪粒度非常细。如下图所示，是Pinpoint对某个接口的trace信息： 而同一个接口skywalking的trace信息如下图所示：  备注: 此截图是skywalking加载了插件apm-spring-annotation-plugin-6.0.0-GA.jar（这个插件允许跟踪加了@Bean, @Service, @Component and @Repository注解的spring context中的bean的方法）。\n 通过对比发现，在跟踪粒度方面，Pinpoint更胜一筹。\n过滤追踪 Pinpoint和skywalking都可以实现，而且配置的表达式都是基于ant风格。 Pinpoint在Web UI上配置 filter wizard 即可自定义过滤追踪。 skywalking通过加载apm-trace-ignore-plugin插件就能自定义过滤跟踪，skywalking这种方式更灵活，比如一台高配服务器上有若干个服务，在共用的agent配置文件apm-trace-ignore-plugin.config中可以配置通用的过滤规则，然后通过-D的方式为每个服务配置个性化过滤。\n所以，在过滤追踪方面，skywalking更胜一筹。\n性能损耗 由于Pinpoint采集信息太过详细，所以，它对性能的损耗最大。而skywalking默认策略比较保守，对性能损耗很小。 有网友做过压力测试，对比如下：\n 图片来源于：https://juejin.im/post/5a7a9e0af265da4e914b46f1\n 所以，在性能损耗方面，skywalking更胜一筹。\n发布包比较 skywalking与时俱进，全系标配jar包，部署只需要执行start.sh脚本即可。而Pinpoint的collector和web还是war包，部署时依赖web容器（比如Tomcat）。拜托，都9012年了。\n所以，在发布包方面，skywalking更胜一筹。\n支持组件比较 skywalking和Pinpoint支持的中间件对比说明：\n WEB容器说明：Pinpoint支持几乎所有的WEB容器，包括开源和商业的。而wkywalking只支持开源的WEB容器，对2款大名鼎鼎的商业WEB容器Weblogic和Wevsphere都不支持。 RPC框架说明：对RPC框架的支持，skywalking简直秒杀Pinpoint。连小众的motan和sofarpc都支持。 MQ说明：skywalking比Pinpoint多支持一个国产的MQ中间件RocketMQ，毕竟RocketMQ在国内名气大，而在国外就一般了。加之skywalking也是国产的。 RDBMS/NoSQL说明：Pinpoint对RDBMS和NoSQL的支持都要略好于skywalking，RDBMS方面，skywalking不支持MSSQL和MariaDB。而NoSQL方面，skywalking不支持Cassandra和HBase。至于Pinpoint不支持的H2，完全不是问题，毕竟生产环境是肯定不会使用H2作为底层存储的。 Redis客户端说明：虽然skywalking和Pinpoint都支持Redis，但是skywalking支持三种流行的Redis客户端：Jedis，Redisson，Lettuce。而Pinpoint只支持Jedis和Lettuce，再一次，韩国人开发的Pinpoint无视了目前中国人开发的GitHub上star最多的Redis Client \u0026ndash; Redisson。 日志框架说明：Pinpoint居然不支持log4j2？但是已经有人开发了相关功能，详情请戳链接：log4j plugin support log4j2 or not? https://github.com/naver/pinpoint/issues/3055  通过对skywalking和Pinpoint支持中间件的对比我们发现，skywalking对国产软件的支持真的是全方位秒杀Pinpoint，比如小众化的RPC框架：motan（微博出品），sofarpc，阿里的RocketMQ，Redis客户端Redisson，以及分布式任务调度框架elastic-job等。当然也从另一方面反应国产开源软件在世界上的影响力还很小。\n这方面没有谁好谁坏，毕竟每个公司使用的技术栈不一样。如果你对RocketMQ有强需求，那么skywalking是你的最佳选择。如果你对es有强需求，那么skywalking也是你的最佳选择。如果HBase是你的强需求，那么Pinpoint就是你的最佳选择。如果MSSQL是你的强需求，那么Pinpoint也是你的最佳选择。总之，这里完全取决你的项目了。\n总结 经过前面对skywalking和Pinpoint全方位对比后我们发现，对于两款非常优秀的APM软件，有一种既生瑜何生亮的感觉。Pinpoint的优势在于：追踪数据粒度非常细、功能强大的用户界面，以及使用HBase作为存储带来的海量存储能力。而skywalking的优势在于：非常活跃的中文社区，支持多种语言的探针，对国产开源软件非常全面的支持，以及使用es作为底层存储带来的强大的检索能力，并且skywalking的扩展性以及定制化要更优于Pinpoint：\n 如果你有海量的日志存储需求，推荐Pinpoint。 如果你更看重二次开发的便捷性，推荐skywalking。  最后，参考上面的对比，结合你的需求，哪些不能妥协，哪些可以舍弃，从而更好的选择一款最适合你的APM软件。\n参考链接  参考[1]. https://github.com/apache/incubator-skywalking/blob/master/docs/en/setup/service-agent/java-agent/Supported-list.md 参考[2]. http://naver.github.io/pinpoint/1.8.2/main.html#supported-modules 参考[3]. https://juejin.im/post/5a7a9e0af265da4e914b46f1    如果觉得本文不错，请关注作者公众号：【阿飞的博客】，多谢！\n ","excerpt":"作者：王振飞, 写于：2019-02-24 说明：此文是个人所写，版本归属作者，代表个人观点，仅供参考，不代表skywalking官方观点。 说明：本次对比基于skywalking-6.0.0-GA …","ref":"/zh/2019-02-24-skywalking-pk-pinpoint/","title":"APM巅峰对决：SkyWalking P.K. Pinpoint"},{"body":"According to Apache Software Foundation branding policy all docker images of Apache Skywalking should be transferred from skywalking to apache with a prefix skywalking-. The transfer details are as follows\n skywalking/base -\u0026gt; apache/skywalking-base skywalking/oap -\u0026gt; apache/skywalking-oap-server skywalking/ui -\u0026gt; apache/skywalking-ui  All of repositories in skywalking will be removed after one week.\n","excerpt":"According to Apache Software Foundation branding policy all docker images of Apache Skywalking …","ref":"/events/transfer-docker-images-to-apache-official-repository/","title":"Transfer Docker Images to Apache Official Repository"},{"body":"6.0.0-GA release. Go to downloads page to find release tars. This is an important milestone version, we recommend all users upgrade to this version.\nKey updates\n Bug fixed Register bug fix, refactor and performance improvement New trace UI  ","excerpt":"6.0.0-GA release. Go to downloads page to find release tars. This is an important milestone version, …","ref":"/events/release-apache-skywalking-apm-6-0-0-ga/","title":"Release Apache SkyWalking APM 6.0.0-GA"},{"body":"Based on his contributions to the project, he has been accepted as SkyWalking PPMC. Welcome aboard.\n","excerpt":"Based on his contributions to the project, he has been accepted as SkyWalking PPMC. Welcome aboard.","ref":"/events/welcome-jian-tan-as-a-new-ppmc/","title":"Welcome Jian Tan as a new PPMC"},{"body":"","excerpt":"","ref":"/tags/performance/","title":"Performance"},{"body":" Author: Hongtao Gao, Apache SkyWalking \u0026amp; ShardingShpere PMC GitHub, Twitter, Linkedin  Service mesh receiver was first introduced in Apache SkyWalking 6.0.0-beta. It is designed to provide a common entrance for receiving telemetry data from service mesh framework, for instance, Istio, Linkerd, Envoy etc. What’s the service mesh? According to Istio’s explain:\nThe term service mesh is used to describe the network of microservices that make up such applications and the interactions between them.\nAs a PMC member of Apache SkyWalking, I tested trace receiver and well understood the performance of collectors in trace scenario. I also would like to figure out the performance of service mesh receiver.\nDifferent between trace and service mesh Following chart presents a typical trace map:\nYou could find a variety of elements in it just like web service, local method, database, cache, MQ and so on. But service mesh only collect service network telemetry data that contains the entrance and exit data of a service for now(more elements will be imported soon, just like Database). A smaller quantity of data is sent to the service mesh receiver than the trace.\nBut using sidecar is a little different.The client requesting “A” that will send a segment to service mesh receiver from “A”’s sidecar. If “A” depends on “B”, another segment will be sent from “A”’s sidecar. But for a trace system, only one segment is received by the collector. The sidecar model splits one segment into small segments, that will increase service mesh receiver network overhead.\nDeployment Architecture In this test, I will pick two different backend deployment. One is called mini unit, consist of one collector and one elasticsearch instance. Another is a standard production cluster, contains three collectors and three elasticsearch instances.\nMini unit is a suitable architecture for dev or test environment. It saves your time and VM resources, speeds up depolyment process.\nThe standard cluster provides good performance and HA for a production scenario. Though you will pay more money and take care of the cluster carefully, the reliability of the cluster will be a good reward to you.\nI pick 8 CPU and 16GB VM to set up the test environment. This test targets the performance of normal usage scenarios, so that choice is reasonable. The cluster is built on Google Kubernetes Engine(GKE), and every node links each other with a VPC network. For running collector is a CPU intensive task, the resource request of collector deployment should be 8 CPU, which means every collector instance occupy a VM node.\nTesting Process Receiving mesh fragments per second(MPS) depends on the following variables.\n Ingress query per second(QPS) The topology of a microservice cluster Service mesh mode(proxy or sidecar)  In this test, I use Bookinfo app as a demo cluster.\nSo every request will touch max 4 nodes. Plus picking the sidecar mode(every request will send two telemetry data), the MPS will be QPS * 4 *2.\nThere are also some important metrics that should be explained\n Client Query Latency: GraphQL API query response time heatmap. Client Mesh Sender: Send mesh segments per second. The total line represents total send amount and the error line is the total number of failed send. Mesh telemetry latency: service mesh receiver handling data heatmap. Mesh telemetry received: received mesh telemetry data per second.  Mini Unit You could find collector can process up to 25k data per second. The CPU usage is about 4 cores. Most of the query latency is less than 50ms. After login the VM on which collector instance running, I know that system load is reaching the limit(max is 8).\nAccording to the previous formula, a single collector instance could process 3k QPS of Bookinfo traffic.\nStandard Cluster Compare to the mini-unit, cluster’s throughput increases linearly. Three instances provide total 80k per second processing power. Query latency increases slightly, but it’s also very small(less than 500ms). I also checked every collector instance system load that all reached the limit. 10k QPS of BookInfo telemetry data could be processed by the cluster.\nConclusion Let’s wrap them up. There are some important things you could get from this test.\n QPS varies by the there variables. The test results in this blog are not important. The user should pick property value according to his system. Collector cluster’s processing power could scale out. The collector is CPU intensive application. So you should provide sufficient CPU resource to it.  This blog gives people a common method to evaluate the throughput of Service Mesh Receiver. Users could use this to design their Apache Skywalking backend deployment architecture.\n","excerpt":"Author: Hongtao Gao, Apache SkyWalking \u0026amp; ShardingShpere PMC GitHub, Twitter, Linkedin  Service …","ref":"/blog/2019-01-25-mesh-loadtest/","title":"SkyWalking performance in Service Mesh scenario"},{"body":"","excerpt":"","ref":"/zh_tags/development/","title":"Development"},{"body":"ps:本文仅写给菜鸟，以及不知道如何远程调试的程序员，并且仅仅适用skywalking的远程调试\n概述 远程调试的目的是为了解决代码或者说程序包部署在服务器上运行，只能通过log来查看问题，以及不能跟在本地IDE运行debug那样查找问题，观看程序运行流程\u0026hellip; 想想当你的程序运行在服务器上，你在本地的IDE随时debug，是不是很爽的感觉。\n好了不废话，切入正题。\n环境篇 IDE：推荐 IntelliJ IDEA\n开发语言: 本文仅限于java，其他语言请自行询问google爸爸或者baidu娘娘\n源代码：自行从github下载，并且确保你运行的skywalking包也源代码的一致，（也就是说你自己从源代码编译打包运行，虽然不一样也可以调试，但是你想想你在本地开发，更改完代码，没有重新运行，debug出现的诡异情况）\n场景篇 假定有如下三台机器\n   IP 用途 备注     10.193.78.1 oap-server skywalking 的oap服务（或者说collector所在的服务器）   10.193.78.2 agent skywalking agent运行所在的服务器   10.193.78.0 IDE 你自己装IDE也就是IntelliJ IDEA的机器    以上环境，场景请自行安装好，并确认正常运行。本文不在赘述\n废话终于说完了\n操作篇 首要条件，下载源码后，先用maven 打包编译。然后使用Idea打开源码的父目录，整体结构大致如下图 1 :agent调试 1)Idea 配置部分 点击Edit Configurations 在弹出窗口中依次找到（红色线框的部分）并点击 打开的界面如下 修改Name值，自己随意，好记即可 然后Host输入10.193.78.2 Port默认或者其他的，重要的是这个端口在10.193.78.2上没有被占用\n然后找到Use module classpath 选择 apm-agent 最终的结果如下： 注意选择目标agent运行的jdk版本，很重要\n然后点击Apply，并找到如下内容，并且复制待用 2）agent配置部分 找到agent配置的脚本，并打开，找到配置agent的地方， 就这个地方，在这个后边加上刚才复制的内容 最终的结果如下 提供一个我配置的weblogic的配置（仅供参考） 然后重启应用（agent）\n3）调试 回到Idea中找到这个地方，并点击debug按钮，你没看错，就是红色圈住的地方 然后控制台如果出现以下字样： 那么恭喜你，可以愉快的加断点调试了。 ps:需要注意的是agent的、 service instance的注册可能不能那么愉快的调试。因为这个注册比较快，而且是在agent启动的时候就发生的， 而远程调试也需要agent打开后才可以调试，所以，如果你手快当我没说这句话。\n2 :oap-server的调试（也就是collector的调试） 具体过程不在赘述，和上一步的agent调试大同小异，不同的是 Use module classpath需要选择oap-server\n","excerpt":"ps:本文仅写给菜鸟，以及不知道如何远程调试的程序员，并且仅仅适用skywalking的远程调试\n概述 远程调试的目的是为了解决代码或者说程序包部署在服务器上运行，只能通过log来查看问题，以及不能跟 …","ref":"/zh/2019-01-24-skywalking-remote-debug/","title":"SkyWalking的远程调试"},{"body":"引言 《SkyWalking Java 插件贡献实践》：本文将基于SkyWalking 6.0.0-GA-SNAPSHOT版本，以编写Redis客户端Lettuce的SkyWalking Java Agent 插件为例，与大家分享我贡献PR的过程，希望对大家了解SkyWalking Java Agent插件有所帮助。\n基础概念 OpenTracing和SkyWalking链路模块几个很重要的语义概念。\n  Span:可理解为一次方法调用，一个程序块的调用，或一次RPC/数据库访问。只要是一个具有完整时间周期的程序访问，都可以被认为是一个span。SkyWalking Span对象中的重要属性\n   属性 名称 备注     component 组件 插件的组件名称，如：Lettuce，详见:ComponentsDefine.Class。   tag 标签 k-v结构，关键标签，key详见：Tags.Class。   peer 对端资源 用于拓扑图，若DB组件，需记录集群信息。   operationName 操作名称 若span=0，operationName将会搜索的下拉列表。   layer 显示 在链路页显示，详见SpanLayer.Class。      Trace:调用链，通过归属于其的Span来隐性的定义。一条Trace可被认为是一个由多个Span组成的有向无环图（DAG图），在SkyWalking链路模块你可以看到，Trace又由多个归属于其的trace segment组成。\n  Trace segment:Segment是SkyWalking中的一个概念，它应该包括单个OS进程中每个请求的所有范围，通常是基于语言的单线程。由多个归属于本线程操作的Span组成。\n  核心API 跨进程ContextCarrier核心API  为了实现分布式跟踪，需要绑定跨进程的跟踪，并且应该传播上下文 整个过程。 这就是ContextCarrier的职责。 以下是实现有关跨进程传播的步骤：  在客户端，创建一个新的空的ContextCarrier，将ContextCarrier所有信息放到HTTP heads、Dubbo attachments 或者Kafka messages。 通过服务调用，将ContextCarrier传递到服务端。 在服务端，在对应组件的heads、attachments或messages获取ContextCarrier所有消息。将服务端和客户端的链路信息绑定。    跨线程ContextSnapshot核心API  除了跨进程，跨线程也是需要支持的，例如异步线程（内存中的消息队列）和批处理在Java中很常见，跨进程和跨线程十分相似，因为都是需要传播 上下文。 唯一的区别是，不需要跨线程序列化。 以下是实现有关跨线程传播的步骤：  使用ContextManager＃capture获取ContextSnapshot对象。 让子线程以任何方式，通过方法参数或由现有参数携带来访问ContextSnapshot。 在子线程中使用ContextManager#continued。    详尽的核心API相关知识，可点击阅读 《插件开发指南-中文版本》\n插件实践 Lettuce操作redis代码 @PostMapping(\u0026#34;/ping\u0026#34;) public String ping(HttpServletRequest request) throws ExecutionException, InterruptedException { RedisClient redisClient = RedisClient.create(\u0026#34;redis://\u0026#34; + \u0026#34;127.0.0.1\u0026#34; + \u0026#34;:6379\u0026#34;); StatefulRedisConnection\u0026lt;String, String\u0026gt; connection0 = redisClient.connect(); RedisAsyncCommands\u0026lt;String, String\u0026gt; asyncCommands0 = connection0.async(); AsyncCommand\u0026lt;String, String, String\u0026gt; future = (AsyncCommand\u0026lt;String, String, String\u0026gt;)asyncCommands0.set(\u0026#34;key_a\u0026#34;, \u0026#34;value_a\u0026#34;); future.onComplete(s -\u0026gt; OkHttpClient.call(\u0026#34;http://skywalking.apache.org\u0026#34;)); future.get(); connection0.close(); redisClient.shutdown(); return \u0026#34;pong\u0026#34;; } 插件源码架构 Lettuce对Redis封装与Redisson Redisson 类似，目的均是实现简单易用，且无学习曲线的Java的Redis客户端。所以要是先对Redis操作的拦截，需要学习对应客户端的源码。\n设计插件 理解插件实现过程，找到最佳InterceptPoint位置是实现插件融入SkyWalking的核心所在。\n代码实现 PR的url：Support lettuce plugin\n实践中遇到的问题  多线程编程使用debug断点会将链路变成同步，建议使用run模式增加log，或者远程debug来解决。 多线程编程，需要使用跨线程ContextSnapshot核心API，否则链路会断裂。 CompleteableCommand.onComplete方法有时会同步执行，这个和内部机制有关，有时候不分离线程。 插件编译版本若为1.7+，需要将插件放到可选插件中。因为sniffer支持的版本是1.6。  插件兼容 为了插件得到插件最终的兼容兼容版本，我们需要使用docker对所有插件版本的测试，具体步骤如下：\n 编写测试用例：关于如何编写测试用例，请按照如何编写文档来实现。 提供自动测试用例。 如：Redisson插件testcase 确保本地几个流行的插件版本，在本地运行起来是和自己的预期是一致的。 在提供自动测试用例并在CI中递交测试后，插件提交者会批准您的插件。 最终得到完整的插件测试报告。  Pull Request 提交PR 提交PR的时候，需要简述自己对插件的设计，这样有助于与社区的贡献者讨论完成codereview。\n申请自动化测试 测试用例编写完成后，可以申请自动化测试，在自己的PR中会生成插件兼容版本的报告。\n插件文档 插件文档需要更新：Supported-list.md相关插件信息的支持。\n插件如果为可选插件需要在agent-optional-plugins可选插件文档中增加对应的描述。\n注释 Lettuce是一个完全无阻塞的Redis客户端，使用netty构建，提供反应，异步和同步数据访问。了解细节可点击阅读 lettuce.io;\nOpenTracing是一个跨编程语言的标准，了解细节可点击阅读 《OpenTracing语义标准》;\nspan:org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan接口定义了所有Span实现需要完成的方法;\nRedisson是一个非常易用Java的Redis客户端， 它没有学习曲线，无需知道任何Redis命令即可开始使用它。了解细节可点击阅读 redisson.org;\n","excerpt":"引言 《SkyWalking Java 插件贡献实践》：本文将基于SkyWalking 6.0.0-GA-SNAPSHOT版本，以编写Redis客户端Lettuce的SkyWalking Java …","ref":"/zh/2019-01-21-agent-plugin-practice/","title":"SkyWalking Java 插件贡献实践"},{"body":"Jinlin Fu has contributed 4 new plugins, including gson, activemq, rabbitmq and canal, which made SkyWalking supporting all mainstream OSS MQ. Also provide several documents and bug fixes. The SkyWalking PPMC based on these, promote him as new committer. Welcome on board.\n","excerpt":"Jinlin Fu has contributed 4 new plugins, including gson, activemq, rabbitmq and canal, which made …","ref":"/events/welcome-jinlin-fu-as-new-committer/","title":"Welcome Jinlin Fu as new committer"},{"body":" 作者：赵瑞栋 原文地址  引言 微服务框架落地后，分布式部署架构带来的问题就会迅速凸显出来。服务之间的相互调用过程中，如果业务出现错误或者异常，如何快速定位问题？如何跟踪业务调用链路？如何分析解决业务瓶颈？\u0026hellip;本文我们来看看如何解决以上问题。\n一、SkyWalking初探 Skywalking 简介 Skywalking是一款国内开源的应用性能监控工具，支持对分布式系统的监控、跟踪和诊断。\n它提供了如下的主要功能特性： Skywalking 技术架构 SW总体可以分为四部分：\n1.Skywalking Agent：使用Javaagent做字节码植入，无侵入式的收集，并通过HTTP或者gRPC方式发送数据到Skywalking Collector。\nSkywalking Collector ：链路数据收集器，对agent传过来的数据进行整合分析处理并落入相关的数据存储中。 Storage：Skywalking的存储，时间更迭，sw已经开发迭代到了6.x版本，在6.x版本中支持以ElasticSearch、Mysql、TiDB、H2、作为存储介质进行数据存储。 UI ：Web可视化平台，用来展示落地的数据。  Skywalking Agent配置 通过了解配置，可以对一个组件功能有一个大致的了解。让我们一起看一下skywalking的相关配置。\n解压开skywalking的压缩包，在agent/config文件夹中可以看到agent的配置文件。\n从skywalking支持环境变量配置加载，在启动的时候优先读取环境变量中的相关配置。\n agent.namespace: 跨进程链路中的header，不同的namespace会导致跨进程的链路中断 agent.service_name:一个服务（项目）的唯一标识，这个字段决定了在sw的UI上的关于service的展示名称 agent.sample_n_per_3_secs: 客户端采样率，默认是-1代表全采样 agent.authentication: 与collector进行通信的安全认证，需要同collector中配置相同 agent.ignore_suffix: 忽略特定请求后缀的trace collecttor.backend_service: agent需要同collector进行数据传输的IP和端口 logging.level: agent记录日志级别  skywalking agent使用javaagent无侵入式的配合collector实现对分布式系统的追踪和相关数据的上下文传递。\nSkywalking Collector关键配置 Collector支持集群部署，zookeeper、kubernetes（如果你的应用是部署在容器中的）、consul（GO语言开发的服务发现工具）是sw可选的集群管理工具，结合大家具体的部署方式进行选择。详细配置大家可以去Skywalking官网下载介质包进行了解。\nCollector端口设置\n downsampling: 采样汇总统计维度，会分别按照分钟、【小时、天、月】（可选）来统计各项指标数据。 通过设置TTL相关配置项可以对数据进行自动清理。  Skywalking 在6.X中简化了配置。collector提供了gRPC和HTTP两种通信方式。\nUI使用rest http通信，agent在大多数场景下使用grpc方式通信，在语言不支持的情况下会使用http通信。\n关于绑定IP和端口需要注意的一点是，通过绑定IP，agent和collector必须配置对应ip才可以正常通信。\nCollector存储配置\n在application.yml中配置的storage模块配置中选择要使用的数据库类型，并填写相关的配置信息。\nCollector Receiver\nReceiver是Skywalking在6.x提出的新的概念，负责从被监控的系统中接受指标数据。用户完全可以参照OpenTracing规范来上传自定义的监控数据。Skywalking官方提供了service-mesh、istio、zipkin的相关能力。\n现在Skywalking支持服务端采样，配置项为sampleRate，比例采样，如果配置为5000则采样率就是50%。\n关于采样设置的一点注意事项\n关于服务采样配置的一点建议，如果Collector以集群方式部署，比如：Acollector和Bcollector，建议Acollector.sampleRate = Bcollector.sampleRate。如果采样率设置不相同可能会出现数据丢失问题。\n假设Agent端将所有数据发送到后端Collector处，A采样率设置为30%，B采样率为50%。\n假设有30%的数据，发送到A上，这些数据被全部正确接受并存储，极端情况（与期望的采样数据量相同）下，如果剩下20%待采样的数据发送到了B，这个时候一切都是正常的，如果这20%中有一部分数据被送到了A那么，这些数据将是被忽略的，由此就会造成数据丢失。\n二、业务调用链路监控 Service Topology监控 调用链路监控可以从两个角度去看待。我们先从整体上来认识一下我们所监控的系统。\n通过给服务添加探针并产生实际的调用之后，我们可以通过Skywalking的前端UI查看服务之间的调用关系。\n我们简单模拟一次服务之间的调用。新建两个服务，service-provider以及service-consumer，服务之间简单的通过Feign Client 来模拟远程调用。\n从图中可以看到:\n 有两个服务节点：provider \u0026amp; consumer 有一个数据库节点：localhost【mysql】 一个注册中心节点  consumer消费了provider提供出来的接口。\n一个系统的拓扑图让我们清晰的认识到系统之间的应用的依赖关系以及当前状态下的业务流转流程。细心的可能发现图示节点consumer上有一部分是红色的，红色是什么意思呢？\n红色代表当前流经consumer节点的请求有一断时间内是响应异常的。当节点全部变红的时候证明服务现阶段内就彻底不可用了。运维人员可以通过Topology迅速发现某一个服务潜在的问题，并进行下一步的排查并做到预防。\nSkywalking Trace监控 Skywalking通过业务调用监控进行依赖分析，提供给我们了服务之间的服务调用拓扑关系、以及针对每个endpoint的trace记录。\n我们在之前看到consumer节点服务中发生了错误，让我们一起来定位下错误是发生在了什么地方又是什么原因呢？\n在每一条trace的信息中都可以看到当前请求的时间、GloableId、以及请求被调用的时间。我们分别看一看正确的调用和异常的调用。\nTrace调用链路监控 图示展示的是一次正常的响应，这条响应总耗时19ms，它有4个span：\n span1 /getStore = 19ms 响应的总流转时间 span2 /demo2/stores = 14ms feign client 开始调用远程服务后的响应的总时间 span3 /stores = 14ms 接口服务响应总时间 span4 Mysql = 1ms 服务提供端查询数据库的时间  这里span2和span3的时间表现相同，其实是不同的，因为这里时间取了整。\n在每个Span中可以查看当前Span的相关属性。\n 组件类型: SpringMVC、Feign Span状态: false HttpMethod: GET Url: http://192.168.16.125:10002/demo2/stores  这是一次正常的请求调用Trace日志，可能我们并不关心正常的时候，毕竟一切正常不就是我们期待的么！\n我们再来看下，异常状态下我们的Trace以及Span又是什么样的呢。\n发生错误的调用链中Span中的is error标识变为true，并且在名为Logs的TAB中可以看到错误发生的具体原因。根据异常情况我们就可以轻松定位到影响业务的具体原因，从而快速定位问题，解决问题。\n通过Log我们看到连接被拒，那么可能是我们的网络出现了问题（可能性小，因为实际情况如果网络出现问题我们连这个trace都看不到了），也有可能是服务端配置问题无法正确建立连接。通过异常日志，我们迅速就找到了问题的关键。\n实际情况是，我把服务方停掉了，做了一次简单的模拟。可见，通过拓扑图示我们可以清晰的看到众多服务中哪个服务是出现了问题的，通过trace日志我们可以很快就定位到问题所在，在最短的时间内解决问题。\n三、服务性能指标监控 Skywalking还可以查看具体Service的性能指标，根据相关的性能指标可以分析系统的瓶颈所在并提出优化方案。\nSkywalking 性能监控 在服务调用拓扑图上点击相应的节点我们可以看到该服务的\n SLA: 服务可用性（主要是通过请求成功与失败次数来计算） CPM: 每分钟调用次数 Avg Response Time: 平均响应时间  从应用整体外部来看我们可以监测到应用在一定时间段内的\n 服务可用性指标SLA 每分钟平均响应数 平均响应时间 服务进程PID 服务所在物理机的IP、HostName、Operation System  Service JVM信息监控 还可以监控到Service运行时的CPU、堆内存、非堆内存使用率、以及GC情况。这些信息来源于JVM。注意这里的数据可不是机器本身的数据。\n四、服务告警 前文我们提到了通过查看拓扑图以及调用链路可以定位问题，可是运维人员又不可能一直盯着这些数据，那么我们就需要告警能力，在异常达到一定阈值的时候主动的提示我们去查看系统状态。\n在Sywalking 6.x版本中新增了对服务状态的告警能力。它通过webhook的方式让我们可以自定义我们告警信息的通知方式。诸如:邮件通知、微信通知、短信通知等。\nSkywalking 服务告警 先来看一下告警的规则配置。在alarm-settings.xml中可以配置告警规则，告警规则支持自定义。\n一份告警配置由以下几部分组成：\n service_resp_time_rule：告警规则名称 ***_rule （规则名称可以自定义但是必须以’_rule’结尾 indicator-name：指标数据名称： 定义参见http://t.cn/EGhfbmd op: 操作符： \u0026gt; , \u0026lt; , = 【当然你可以自己扩展开发其他的操作符】 threshold：目标值：指标数据的目标数据 如sample中的1000就是服务响应时间，配合上操作符就是大于1000ms的服务响应 period: 告警检查周期：多久检查一次当前的指标数据是否符合告警规则 counts: 达到告警阈值的次数 silence-period：忽略相同告警信息的周期 message：告警信息 webhooks：服务告警通知服务地址  Skywalking通过HttpClient的方式远程调用在配置项webhooks中定义的告警通知服务地址。\n了解了SW所传送的数据格式我们就可以对告警信息进行接收处理，实现我们需要的告警通知服务啦！\n我们将一个服务停掉，并将另外一个服务的某个对外暴露的接口让他休眠一定的时间。然后调用一定的次数观察服务的状态信息以及告警情况。\n总结 本文简单的通过skwaylking的配置来对skywlaking的功能进行一次初步的了解，对skwaylking新提出的概念以及新功能进行简单的诠释，方便大家了解和使用。通过使用APM工具，可以让我们方便的查看微服务架构中系统瓶颈以及性能问题等。\n精选提问 问1：想问问选型的时候用pinpoint还是SK好？\n答：选型问题\n 要结合具体的业务场景， 比如你的代码运行环境 是java、php、net还是什么。 pinpoint在安装部署上要比skywalking略微复杂 pinpoint和sw支持的组件列表是不同的。 https://github.com/apache/incubator-skywalking/blob/master/docs/en/setup/service-agent/java-agent/Supported-list.md你可以参照这里的支持列表对比下pinpoint的支持对象做一个简单对比。 sw经过测试在并发量较高的情况下比pinpoint的吞吐量更好一些。  问2：有没有指标统计，比如某个url 的top10 请求、响应最慢的10个请求？某个服务在整个链条中的耗时占比？\n答：1.sw自带有响应最慢的请求top10统计针对所有的endpoint的统计。 2.针对每个url的top10统计，sw本身没有做统计，数据都是现成的通过简单的检索就可以搜到你想要的结果。 3.没有具体的耗时占比，但是有具体总链路时间统计以及某个服务的耗时统计，至于占比自己算吧，可以看ppt中的调用链路监控的span时间解释。\n问3：能不能具体说一下在你们系统中的应用？\n答：EOS8LA版本中，我们整合sw对应用提供拓扑、调用链路、性能指标的监控、并在sw数据的基础上增加系统的维度。 当服务数很庞大的时候，整体的拓扑其实就是一张密密麻麻的蜘蛛网。我们可以通过系统来选择具体某个系统下的应用。 8LA中SW是5.0.0alpha版本，受限于sw功能，我们并没有提供告警能力，这在之后会是我们的考虑目标。\n问4：业务访问日志大概每天100G，kubernetes 环境中部署，使用稳定吗？\n答：监控数据没有长时间的存储必要，除非你有特定的需求。它有一定的时效性，你可以设置ttl自动清除过时信息。100g，es集群还是能轻松支撑的。\n问5：和pinpoint相比有什么优势吗？\n答：\n 部署方式、使用方式简单 功能特性支持的更多 高并发性能会更好一些  问6：skywalking的侵入式追踪功能方便进行单服务链的服务追踪。但是跨多台服务器多项目的整体服务链追踪是否有整体设计考虑？\n答：sw本身特性就是对分布式系统的追踪，他是无侵入式的。无关你的应用部署在多少台服务器上。\n问7：应用在加上代理之后性能会下降。请问您有什么解决方法吗？\n答：性能下降是在所难免的，但是据我了解，以及官方的测试，他的性能影响是很低的。这是sw的测试数据供你参考。 https://skywalkingtest.github.io/Agent-Benchmarks/README_zh.html。\n问8：有异构系统需求的话可以用sw吗？\n答：只要skywalking的探针支持的应该都是可以的。\n问9：sw对于商用的web中间件，如bes、tongweb、websphere、weblogic的支持如何？\n答：商业组件支持的比较少，因为涉及到相关license的问题，sw项目组需要获得他们的支持来进行数据上报，据我了解，支持不是很好。\n","excerpt":"作者：赵瑞栋 原文地址  引言 微服务框架落地后，分布式部署架构带来的问题就会迅速凸显出来。服务之间的相互调用过程中，如果业务出现错误或者异常，如何快速定位问题？如何跟踪业务调用链路？如何分析解决业务 …","ref":"/zh/2019-01-03-monitor-microservice/","title":"SkyWalking 微服务监控分析"},{"body":"","excerpt":"","ref":"/zh_tags/elasticsearch/","title":"ElasticSearch"},{"body":"SkyWalking 依赖 elasticsearch 集群，如果 elasticsearch 安装有 x-pack 插件的话，那么就会存在一个 Basic 认证，导致 skywalking 无法调用 elasticsearch, 解决方法是使用 nginx 做代理，让 nginx 来做这个 Basic 认证，那么这个问题就自然解决了。\n方法如下:\n 安装 nginx   yum install -y nginx\n 配置 nginx  server { listen 9200 default_server; server_name _; location / { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://localhost:9200; #Basic字符串就是使用你的用户名(admin),密码(12345)编码后的值 #注意:在进行Basic加密的时候要使用如下格式如:admin:123456 注意中间有个冒号 proxy_set_header Authorization \u0026#34;Basic YWRtaW4gMTIzNDU2\u0026#34;; } } 验证   curl localhost:9200\n { \u0026#34;name\u0026#34; : \u0026#34;Yd0rCp9\u0026#34;, \u0026#34;cluster_name\u0026#34; : \u0026#34;es-cn-4590xv9md0009doky\u0026#34;, \u0026#34;cluster_uuid\u0026#34; : \u0026#34;jAPLrqY5R6KWWgHnGCWOAA\u0026#34;, \u0026#34;version\u0026#34; : { \u0026#34;number\u0026#34; : \u0026#34;6.3.2\u0026#34;, \u0026#34;build_flavor\u0026#34; : \u0026#34;default\u0026#34;, \u0026#34;build_type\u0026#34; : \u0026#34;tar\u0026#34;, \u0026#34;build_hash\u0026#34; : \u0026#34;053779d\u0026#34;, \u0026#34;build_date\u0026#34; : \u0026#34;2018-07-20T05:20:23.451332Z\u0026#34;, \u0026#34;build_snapshot\u0026#34; : false, \u0026#34;lucene_version\u0026#34; : \u0026#34;7.3.1\u0026#34;, \u0026#34;minimum_wire_compatibility_version\u0026#34; : \u0026#34;5.6.0\u0026#34;, \u0026#34;minimum_index_compatibility_version\u0026#34; : \u0026#34;5.0.0\u0026#34; }, \u0026#34;tagline\u0026#34; : \u0026#34;You Know, for Search\u0026#34; } 看到如上结果那么恭喜你成功了。\n","excerpt":"SkyWalking 依赖 elasticsearch 集群，如果 elasticsearch 安装有 x-pack 插件的话，那么就会存在一个 Basic 认证，导致 skywalking …","ref":"/zh/2019-01-02-skywalking-elasticsearch-basic/","title":"关于 ElastiSsearch 因 basic 认证导致 SkyWalking 无法正常调用接口问题"},{"body":" 作者: Wu Sheng, tetrate, SkyWalking original creator GitHub, Twitter, Linkedin 翻译: jjlu521016  背景 在当前的微服务架构中分布式链路追踪是很有必要的一部分，但是对于一些用户来说如何去理解和使用分布式链路追踪的相关数据是不清楚的。 这个博客概述了典型的分布式跟踪用例，以及Skywalking的V6版本中新的可视化功能。我们希望新的用户通过这些示例来更好的理解。\n指标和拓扑图 跟踪数据支持两个众所周知的分析特性：指标和拓扑图\n指标: 每个service, service instance, endpoint的指标都是从跟踪中的入口span派生的。指标代表响应时间的性能。所以可以有一个平均响应时间，99%的响应时间，成功率等。它们按service, service instance, endpoint进行分解。\n拓扑图: 拓扑表示服务之间的链接，是分布式跟踪最有吸引力的特性。拓扑结构允许所有用户理解分布式服务关系和依赖关系，即使它们是不同的或复杂的。这一点很重要，因为它为所有相关方提供了一个单一的视图，无论他们是开发人员、设计者还是操作者。\n这里有一个拓扑图的例子包含了4个项目，包括kafka和两个外部依赖。\n-在skywalking的可选择UI0RocketBot的拓扑图-\nTrace 在分布式链路追踪系统中，我们花费大量资源（CPU、内存、磁盘和网络）来生成、传输和持久跟踪数据。让我们试着回答为什么要这样做？我们可以用跟踪数据回答哪些典型的诊断和系统性能问题？\nSkywalking v6包含两种追踪视图:\n   TreeMode: 第一次提供,帮助您更容易识别问题。    ListMode: 常规的时间线视图，通常也出现在其他跟踪系统中，如Zipkin。    发生错误 在trace视图，最简单的部分是定位错误，可能是由代码异常或网络故障引起的。通过span详情提供的细节，ListMode和TreeMode都能够找到错误 -ListMode 错误span-\n-TreeMode 错误span-\n慢span 一个高优先级的特性是识别跟踪中最慢的span。这将使用应用程序代理捕获的执行持续时间。在旧的ListMode跟踪视图中，由于嵌套，父span几乎总是包括子span的持续时间。换句话说，一个缓慢的span通常会导致它的父节点也变慢，在Skywalking 6中，我们提供了 最慢的前5个span 过滤器来帮助你您直接定位span。\n-最慢的前5个span-\n太多子span 在某些情况下，个别持续时间很快，但跟踪速度仍然很慢，如： -没有慢span的追踪-\n如果要了解根问题是否与太多操作相关，请使用子范围号的Top 5 of children span number,筛选器显示每个span的子级数量，突出显示前5个。 -13个数据库访问相关的span-\n在这个截图中，有一个包含13个子项的span，这些子项都是数据库访问。另外，当您看到跟踪的概述时，这个2000ms跟踪的数据库花费了1380ms。 -1380ms花费在数据库访问-\n在本例中，根本原因是数据库访问太多。这在其他场景中也很常见，比如太多的RPC或缓存访问。\n链路深度 跟踪深度也与延迟有关。像太多子span的场景一样，每个span延迟看起来不错，但整个链路追踪的过程很慢。 -链路深度-\n上图所示,最慢的span小鱼500ms,对于2000毫秒的跟踪来说，速度并不太慢。当您看到第一行时，有四种不同的颜色表示这个分布式跟踪中涉及的四个services。每一个都需要100~400ms，这四个都需要近2000ms，从这里我们知道这个缓慢的跟踪是由一个序列中的3个RPC造成的。\n结束语 分布式链路追踪和APM 工具帮助我们确定造成问题的根源，允许开发和操作团队进行相应的优化。我们希望您喜欢这一点，并且喜欢Apache Skywalking和我们的新链路追踪可视化界面。如果你喜欢的话，在github上面给我们加start来鼓励我们\nSkywakling 6计划在2019年的1月底完成release。您可以通过以下渠道联系项目团队成员\n 关注 skywalking推特 订阅邮件:dev@skywalking.apache.org。发送邮件到 dev-subscribe@kywalking.apache.org 来订阅. 加入Gitter聊天室  ","excerpt":"作者: Wu Sheng, tetrate, SkyWalking original creator GitHub, Twitter, Linkedin 翻译: jjlu521016  背景 在当前的 …","ref":"/zh/2019-01-02-understand-trace-trans2cn/","title":"更容易理解将要到来的分布式链路追踪 6.0GA (翻译)"},{"body":"Background Distributed tracing is a necessary part of modern microservices architecture, but how to understand or use distributed tracing data is unclear to some end users. This blog overviews typical distributed tracing use cases with new visualization features in SkyWalking v6. We hope new users will understand more through these examples.\nMetric and topology Trace data underpins in two well known analysis features: metric and topology\nMetric of each service, service instance, endpoint are derived from entry spans in trace. Metrics represent response time performance. So, you could have average response time, 99% response time, success rate, etc. These are broken down by service, service instance, endpoint.\nTopology represents links between services and is distributed tracing\u0026rsquo;s most attractive feature. Topologies allows all users to understand distributed service relationships and dependencies even when they are varied or complex. This is important as it brings a single view to all interested parties, regardless of if they are a developer, designer or operator.\nHere\u0026rsquo;s an example topology of 4 projects, including Kafka and two outside dependencies.\nTopology in SkyWalking optional UI, RocketBot\nTrace In a distributed tracing system, we spend a lot of resources(CPU, Memory, Disk and Network) to generate, transport and persistent trace data. Let\u0026rsquo;s try to answer why we do this? What are the typical diagnosis and system performance questions we can answer with trace data?\nSkyWalking v6 includes two trace views:\n TreeMode: The first time provided. Help you easier to identify issues. ListMode: Traditional view in time line, also usually seen in other tracing system, such as Zipkin.  Error occurred In the trace view, the easiest part is locating the error, possibly caused by a code exception or network fault. Both ListMode and TreeMode can identify errors, while the span detail screen provides details.\nListMode error span\nTreeMode error span\nSlow span A high priority feature is identifying the slowest spans in a trace. This uses execution duration captured by application agents. In the old ListMode trace view, parent span almost always includes the child span\u0026rsquo;s duration, due to nesting. In other words, a slow span usually causes its parent to also become slow. In SkyWalking 6, we provide Top 5 of slow span filter to help you locate the spans directly.\nTop 5 slow span\nThe above screenshot highlights the top 5 slow spans, excluding child span duration. Also, this shows all spans\u0026rsquo; execution time, which helps identify the slowest ones.\nToo many child spans In some cases, individual durations are quick, but the trace is still slow, like this one:\nTrace with no slow span\nTo understand if the root problem is related to too many operations, use Top 5 of children span number. This filter shows the amount of children each span has, highlighting the top 5.\n13 database accesses of a span\nIn this screenshot, there is a span with 13 children, which are all Database accesses. Also, when you see overview of trace, database cost 1380ms of this 2000ms trace.\n1380ms database accesses\nIn this example, the root cause is too many database accesses. This is also typical in other scenarios like too many RPCs or cache accesses.\nTrace depth Trace depth is also related latency. Like the too many child spans scenario, each span latency looks good, but the whole trace is slow.\nTrace depth\nHere, the slowest spans are less than 500ms, which are not too slow for a 2000ms trace. When you see the first line, there are four different colors representing four services involved in this distributed trace. Every one of them costs 100~400ms. For all four, there nearly 2000ms. From here, we know this slow trace is caused by 3 RPCs in a serial sequence.\nAt the end Distributed tracing and APM tools help users identify root causes, allowing development and operation teams to optimize accordingly. We hope you enjoyed this, and love Apache SkyWalking and our new trace visualization. If so, give us a star on GitHub to encourage us.\nSkyWalking 6 is scheduled to release at the end of January 2019. You can contact the project team through the following channels:\n Follow SkyWalking twitter Subscribe mailing list: dev@skywalking.apache.org . Send to dev-subscribe@kywalking.apache.org to subscribe the mail list. Join Gitter room.  ","excerpt":"Background Distributed tracing is a necessary part of modern microservices architecture, but how to …","ref":"/blog/2019-01-01-understand-trace/","title":"Understand distributed trace easier in the incoming 6-GA"},{"body":"6.0.0-beta release. Go to downloads page to find release tars.\nKey updates\n Bugs fixed, closed to GA New protocols provided, old still compatible. Spring 5 supported MySQL and TiDB as optional storage  ","excerpt":"6.0.0-beta release. Go to downloads page to find release tars.\nKey updates\n Bugs fixed, closed to GA …","ref":"/events/release-apache-skywalking-apm-6-0-0-beta/","title":"Release Apache SkyWalking APM 6.0.0-beta"},{"body":"Based on his contributions. Including created RocketBot as our secondary UI, new website and very cool trace view page in next release. he has been accepted as SkyWalking PPMC. Welcome aboard.\n","excerpt":"Based on his contributions. Including created RocketBot as our secondary UI, new website and very …","ref":"/events/welcome-yao-wang-as-a-new-ppmc/","title":"Welcome Yao Wang as a new PPMC"},{"body":"导读  SkyWalking 中 Java 探针是使用 JavaAgent 的两大字节码操作工具之一的 Byte Buddy（另外是 Javassist）实现的。项目还包含.Net core 和 Nodejs 自动探针，以及 Service Mesh Istio 的监控。总体上，SkyWalking 是一个多语言，多场景的适配，特别为微服务、云原生和基于容器架构设计的可观测性分析平台（Observability Analysis Platform）。 本文基于 SkyWalking 5.0.0-RC2 和 Byte Buddy 1.7.9 版本，会从以下几个章节，让大家掌握 SkyWalking Java 探针的使用，进而让 SkyWalking 在自己公司中的二次开发变得触手可及。  Byte Buddy 实现 JavaAgent 项目 迭代 JavaAgent 项目的方法论 SkyWalking agent 项目如何 Debug SkyWalking 插件开发实践   文章底部有 SkyWalking 和 Byte Buddy 相应的学习资源。  Byte Buddy 实现  首先如果你对 JavaAgent 还不是很了解可以先百度一下，或在公众号内看下《JavaAgent 原理与实践》简单入门下。 SpringMVC 分发请求的关键方法相信已经不用我在赘述了，那我们来编写 Byte Buddy JavaAgent 代码吧。  public class AgentMain { public static void premain(String agentOps, Instrumentation instrumentation) { new AgentBuilder.Default() .type(ElementMatchers.named(\u0026#34;org.springframework.web.servlet.DispatcherServlet\u0026#34;)) .transform((builder, type, classLoader, module) -\u0026gt; builder.method(ElementMatchers.named(\u0026#34;doDispatch\u0026#34;)) .intercept(MethodDelegation.to(DoDispatchInterceptor.class))) .installOn(instrumentation); } }  编写 DispatcherServlet doDispatch 拦截器代码（是不是跟 AOP 如出一辙）  public class DoDispatchInterceptor { @RuntimeType public static Object intercept(@Argument(0) HttpServletRequest request, @SuperCall Callable\u0026lt;?\u0026gt; callable) { final StringBuilder in = new StringBuilder(); if (request.getParameterMap() != null \u0026amp;\u0026amp; request.getParameterMap().size() \u0026gt; 0) { request.getParameterMap().keySet().forEach(key -\u0026gt; in.append(\u0026#34;key=\u0026#34; + key + \u0026#34;_value=\u0026#34; + request.getParameter(key) + \u0026#34;,\u0026#34;)); } long agentStart = System.currentTimeMillis(); try { return callable.call(); } catch (Exception e) { System.out.println(\u0026#34;Exception :\u0026#34; + e.getMessage()); return null; } finally { System.out.println(\u0026#34;path:\u0026#34; + request.getRequestURI() + \u0026#34; 入参:\u0026#34; + in + \u0026#34; 耗时:\u0026#34; + (System.currentTimeMillis() - agentStart)); } } }  resources/META-INF/MANIFEST.MF  Manifest-Version: 1.0 Premain-Class: com.z.test.agent.AgentMain Can-Redefine-Classes: true  pom.xml 文件  dependencies +net.bytebuddy.byte-buddy +javax.servlet.javax.servlet-api *scope=provided plugins +maven-jar-plugin *manifestFile=src/main/resources/META-INF/MANIFEST.MF +maven-shade-plugin *include:net.bytebuddy:byte-buddy:jar: +maven-compiler-plugin  小结：没几十行代码就完成了，通过 Byte Buddy 实现应用组件 SpringMVC 记录请求路径、入参、执行时间 JavaAgent 项目，是不是觉得自己很优秀。  持续迭代 JavaAgent  本章节主要介绍 JavaAgent 如何 Debug，以及持续集成的方法论。 首先我的 JavaAgent 项目目录结构如图所示: 应用项目是用几行代码实现的 SpringBootWeb 项目:  @SpringBootApplication(scanBasePackages = {\u0026#34;com\u0026#34;}) public class TestBootWeb { public static void main(String[] args) { SpringApplication.run(TestBootWeb.class, args); } @RestController public class ApiController { @PostMapping(\u0026#34;/ping\u0026#34;) public String ping(HttpServletRequest request) { return \u0026#34;pong\u0026#34;; } } }  下面是关键 JavaAgent 项目如何持续迭代与集成:  VM options增加:-JavaAgent:{$HOME}/Code/github/z_my_test/test-agent/target/test-agent-1.0-SNAPSHOT.jar=args Before launch 在Build之前增加： Working directory:{$HOME}/Code/github/incubator-skywalking Command line:-T 1C -pl test-agent -am clean package -Denforcer.skip=true -Dmaven.test.skip=true -Dmaven.compile.fork=true  小结：看到这里的将 JavaAgent 持续迭代集成方法，是不是瞬间觉得自己手心已经发痒起来，很想编写一个自己的 agent 项目了呢，等等还有一个好消息:test-demo 这 10 几行的代码实现的 Web 服务，居然有 5k 左右的类可以使用 agent 增强。 注意 mvn 编译加速的命令是 maven3 + 版本以上才支持的哈。  SkyWalking Debug  峰回路转，到了文章的主题《SkyWalking 之高级用法》的正文啦。首先，JavaAgent 项目想 Debug，还需要将 agent 代码与接入 agent 项目至少在同一个工作空间内，网上方法有很多，这里我推荐大家一个最简单的方法。File-\u0026gt;New-\u0026gt;Module from Exisiting Sources… 引入 skywalking-agent 源码即可 详细的 idea 编辑器配置： 优化 SkyWalking agent 编译时间，我的集成时间优化到 30 秒左右：  VM options增加:-JavaAgent:-JavaAgent:{$HOME}/Code/github/incubator-skywalking/skywalking-agent/skywalking-agent.jar：不要用dist里面的skywalking-agent.jar，具体原因大家可以看看源码：apm-sniffer/apm-agent/pom.xml中的maven插件的使用。 Before launch 在Build之前增加： Working directory:{$HOME}/Code/github/incubator-skywalking Command line:-T 1C -pl apm-sniffer/apm-sdk-plugin -amd clean package -Denforcer.skip=true -Dmaven.test.skip=true -Dmaven.compile.fork=true： 这里我针对插件包，因为紧接着下文要开发插件 另外根pom注释maven-checkstyle-plugin也可加速编译 kob 之 SkyWalking 插件编写  kob（贝壳分布式作业调度框架）是贝壳找房项目微服务集群中的基础组件，通过编写贝壳分布式作业调度框架的 SkyWalking 插件，可以实时收集作业调度任务的执行链路信息，从而及时得到基础组件的稳定性，了解细节可点击阅读《贝壳分布式调度框架简介》。想详细了解 SkyWalking 插件编写可在文章底部参考链接中，跳转至对应的官方资源，好话不多说，代码一把唆起来。 apm-sdk-plugin pom.xml 增加自己的插件 model  \u0026lt;artifactId\u0026gt;apm-sdk-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;modules\u0026gt; \u0026lt;module\u0026gt;kob-plugin\u0026lt;/module\u0026gt; ... \u0026lt;modules\u0026gt;  resources.skywalking-plugin.def 增加自己的描述  kob=org.apache.skywalking.apm.plugin.kob.KobInstrumentation  在 SkyWalking 的项目中，通过继承 ClassInstanceMethodsEnhancePluginDefine 可以定义需要拦截的类和增强的方法，编写作业调度方法的 instrumentation  public class KobInstrumentation extends ClassInstanceMethodsEnhancePluginDefine { private static final String ENHANCE_CLASS = \u0026#34;com.ke.kob.client.spring.core.TaskDispatcher\u0026#34;; private static final String INTERCEPT_CLASS = \u0026#34;org.apache.skywalking.apm.plugin.kob.KobInterceptor\u0026#34;; @Override protected ClassMatch enhanceClass() { return NameMatch.byName(ENHANCE_CLASS); } @Override protected ConstructorInterceptPoint[] getConstructorsInterceptPoints() { return null; } @Override protected InstanceMethodsInterceptPoint[] getInstanceMethodsInterceptPoints() { return new InstanceMethodsInterceptPoint[] { new InstanceMethodsInterceptPoint() { @Override public ElementMatcher\u0026lt;MethodDescription\u0026gt; getMethodsMatcher() { return named(\u0026#34;dispatcher1\u0026#34;); } @Override public String getMethodsInterceptor() { return INTERCEPT_CLASS; } @Override public boolean isOverrideArgs() { return false; } } }; } }  通过实现 InstanceMethodsAroundInterceptor 后，定义 beforeMethod、afterMethod 和 handleMethodException 的实现方法，可以环绕增强指定目标方法，下面自定义 interceptor 实现 span 的跟踪（这里需要注意 SkyWalking 中 span 的生命周期，在 afterMethod 方法中结束 span）  public class KobInterceptor implements InstanceMethodsAroundInterceptor { @Override public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class\u0026lt;?\u0026gt;[] argumentsTypes, MethodInterceptResult result) throws Throwable { final ContextCarrier contextCarrier = new ContextCarrier(); com.ke.kob.client.spring.model.TaskContext context = (TaskContext) allArguments[0]; CarrierItem next = contextCarrier.items(); while (next.hasNext()) { next = next.next(); next.setHeadValue(JSON.toJSONString(context.getUserParam())); } AbstractSpan span = ContextManager.createEntrySpan(\u0026#34;client:\u0026#34;+allArguments[1]+\u0026#34;,task:\u0026#34;+context.getTaskKey(), contextCarrier); span.setComponent(ComponentsDefine.TRANSPORT_CLIENT); SpanLayer.asRPCFramework(span); } @Override public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class\u0026lt;?\u0026gt;[] argumentsTypes, Object ret) throws Throwable { ContextManager.stopSpan(); return ret; } @Override public void handleMethodException(EnhancedInstance objInst, Method method, Object[] allArguments, Class\u0026lt;?\u0026gt;[] argumentsTypes, Throwable t) { } }  实现效果，将操作名改成任务执行节点 + 任务执行方法，实现 kob 的 SkyWalking 的插件编写，加上报警体系，可以进一步增加公司基础组件的稳定性。  参考链接  Apache SkyWalking Byte Buddy（runtime code generation for the Java virtual machine）  ","excerpt":"导读  SkyWalking 中 Java 探针是使用 JavaAgent 的两大字节码操作工具之一的 Byte Buddy（另外是 Javassist）实现的。项目还包含.Net core …","ref":"/zh/2018-12-21-skywalking-apm-sniffer-beginning/","title":"SkyWalking apm-sniffer 原理学习与插件编写"},{"body":"搭建调试环境 阅读 SkyWalking 源码，从配置调试环境开始。\n一定一定一定不要干读代码，而是通过调试的方式。\n 01 通过 Skywalking-5.x 版本的源码构建并运行 👉：哔哩哔哩 | 腾讯视频 02 通过 Skywalking-6.x 版本的源码构建并运行 👉：哔哩哔哩 | 腾讯视频 03 Java 应用（探针）接入 Skywalking[6.x] 👉：哔哩哔哩 | 腾讯视频  SkyWalking 3.X 源码解析合集 虽然是基于 3.X 版本的源码解析，但是对于阅读 SkyWalking Java Agent 和插件部分，同样适用。\n对于 SkyWalking Collector 部分，可以作为一定的参考。\n 《SkyWalking 源码分析 —— 调试环境搭建》 《SkyWalking 源码分析 —— Agent 初始化》 《SkyWalking 源码分析 —— Agent 插件体系》 《SkyWalking 源码分析 —— Collector 初始化》 《SkyWalking 源码分析 —— Collector Cluster 集群管理》 《SkyWalking 源码分析 —— Collector Client Component 客户端组件》 《SkyWalking 源码分析 —— Collector Server Component 服务器组件》 《SkyWalking 源码分析 —— Collector Jetty Server Manager》 《SkyWalking 源码分析 —— Collector gRPC Server Manager》 《SkyWalking 源码分析 —— Collector Naming Server 命名服务》 《SkyWalking 源码分析 —— Collector Queue 队列组件》 《SkyWalking 源码分析 —— Collector Storage 存储组件》 《SkyWalking 源码分析 —— Collector Streaming Computing 流式处理（一）》 《SkyWalking 源码分析 —— Collector Streaming Computing 流式处理（二）》 《SkyWalking 源码分析 —— Collector Cache 缓存组件》 《SkyWalking 源码分析 —— Collector Remote 远程通信服务》 《SkyWalking 源码分析 —— DataCarrier 异步处理库》 《SkyWalking 源码分析 —— Agent Remote 远程通信服务》 《SkyWalking 源码分析 —— 应用于应用实例的注册》 《SkyWalking 源码分析 —— Agent DictionaryManager 字典管理》 《SkyWalking 源码分析 —— Agent 收集 Trace 数据》 《SkyWalking 源码分析 —— Agent 发送 Trace 数据》 《SkyWalking 源码分析 —— Collector 接收 Trace 数据》 《SkyWalking 源码分析 —— Collector 存储 Trace 数据》 《SkyWalking 源码分析 —— JVM 指标的收集与存储》 《SkyWalking 源码分析 —— 运维界面（一）之应用视角》 《SkyWalking 源码分析 —— 运维界面（二）之应用实例视角》 《SkyWalking 源码分析 —— 运维界面（三）之链路追踪视角》 《SkyWalking 源码分析 —— 运维界面（四）之操作视角》 《SkyWalking 源码分析 —— @Trace 注解想要追踪的任何方法》 《SkyWalking 源码分析 —— traceId 集成到日志组件》 《SkyWalking 源码分析 —— Agent 插件（一）之 Tomcat》 《SkyWalking 源码分析 —— Agent 插件（二）之 Dubbo》 《SkyWalking 源码分析 —— Agent 插件（三）之 SpringMVC》 《SkyWalking 源码分析 —— Agent 插件（四）之 MongoDB》  SkyWalking 6.X 源码解析合集  《SkyWalking 6.x 源码分析 —— 调试环境搭建》  ","excerpt":"搭建调试环境 阅读 SkyWalking 源码，从配置调试环境开始。\n一定一定一定不要干读代码，而是通过调试的方式。\n 01 通过 Skywalking-5.x 版本的源码构建并运行 👉：哔哩哔哩 | …","ref":"/zh/2018-12-21-skywalking-source-code-read/","title":"SkyWalking 源码解析合集"},{"body":"","excerpt":"","ref":"/zh_tags/source-code/","title":"Source Code"},{"body":"版本选择 我们采用的是 5.0.0-RC2 的版本，SkyWalking 的版本信息可以参考 https://github.com/apache/incubator-skywalking/blob/5.x/CHANGES.md\n那么为什么我们没有采用 5.1.0 版本呢，这是因为我们公司内部需要支持 es x-pack，但是在官方发布里面，没有支持 xpack 的版本。\n在 Apache SkyWalking 官方文档 https://github.com/CharlesMaster/incubator-skywalking/tree/master/docs/others/cn 中有提到，SkyWalking 5.x 仍受社区支持。\n对于用户计划从 5.x 升级到 6.x，您应该知道关于有一些概念的定义的变更。最重要的两个改变了的概念是：\n Application（在 5.x 中）更改为 Service（在 6.x 中），Application Instance 也更改为 Service Instance。 Service（在 5.x 中）更改为 Endpoint（在 6.x 中）。  图文详解 Apache SkyWalking 的监控界面由 Monitor 和 Trace 两者构成，Monitor 菜单又包括 Dashbord、Topology、Application、Service、Alarm 五个子菜单构成。本文就是围绕这些菜单分别逐一进行介绍。\nMonitor 当用户通过 SkyWalking 登陆界面使用用户名、密码登陆以后，就会默认进入到 SkyWalking 的 Monitor 下的 Dashboard 界面\nDashboard 下图就是用户登陆之后都会看到的关键 Dashboard 页面，在这个页面的下方的关键指标，图中都做了详细的解释。\n上图中 app 需要强调的是，52 个 app 并不代表 52 个应用，比如 paycenter 有两台 paycenter1 和 paycenter2 就算了 2 个 app，当然还有一些应用是 3 个以上的。在我们公司，paycenter1、paycenter2 这些运维都和我们跳板机管理平台上的名称设置的一样，约定大于配置，开发人员可以更加便捷的排查问题。\n 再次修正一下，关于 dashboard 页面的 app 数，语言类探针，是探针的 app_code 来决定的。比如我们公司的线上配置就是 agent.application_code=auth-center-1\n 上图中需要解释两个概念：\n cpm 代表每分钟请求次数 SLA=(TRANSACTION_CALLS- TRANSACTION_ERROR_CALLS ) * 10000 ) / TRANSACTION_CALLS  该页面主要支持四个跳转：\n一、在上图中，App 板块上的帮助选项是可以直接跳转到 Application 监控页面的。 二、 Service 板块上的帮助选项是可以直接跳转到 Service 监控页面的。\n三、 Slow Service 列表中的每一个慢服务点击以后都会进入到其专项的 Service 监控页面。\n四、 Application Throughput 列表中的每一个 Application 点击以后也都是可以进入到其专项的 Application 监控页面。\n 关于 Application 和 Service 的详细介绍我们后续会展开\n 在 Dashboard 的页面上部分，还有一个选择功能模块： 左侧部分可以定期 refresh Dashboard 的数据，右侧则可以调整整体的查询区间。\nTopology 点击 Monitor 菜单下的 Topology 你会看到下面这张拓扑图\n当然这张图太过于夸张了，如果接入 SkyWalking 的应用并不是很多，会如下图所示： 左侧的三个小按钮可以调整你的视图，支持拖拽。右侧可以输入你所关心的应用名。比如我们输入一个支付和订单两个应用，左侧的拓扑图会变得更加清晰：\n另外，上图中的绿色圆圈都是可以点击的，如果你点击以后，还会出现节点信息： Application 点击 Monitor 菜单下的 Application 你会看到下面这张图，这张图里你可以看到的东西都做了注解。\n这张图里有一个惊喜，就是如果你点开 More Server Details，你可以看到更多的信息\n是的，除了 Host、IPv4、Pid、OS 以外，你还可以看到 CPU、Heap、Non-Heap、GC（Young GC、Old GC）等详细监控信息。\nService 点击 Monitor 菜单下的 Service 你会看到下面这张图，这张图里你可以看到的同样都做了注解。 关于 Dependency Map 这张图我们再补充一下，鼠标悬停可以看到每个阶段的执行时间，这是 Service 下的功能 我们点开图中该图中 Top 20 Slow Traces 下面的被我马赛克掉的 trace 的按钮框，可以看到如下更加详细的信息：\n这些信息可以帮助我们知道每一个方法在哪个阶段那个具体实现耗时了多久。\n如上图所示，每一行基本都是可以打开的，每一行都包含了 Tags、Logs 等监控内容\nAlarm 点击 Monitor 菜单下的 Alarm 你会看到告警菜单。目前 5.X 版本的还没有接入邮件、短信等告警方式，后续 6 支持 webhook，用户可以自己去接短信和邮件。\n告警内容中你可以看到 Applicaion、Server 和 Service 三个层面的告警内容\nTrace Trace 是一个非常实用的功能，用户可以根据精确的 TraceId 去查找\n也可以设定时间段去查找\n我在写使用手册时候，非常巧的是，看到了上图三起异常，于是我们往下拉列表看到了具体的数据\n点击进去，我们可以看到具体的失败原因 当然用户也可以直接将 Trace State 调整为 Error 级别进行查询\n再回顾一遍 一、首先我们进入首页：\n二、点击一下首页的 Slow Service 的 projectC，可以看到如下信息：\n三、如果点击首页的 Appliation Throughput 中的 projectD，可以看到如下信息：\n四、继续点进去右下角的这个 slow service 里的 Consumer，我们可以看到下图：\n参考资料  https://twitter.com/AsfSkyWalking/status/1013616673218179072 https://twitter.com/AsfSkyWalking/status/1013617100143800320  ","excerpt":"版本选择 我们采用的是 5.0.0-RC2 的版本，SkyWalking …","ref":"/zh/2018-12-18-apache-skywalking-5-0-userguide/","title":"Apache SkyWalking 5.0 中文版图文详解使用手册"},{"body":"","excerpt":"","ref":"/zh_tags/web-ui/","title":"Web UI"},{"body":"Based on his contributions to the project, he has been accepted as SkyWalking committer. Welcome aboard.\n","excerpt":"Based on his contributions to the project, he has been accepted as SkyWalking committer. Welcome …","ref":"/events/welcome-yixiong-cao-as-a-new-committer/","title":"Welcome Yixiong Cao as a new committer"},{"body":"Original link, Tetrate.io blog\nContext The integration of SkyWalking and Istio Service Mesh yields an essential open-source tool for resolving the chaos created by the proliferation of siloed, cloud-based services.\nApache SkyWalking is an open, modern performance management tool for distributed services, designed especially for microservices, cloud native and container-based (Docker, K8s, Mesos) architectures. We at Tetrate believe it is going to be an important project for understanding the performance of microservices. The recently released v6 integrates with Istio Service Mesh and focuses on metrics and tracing. It natively understands the most common language runtimes (Java, .Net, and NodeJS). With its new core code, SkyWalking v6 also supports Istrio telemetry data formats, providing consistent analysis, persistence, and visualization.\nSkyWalking has evolved into an Observability Analysis Platform that enables observation and monitoring of hundreds of services all at once. It promises solutions for some of the trickiest problems faced by system administrators using complex arrays of abundant services: Identifying why and where a request is slow, distinguishing normal from deviant system performance, comparing apples-to-apples metrics across apps regardless of programming language, and attaining a complete and meaningful view of performance.\nSkyWalking History Launched in China by Wu Sheng in 2015, SkyWalking started as just a distributed tracing system, like Zipkin, but with auto instrumentation from a Java agent. This enabled JVM users to see distributed traces without any change to their source code. In the last two years, it has been used for research and production by more than 50 companies. With its expanded capabilities, we expect to see it adopted more globally.\nWhat\u0026rsquo;s new Service Mesh Integration Istio has picked up a lot of steam as the framework of choice for distributed services. Based on all the interest in the Istio project, and community feedback, some SkyWalking (P)PMC members decided to integrate with Istio Service Mesh to move SkyWalking to a higher level.\nSo now you can use Skywalking to get metrics and understand the topology of your applications. This works not just for Java, .NET and Node using our language agents, but also for microservices running under the Istio service mesh. You can get a full topology of both kinds of applications.\nObservability analysis platform With its roots in tracing, SkyWalking is now transitioning into an open-standards based Observability Analysis Platform, which means the following:\n It can accept different kinds and formats of telemetry data from mesh like Istio telemetry. Its agents support various popular software technologies and frameworks like Tomcat, Spring, Kafka. The whole supported framework list is here. It can accept data from other compliant sources like Zipkin-formatted traces reported from Zipkin, Jaeger, or OpenCensus clients.  SkyWalking is logically split into four parts: Probes, Platform Backend, Storage and UI:\nThere are two kinds of probes:\n Language agents or SDKs following SkyWalking across-thread propagation formats and trace formats, run in the user’s application process. The Istio mixer adaptor, which collects telemetry from the Service Mesh.  The platform backend provides gRPC and RESTful HTTP endpoints for all SkyWalking-supported trace and metric telemetry data. For example, you can stream these metrics into an analysis system.\nStorage supports multiple implementations such as ElasticSearch, H2 (alpha), MySQL, and Apache ShardingSphere for MySQL Cluster. TiDB will be supported in next release.\nSkyWalking’s built-in UI with a GraphQL endpoint for data allows intuitive, customizable integration.\nSome examples of SkyWalking’s UI:\n Observe a Spring app using the SkyWalking JVM-agent   Observe on Istio without any agent, no matter what langugage the service is written in   See fine-grained metrics like request/Call per Minute, P99/95/90/75/50 latency, avg response time, heatmap   Service dependencies and metrics  Service Focused At Tetrate, we are focused on discovery, reliability, and security of your running services. This is why we are embracing Skywalking, which makes service performance observable.\nBehind this admittedly cool UI, the aggregation logic is very easy to understand, making it easy to customize SkyWalking in its Observability Analysis Language (OAL) script.\nWe’ll post more about OAL for developers looking to customize SkyWalking, and you can read the official OAL introduction document.\nScripts are based on three core concepts:\n  Service represents a group of workloads that provide the same behaviours for incoming requests. You can define the service name whether you are using instrument agents or SDKs. Otherwise, SkyWalking uses the name you defined in the underlying platform, such as Istio.\n  Service Instance Each workload in the Service group is called an instance. Like Pods in Kubernetes, it doesn\u0026rsquo;t need to be a single OS process. If you are using an instrument agent, an instance does map to one OS process.\n  Endpoint is a path in a certain service that handles incoming requests, such as HTTP paths or a gRPC service + method. Mesh telemetry and trace data are formatted as source objects (aka scope). These are the input for the aggregation, with the script describing how to aggregate, including input, conditions, and the resulting metric name.\n  Core Features The other core features in SkyWalking v6 are:\n Service, service instance, endpoint metrics analysis. Consistent visualization in Service Mesh and no mesh. Topology discovery, Service dependency analysis. Distributed tracing. Slow services and endpoints detected. Alarms.  Of course, SkyWalking has some more upgrades from v5, such as:\n ElasticSearch 6 as storage is supported. H2 storage implementor is back. Kubernetes cluster management is provided. You don’t need Zookeeper to keep the backend running in cluster mode. Totally new alarm core. Easier configuration. More cloud native style. MySQL will be supported in the next release.  Please: Test and Provide Feedback! We would love everyone to try to test our new version. You can find everything you need in our Apache repository,read the document for further details. You can contact the project team through the following channels:\n Submit an issue on GitHub repository Mailing list: dev@skywalking.apache.org . Send to dev-subscribe@kywalking.apache.org to subscribe the mail list. Gitter Project twitter  Oh, and one last thing! If you like our project, don\u0026rsquo;t forget to give us a star on GitHub.\n","excerpt":"Original link, Tetrate.io blog\nContext The integration of SkyWalking and Istio Service Mesh yields …","ref":"/blog/2018-12-12-skywalking-service-mesh-ready/","title":"SkyWalking v6 is Service Mesh ready"},{"body":"Based on his contributions to the project, he has been accepted as SkyWalking committer. Welcome aboard.\n","excerpt":"Based on his contributions to the project, he has been accepted as SkyWalking committer. Welcome …","ref":"/events/welcome-jian-tan-as-a-new-committer/","title":"Welcome Jian Tan as a new committer"},{"body":"APM consistently compatible in language agent(Java, .Net, NodeJS), 3rd party format(Zipkin) and service mesh telemetry(Istio). Go to downloads page to find release tars.\n","excerpt":"APM consistently compatible in language agent(Java, .Net, NodeJS), 3rd party format(Zipkin) and …","ref":"/events/release-apache-skywalking-6-0-0-alpha/","title":"Release Apache SkyWalking 6.0.0-alpha"},{"body":"A stable version of 5.x release. Go to downloads page to find release tars.\n","excerpt":"A stable version of 5.x release. Go to downloads page to find release tars.","ref":"/events/release-apache-skywalking-5-0-0-ga/","title":"Release Apache SkyWalking 5.0.0-GA"},{"body":"5.0.0-RC2 release. Go to downloads page to find release tars.\n","excerpt":"5.0.0-RC2 release. Go to downloads page to find release tars.","ref":"/events/release-apache-skywalking-5-0-0-rc2/","title":"Release Apache SkyWalking 5.0.0-RC2"},{"body":"5.0.0-beta2 release. Go to downloads page to find release tars.\n","excerpt":"5.0.0-beta2 release. Go to downloads page to find release tars.","ref":"/events/release-apache-skywalking-5-0-0-beta2/","title":"Release Apache SkyWalking 5.0.0-beta2"},{"body":"Translated by Sheng Wu.\nIn many big systems, distributed and especially microservice architectures become more and more popular. With the increase of modules and services, one incoming request could cross dozens of service. How to pinpoint the issues of the online system, and the bottleneck of the whole distributed system? This became a very important problem, which must be resolved.\nTo resolve the problems in distributed system, Google published the paper “Dapper, a Large-Scale Distributed Systems Tracing Infrastructure”, which mentioned the designs and ideas of building a distributed system. Many projects are inspired by it, created in the last 10 years. At 2015, Apache SkyWalking was created by Wu Sheng as a simple distributed system at first and open source. Through almost 3 years developments, at 2018, according to its 5.0.0-alpha/beta releases, it had already became a cool open source APM system for cloud native, container based system.\nAt the early of this year, I was trying to build the Butterfly open source APM in .NET Core, and that is when I met the Apache SkyWalking team and its creator. I decided to join them, and cooperate with them, to provide .NET Core agent native compatible with SkyWalking. At April, I released the first version .NET core agent 0.1.0. After several weeks interation, we released 0.2.0, for increasing the stability and adding HttpClient, Database driver supports.\nBefore we used .NET Core agent, we need to deploy SkyWalking collector, UI and ElasticSearch 5.x. You can download the release versions at here: http://skywalking.apache.org/downloads/ and follow the docs (Deploy-backend-in-standalone-mode, Deploy-backend-in-cluster-mode) to setup the backend.\nAt here, I are giving a quick start to represent, how to monitor a demo distributed .NET Core applications. I can say, that is easy.\n git clone https://github.com/OpenSkywalking/skywalking-netcore.git\n  cd skywalking-netcore\n  dotnet restore\n  dotnet run -p sample/SkyWalking.Sample.Backend dotnet run -p sample/SkyWalking.Sample.Frontend\n Now you can open http://localhost:5001/api/values to access the demo application. Then you can open SkyWalking WebUI http://localhost:8080\n  Overview of the whole distributed system   Topology of distributed system   Application view   Trace query   Span’s tags, logs and related traces   GitHub  Website: http://skywalking.apache.org/ SkyWalking Github Repo: https://github.com/apache/incubator-skywalking SkyWalking-NetCore Github Repo: https://github.com/OpenSkywalking/skywalking-netcore  ","excerpt":"Translated by Sheng Wu.\nIn many big systems, distributed and especially microservice architectures …","ref":"/blog/2018-05-24-skywalking-net/","title":"Apache SkyWalking provides open source APM and distributed tracing in .NET Core field"},{"body":"在大型网站系统设计中，随着分布式架构，特别是微服务架构的流行，我们将系统解耦成更小的单元，通过不断的添加新的、小的模块或者重用已经有的模块来构建复杂的系统。随着模块的不断增多，一次请求可能会涉及到十几个甚至几十个服务的协同处理，那么如何准确快速的定位到线上故障和性能瓶颈，便成为我们不得不面对的棘手问题。\n为解决分布式架构中复杂的服务定位和性能问题，Google 在论文《Dapper, a Large-Scale Distributed Systems Tracing Infrastructure》中提出了分布式跟踪系统的设计和构建思路。在这样的背景下，Apache SkyWalking 创建于 2015 年，参考 Dapper 论文实现分布式追踪功能，并逐渐进化为一个完整功能的 Application Performance Management 系统，用于追踪、监控和诊断大型分布式系统，尤其是容器和云原生下的微服务系统。\n今年初我在尝试使用.NET Core 构建分布式追踪系统 Butterfly 时接触到 SkyWalking 团队，开始和 SkyWalking 团队合作探索 SkyWalking 对.NET Core 的支持，并于 4 月发布 SkyWalking .NET Core 探针的 第一个版本，同时我也有幸加入 SkyWalking 团队共同进行 SkyWalking 在多语言生态的推动。在.NET Core 探针 v0.1 版本发布之后，得到了一些同学的尝鲜使用，也得到诸多改进的建议。经过几周的迭代，SkyWalking .NET Core 探针于今天发布 v0.2 release，在 v0.1 的基础上增加了\u0008稳定性和 HttpClient 及数据库驱动的追踪支持。\n在使用 SkyWalking 对.NET Core 应用追踪之前，我们需要先部署 SkyWalking Collector 收集分析 Trace 和 Elasticsearch 作为 Trace 数据存储。SkyWalking 支持 5.x 的 ES，所以我们需要下载安装对应版本的 ES，并配置 ES 的 cluster.name 为 CollectorDBCluster。然后部署 SkyWalking 5.0 beta 或更高版本 (下载地址:http://skywalking.apache.org/downloads/)。更详细的 Collector 部署文档，请参考 Deploy-backend-in-standalone-mode 和 Deploy-backend-in-cluster-mode。\n最后我们使用示例项目来演示在.NET Core 应用中使用 SkyWalking 进行追踪和监控，克隆 SkyWalking-NetCore 项目到本地：\ngit clone https://github.com/OpenSkywalking/skywalking-netcore.git 进入 skywalking-netcore 目录：\ncd skywalking-netcore 还原 nuget package：\ndotnet restore 启动示例项目：\ndotnet run -p sample/SkyWalking.Sample.Backend dotnet run -p sample/SkyWalking.Sample.Frontend 访问示例应用：\n打开 SkyWalking WebUI 即可看到我们的应用监控面板 http://localhost:8080\nDashboard 视图\nTopologyMap 视图\nApplication 视图\nTrace 视图\nTraceDetails 视图\nGitHub  SkyWalking Github Repo：https://github.com/apache/incubator-skywalking SkyWalking-NetCore Github Repo：https://github.com/OpenSkywalking/skywalking-netcore  ","excerpt":"在大型网站系统设计中，随着分布式架构，特别是微服务架构的流行，我们将系统解耦成更小的单元，通过不断的添加新的、小的模块或者重用已经有的模块来构建复杂的系统。随着模块的不断增多，一次请求可能会涉及到十几 …","ref":"/zh/2018-05-24-skywalking-net/","title":"Apache SkyWalking 为.NET Core带来开箱即用的分布式追踪和应用性能监控"},{"body":"","excerpt":"","ref":"/zh_tags/dotnetcore/","title":"DotNetCore"},{"body":"","excerpt":"","ref":"/tags/dotnetcore/","title":"DotNetCore"},{"body":"5.0.0-beta release. Go to downloads page to find release tars.\n","excerpt":"5.0.0-beta release. Go to downloads page to find release tars.","ref":"/events/release-apache-skywalking-5-0-0-beta/","title":"Release Apache SkyWalking 5.0.0-beta"},{"body":"5.0.0-alpha release. Go to downloads page to find release tars.\n","excerpt":"5.0.0-alpha release. Go to downloads page to find release tars.","ref":"/events/release-apache-skywalking-apm-5-0-0-alpha/","title":"Release Apache SkyWalking APM 5.0.0-alpha"},{"body":"","excerpt":"","ref":"/index.json","title":""},{"body":"  #td-cover-block-0 { background-image: url(/home_background_hu0af614851632d061c3c80a153395694b_2812588_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/home_background_hu0af614851632d061c3c80a153395694b_2812588_1920x1080_fill_q75_catmullrom_top.jpg); } }  Apache SkyWalking Quick Start  GitHub  Application performance monitor tool for distributed systems, especially designed for microservices, cloud native and container-based (Docker, Kubernetes, Mesos) architectures.        What is SkyWalking?  SkyWalking is an Observability Analysis Platform and Application Performance Management system. Tracing, Metrics and Logging all-in-one solution.\nJava, .Net Core, PHP, NodeJS, Golang, LUA, C++ agents supported\nIstio + Envoy Service Mesh supported\n                Live Demo  User: skywalking \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; Password: skywalking  Go      Feature List Consistent Observability  Tracing Metrics\nLogging\nBrowser monitoring\n  Multiple Language Agents  Java Golang\n.Net Core\nPython\nNodeJS\nC++\nPHP\nLua\n  Lightweight  No big data stack Adopt different scale\n  Modular  Storage pluggable Cluster coordinator pluggable\nSupport pull/push transportation\n  Alarm Supported  Alarm HTTP/gRPC forwarder Slack notification\nDingding notification\nWeChat notification\nRaw metrics data exporter\n  Fancy Visualization  Customizable dashboard\nTopology map\nTrace and profile explorer\nCLI dashboard\nIntelliJ IDE plugin, metrics side by side with codes\n       Events \u0026amp; News  .fr{ float: right; }  Release Apache SkyWalking APM 8.4.0 Thu, Feb 4, 2021 SkyWalking 8.4.0 is released. Go to downloads page to find release tars. Changes by Version Project …\n Release Apache SkyWalking Cloud on Kubernetes 0.2.0 Sun, Jan 31, 2021 SkyWalking Cloud on Kubernetes 0.2.0 is released. Go to downloads page to find release tars. …\n Release Apache SkyWalking Client JS 0.3.0 Thu, Jan 14, 2021 SkyWalking Client JS 0.3.0 is released. Go to downloads page to find release tars. Support tracing …\n Release Apache SkyWalking Eyes 0.1.0 Tue, Jan 12, 2021 SkyWalking Eyes 0.1.0 is released. Go to downloads page to find release tars. License Header Add …\n     Our Users  Various companies and organizations use SkyWalking for research, production and commercial products.                                                                                                                                                                                                                                                                                                                                                                                                                               Users are encouraged to add themselves to this page. Send a pull request to add your company or organization information [here].\n      Any questions? Features request, ask questions or report bugs? Feel free to file a issue or join our slack workspace.\n   Contributions welcome! We do a Pull Request contributions workflow on GitHub. New users are always welcome!\n   Follow us on Twitter! For announcement of latest features etc on @ASFSkyWalking.\n     This is the second Section     -- ","excerpt":"#td-cover-block-0 { background-image: …","ref":"/","title":"Apache SkyWalking"},{"body":"This is the blog section. It has two categories: News and Releases.\nFiles in these directories will be listed in reverse chronological order.\n","excerpt":"This is the blog section. It has two categories: News and Releases.\nFiles in these directories will …","ref":"/blog/","title":"Blog"},{"body":"","excerpt":"","ref":"/docs/","title":"Documentation"},{"body":"Download the SkyWalking recommended releases Use the links below to download the Apache SkyWalking from one of our mirrors.\nOnly source code releases are official Apache releases, binary distributions are just for end user convenience.\nDownload the latest versions S SkyWalking APM  SkyWalking is an Observability Analysis Platform and Application Performance Management system.\nSource  v8.4.0 | Feb. 4th, 2021 [src] [asc] [sha512]  v8.3.0 | Dec. 3rd, 2020 [src] [asc] [sha512]  v8.2.0 | Oct. 27th, 2020 [src] [asc] [sha512]     Distribution  v8.4.0 for ElasticSearch 6 | Feb. 4th, 2021 [tar] [asc] [sha512]  v8.4.0 for H2/MySQL/TiDB/InfluxDB/ElasticSearch 7 | Feb. 4th, 2021 [tar] [asc] [sha512]  v8.3.0 for ElasticSearch 6 | Dec. 3rd, 2020 [tar] [asc] [sha512]  v8.3.0 for H2/MySQL/TiDB/InfluxDB/ElasticSearch 7 | Dec. 3rd, 2020 [tar] [asc] [sha512]  v8.2.0 for ElasticSearch 6 | Oct. 27th, 2020 [tar] [asc] [sha512]  v8.2.0 for H2/MySQL/TiDB/InfluxDB/ElasticSearch 7 | Oct. 27th, 2020 [tar] [asc] [sha512]       L SkyWalking Nginx LUA  SkyWalking Nginx Agent provides the native tracing capability for Nginx powered by Nginx LUA module.\nSource  v0.3.0 | Oct. 24th, 2020 [src] [asc] [sha512]        C SkyWalking CLI  SkyWalking CLI is a command interaction tool for the SkyWalking user or OPS team.\nSource  v0.5.0 | Nov. 29th, 2020 [src] [asc] [sha512]     Distribution  v0.5.0 | Nov. 29th, 2020 [tar] [asc] [sha512]       P SkyWalking Python  The Python Agent for Apache SkyWalking, which provides the native tracing abilities for Python.\nSource  v0.5.0 | Dec. 28th, 2020 [src] [asc] [sha512]     Distribution  v0.5.0 | Dec. 28th, 2020 [Install via pip]       J SkyWalking NodeJS  The NodeJS Agent for Apache SkyWalking, which provides the native tracing abilities for NodeJS backend.\nSource  v0.1.0 | Dec. 30th, 2020 [src] [asc] [sha512]     Distribution  v0.1.0 | Dec. 30th, 2020 [Install via npm]       H SkyWalking Helm  SkyWalking Kubernetes repository provides ways to install and configure SkyWalking in a Kubernetes cluster. The scripts are written in Helm 3.\nSource  v4.0.0 | Nov. 3rd, 2020 [src] [asc] [sha512]        K SkyWalking Cloud on Kubernetes  A bridge project between Apache SkyWalking and Kubernetes.\nSource  v0.2.0 | Jan. 31st, 2020 [src] [asc] [sha512]     Distribution  v0.2.0 | Jan. 31st, 2020 [tar] [asc] [sha512]       S SkyWalking Client JavaScript  Apache SkyWalking Client-side JavaScript exception and tracing library.\nSource  v0.3.0 | Jan. 14th, 2021 [src] [asc] [sha512]        I SkyWalking Eyes  A full-featured license tool to check and fix license headers and resolve dependencies\u0026#39; licenses.\nSource  v0.1.0 | Jan. 12th, 2021 [src] [asc] [sha512]     Distribution  v0.1.0 | Jan. 12th, 2021 [tar] [asc] [sha512]        All Releases  Find all SkyWalking releases in the Archive repository. Archive incubating repository hosts older releases when SkyWalking was an incubator project.  Docker Images for convenience Docker images are not official ASF releases but provided for convenience. Recommended usage is always to build the source\nO SkyWalking OAP Server  This image would start up SkyWalking OAP server only. Note, choose *-es6 tags when use ElasticSearch 6, *-es7 tags when use ElasticSearch 7.\nDocker Image     U SkyWalking UI Image  This image would start up SkyWalking UI only.\nDocker Image     I SkyWalking Eyes Image  A full-featured license tool to check and fix license headers and resolve dependencies\u0026#39; licenses.\nDocker Image     K SkyWalking Cloud on Kubernetes  A platform for the SkyWalking user, provisions, upgrades, maintains SkyWalking relevant components, and makes them work natively on Kubernetes.\nDocker Image      Verify the releases PGP signatures KEYS\nIt is essential that you verify the integrity of the downloaded files using the PGP or SHA signatures. The PGP signatures can be verified using GPG or PGP. Please download the KEYS as well as the asc signature files for relevant distribution. It is recommended to get these files from the main distribution directory and not from the mirrors.\ngpg -i KEYS or pgpk -a KEYS or pgp -ka KEYS To verify the binaries/sources you can download the relevant asc files for it from main distribution directory and follow the below guide.\ngpg --verify apache-skywalking-apm-********.asc apache-skywalking-apm-********* or pgpv apache-skywalking-apm-********.asc or pgp apache-skywalking-apm-********.asc ","excerpt":"Download the SkyWalking recommended releases Use the links below to download the Apache SkyWalking …","ref":"/downloads/","title":"Downloads"},{"body":"SkyWalking events.\n","excerpt":"SkyWalking events.","ref":"/events/","title":"Events"},{"body":"","excerpt":"","ref":"/false/","title":"False"},{"body":"","excerpt":"","ref":"/search/","title":"Search Results"},{"body":"","excerpt":"","ref":"/tango/","title":"Tango"},{"body":"SkyWalking Team The SkyWalking team is comprised of Members and Contributors. Members have direct access to the source of SkyWalking project and actively evolve the code-base. Contributors improve the project through submission of patches and suggestions to the Members. The number of Contributors to the project is unbounded. All contributions to SkyWalking are greatly appreciated, whether for trivial cleanups, big new features or other material rewards. More details see here.\nMembers Members include Project Management Committee members and committers. The list is in alphabet order.\nProject Management Committee    Name Apache ID Twitter     Can Li lican Candy198088   DongXue Si ilucky    Han Liu liuhan dalek_zero   Haochao Zhuang daming    Haoyang Liu liuhaoyangzz    Hongtao Gao hanahmily    Hongwei Zhai innerpeacez    Ignasi Barrera nacx    Jian Tan tanjian    Jiaqi Lin linjiaqi    Jinlin Fu withlin    Kai Wang wangkai    Lang Li lilang    Michael Semb Wever mck    Qiuxia Fan qiuxiafan    Sheng Wu (V.P. and Chair of PMC) wusheng wusheng1108   Shinn Zhang zhangxin ascrutae   Wei Zhang zhangwei24    Wenbing Wang wangwenbin    Willem Ning Jiang ningjiang    Yang Bai baiyang    Yao Wang ywang    Yixiong Cao caoyixiong    Yongsheng Peng pengys    Yuguang Zhao zhaoyuguang    Zhang Kewei zhangkewei    Zhenxu Ke kezhenxu94 kezhenxu94    Committer    Name Apache ID Twitter     Brandon Fergerson bfergerson    Gui Cao zifeihan zifeihan007   Huaxi Jiang hoshea Zerone___01   Jiapeng Liu liujiapeng    JunXu Chen chenjunxu    Juntao Zhang zhangjuntao    Ke Zhang zhangke Humbertttttt   Ming Wen wenming    Sheng Wang wangsheng    Wei Hua alonelaval    Wei Jin kvn    Weijie Zou kdump RootShellExp   Weiyi Liu wayilau    Yanlong He heyanlong YanlongHe   Yuntao Li liyuntao    Zhusheng Xu aderm     Contributors SkyWalking have hundreds of contributors, you could find them in our repositories\u0026rsquo; contribution list.\n SkyWalking main repository SkyWalking Nginx LUA SkyWalking RocketBot UI SkyWalking data collect protocol SkyWalking query protocol SkyWalking website SkyWalking docker SkyWalking kubernetes SkyWalking K8s Operator - SkyWalking Cloud on Kubernetes SkyWalking Python Agent SkyWalking CLI SkyWalking Client JS SkyWalking satellite SkyWalking agent test tool SkyWalking NodeJS Agent  Archived\n SkyWalking UI. Replaced by RocketBot UI. SkyWalking OAL tool  Becoming a Committer SkyWalking follows the Apache way to build the community. Anyone can become a committer once they have contributed sufficiently to the project and earned the trust. Read Contributing Guides to take part in the community.\nThe SkyWalking community follows the Apache Community’s process on accepting a new committer.\n Start the discussion and vote in @private. Only current PMC member could nominate. If the vote passes, send an offer to become a committer with @private CC’ed. Add the committer to the team page Setup committer rights  ","excerpt":"SkyWalking Team The SkyWalking team is comprised of Members and Contributors. Members have direct …","ref":"/team/","title":"Team"},{"body":"","excerpt":"","ref":"/true/","title":"True"},{"body":"","excerpt":"","ref":"/zh/","title":"博客"}]